{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "GRU.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyNV0KPIAT7C9F6NcG9YIqy4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/quekhyg/NLP-Lyric-Generator/blob/main/GRU.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GWydhOPBB9Oh",
        "outputId": "126aa434-3767-439d-af92-1c5e1824fb25"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "/content/drive/.shortcut-targets-by-id/1MmY0pN1b5xL_C2CijM9ImcFM-UFt4bwr/NLP project\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "%cd /content/drive/MyDrive/Colab Notebooks/SMU_MITB_NLP/NLP project/"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#import packages\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "import tensorflow as tf\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Dropout\n",
        "from keras.layers import GRU\n",
        "from keras.utils import np_utils"
      ],
      "metadata": {
        "id": "lusSKivLCRz3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Data Preprocessing"
      ],
      "metadata": {
        "id": "iiO1wTbgdAtB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "path = \"./songs_edit_revised/\"\n",
        "corpus = ''\n",
        "\n",
        "all_files = os.listdir(path)\n",
        "for file in all_files:\n",
        "  with open(os.path.join(path, file)) as f:\n",
        "    text = f.read()\n",
        "    corpus+= text"
      ],
      "metadata": {
        "id": "r15Y7g3MCSyY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Deep Learning Setup using Tensorflow Text Generation"
      ],
      "metadata": {
        "id": "Jm2HUDgHbQEM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "vocab = sorted(set(corpus))\n",
        "print(f'{len(vocab)} unique characters')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eCbfcHO_Sqoj",
        "outputId": "8d7be4f3-1738-4023-cafd-9aa6ff461c76"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "62 unique characters\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ids_from_chars = tf.keras.layers.StringLookup(vocabulary = list(vocab),\n",
        "                                              mask_token=None)\n",
        "chars_from_ids = tf.keras.layers.StringLookup(\n",
        "    vocabulary=ids_from_chars.get_vocabulary(), invert=True, mask_token=None)"
      ],
      "metadata": {
        "id": "0p6zBPwXZzQJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def text_from_ids(ids):\n",
        "  return tf.strings.reduce_join(chars_from_ids(ids), axis=-1)"
      ],
      "metadata": {
        "id": "Q2O2TjA_aeCq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "all_ids = ids_from_chars(tf.strings.unicode_split(corpus, 'UTF-8'))\n",
        "all_ids"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mAfXthZtbezR",
        "outputId": "7d4e733c-5f70-430f-c68c-4c39216c87a8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(56674,), dtype=int64, numpy=array([ 8, 32, 15, ..., 36, 49, 39])>"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ids_dataset =tf.data.Dataset.from_tensor_slices(all_ids)"
      ],
      "metadata": {
        "id": "yj6Doh3vb3uH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for ids in ids_dataset.take(10):\n",
        "  print(chars_from_ids(ids).numpy().decode('utf-8'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JuuRKTz4b_Vf",
        "outputId": "64699e05-b641-4b2b-de1f-ab6306d4429e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<\n",
            "V\n",
            "E\n",
            "R\n",
            "S\n",
            "E\n",
            ">\n",
            "\n",
            "\n",
            "W\n",
            "i\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "seq_length = 100 #100 characters\n",
        "sequences = ids_dataset.batch(seq_length+1,drop_remainder=True)\n",
        "for seq in sequences.take(5):\n",
        "  print(text_from_ids(seq).numpy())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FPy-FTKycGDY",
        "outputId": "8bdfa7ae-c6ff-4574-9e1f-26c588fdb4e6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "b'<VERSE>\\nWill you make this island\\nAmazing in all ways\\nSurprises every corner\\nDelightful nights and da'\n",
            "b'ys\\nWill you take this country\\nAnd turn it from a place\\nTo a home that greets you\\nWith smiles on every'\n",
            "b' face\\nWill you come on this brave journey\\nWill you help to make it real\\nWill you write us grand new s'\n",
            "b'tories\\nSongs that everyone will feel\\n\\n<CHORUS>\\nSo will you swim the current\\nWill you scale new height'\n",
            "b's\\nWill you make it happen\\nWill you let your dreams take flight\\nAnd will you make the difference\\nWill '\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def split_input_target(sequence):\n",
        "  '''\n",
        "  For training, a dataset of (input,label) pairs are needed.\n",
        "  At each time step, the input is the current character, and the label\n",
        "  is the next character.\n",
        "  '''\n",
        "  input_text = sequence[:-1]\n",
        "  target_text = sequence[1:]\n",
        "  return input_text, target_text"
      ],
      "metadata": {
        "id": "E3UzjtJkcqoh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = sequences.map(split_input_target)"
      ],
      "metadata": {
        "id": "GRD07hAsc9Yc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for input_example, target_example in dataset.take(1):\n",
        "  print(\"Input: \",text_from_ids(input_example).numpy())\n",
        "  print(\"Target: \",text_from_ids(target_example).numpy())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y-ntS1OZdOTG",
        "outputId": "67b8feae-3023-4e85-abce-49bade0b1789"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input:  b'<VERSE>\\nWill you make this island\\nAmazing in all ways\\nSurprises every corner\\nDelightful nights and d'\n",
            "Target:  b'VERSE>\\nWill you make this island\\nAmazing in all ways\\nSurprises every corner\\nDelightful nights and da'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 128\n",
        "buffer_size = 10000\n",
        "# Buffer size to shuffle the dataset\n",
        "# (TF data is designed to work with possibly infinite sequences,\n",
        "# so it doesn't attempt to shuffle the entire sequence in memory. Instead,\n",
        "# it maintains a buffer in which it shuffles elements).\n",
        "\n",
        "dataset = (\n",
        "    dataset\n",
        "    .shuffle(buffer_size)\n",
        "    .batch(batch_size, drop_remainder=True)\n",
        "    .prefetch(tf.data.experimental.AUTOTUNE))"
      ],
      "metadata": {
        "id": "CNDl1N1jdYAt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model development"
      ],
      "metadata": {
        "id": "3q_DyM1Ne7Bp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Length of the vocabulary in StringLookup Layer\n",
        "vocab_size = len(ids_from_chars.get_vocabulary())\n",
        "\n",
        "# The embedding dimension\n",
        "embedding_dim = 512\n",
        "\n",
        "# Number of RNN units\n",
        "rnn_units = 2048"
      ],
      "metadata": {
        "id": "7YWcqsTLeX08"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class BuildGRUModel(tf.keras.Model):\n",
        "  def __init__(self, vocab_size, embedding_dim, rnn_units):\n",
        "    super().__init__(self)\n",
        "    self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
        "    self.gru_1 = tf.keras.layers.GRU(rnn_units,\n",
        "                                   return_sequences=True,\n",
        "                                   return_state=True)\n",
        "    self.dense = tf.keras.layers.Dense(vocab_size)\n",
        "\n",
        "  def call(self, inputs, states=None, return_state=False, training=False):\n",
        "    x = inputs\n",
        "    x = self.embedding(x, training=training)\n",
        "    if states is None:\n",
        "      states = self.gru_1.get_initial_state(x)\n",
        "    x, states = self.gru_1(x, initial_state=states, training=training)\n",
        "    x = self.dense(x, training=training)\n",
        "\n",
        "    if return_state:\n",
        "      return x, states\n",
        "    else:\n",
        "      return x"
      ],
      "metadata": {
        "id": "KVxD519fhzIG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = BuildGRUModel(\n",
        "    vocab_size=vocab_size,\n",
        "    embedding_dim=embedding_dim,\n",
        "    rnn_units=rnn_units)"
      ],
      "metadata": {
        "id": "_o094k7oib3t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for input_example_batch, target_example_batch in dataset.take(1):\n",
        "    example_batch_predictions = model(input_example_batch)\n",
        "    print(example_batch_predictions.shape, \"# (batch_size, sequence_length, vocab_size)\")\n",
        "    \n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9OjAAqs3jOlt",
        "outputId": "4b366f5b-51c4-40d9-96d0-9b156a9902f5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(128, 100, 63) # (batch_size, sequence_length, vocab_size)\n",
            "Model: \"build_gru_model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding (Embedding)       multiple                  32256     \n",
            "                                                                 \n",
            " gru (GRU)                   multiple                  15740928  \n",
            "                                                                 \n",
            " dense (Dense)               multiple                  129087    \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 15,902,271\n",
            "Trainable params: 15,902,271\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss = tf.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
        "model.compile(optimizer='adam', loss=loss)"
      ],
      "metadata": {
        "id": "tMi9BnWkiv90"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 100\n",
        "history = model.fit(dataset,epochs=epochs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-N3WJKyPi7cY",
        "outputId": "2eca19fb-efff-40af-ce0c-9ff7ab51c33d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "4/4 [==============================] - 3s 185ms/step - loss: 6.5772\n",
            "Epoch 2/100\n",
            "4/4 [==============================] - 1s 183ms/step - loss: 4.9843\n",
            "Epoch 3/100\n",
            "4/4 [==============================] - 1s 184ms/step - loss: 3.8803\n",
            "Epoch 4/100\n",
            "4/4 [==============================] - 1s 185ms/step - loss: 3.6900\n",
            "Epoch 5/100\n",
            "4/4 [==============================] - 1s 183ms/step - loss: 3.3882\n",
            "Epoch 6/100\n",
            "4/4 [==============================] - 1s 188ms/step - loss: 3.0633\n",
            "Epoch 7/100\n",
            "4/4 [==============================] - 1s 188ms/step - loss: 2.8792\n",
            "Epoch 8/100\n",
            "4/4 [==============================] - 1s 184ms/step - loss: 2.7194\n",
            "Epoch 9/100\n",
            "4/4 [==============================] - 1s 184ms/step - loss: 2.6156\n",
            "Epoch 10/100\n",
            "4/4 [==============================] - 1s 184ms/step - loss: 2.5101\n",
            "Epoch 11/100\n",
            "4/4 [==============================] - 1s 187ms/step - loss: 2.4162\n",
            "Epoch 12/100\n",
            "4/4 [==============================] - 1s 183ms/step - loss: 2.3457\n",
            "Epoch 13/100\n",
            "4/4 [==============================] - 1s 188ms/step - loss: 2.2718\n",
            "Epoch 14/100\n",
            "4/4 [==============================] - 1s 188ms/step - loss: 2.2086\n",
            "Epoch 15/100\n",
            "4/4 [==============================] - 1s 184ms/step - loss: 2.1516\n",
            "Epoch 16/100\n",
            "4/4 [==============================] - 1s 184ms/step - loss: 2.1047\n",
            "Epoch 17/100\n",
            "4/4 [==============================] - 1s 183ms/step - loss: 2.0643\n",
            "Epoch 18/100\n",
            "4/4 [==============================] - 1s 187ms/step - loss: 2.0251\n",
            "Epoch 19/100\n",
            "4/4 [==============================] - 1s 183ms/step - loss: 1.9810\n",
            "Epoch 20/100\n",
            "4/4 [==============================] - 1s 188ms/step - loss: 1.9534\n",
            "Epoch 21/100\n",
            "4/4 [==============================] - 1s 187ms/step - loss: 1.9079\n",
            "Epoch 22/100\n",
            "4/4 [==============================] - 1s 184ms/step - loss: 1.8756\n",
            "Epoch 23/100\n",
            "4/4 [==============================] - 1s 183ms/step - loss: 1.8452\n",
            "Epoch 24/100\n",
            "4/4 [==============================] - 1s 183ms/step - loss: 1.8154\n",
            "Epoch 25/100\n",
            "4/4 [==============================] - 1s 185ms/step - loss: 1.7817\n",
            "Epoch 26/100\n",
            "4/4 [==============================] - 1s 184ms/step - loss: 1.7542\n",
            "Epoch 27/100\n",
            "4/4 [==============================] - 1s 189ms/step - loss: 1.7249\n",
            "Epoch 28/100\n",
            "4/4 [==============================] - 1s 187ms/step - loss: 1.6925\n",
            "Epoch 29/100\n",
            "4/4 [==============================] - 1s 184ms/step - loss: 1.6545\n",
            "Epoch 30/100\n",
            "4/4 [==============================] - 1s 184ms/step - loss: 1.6322\n",
            "Epoch 31/100\n",
            "4/4 [==============================] - 1s 183ms/step - loss: 1.5998\n",
            "Epoch 32/100\n",
            "4/4 [==============================] - 1s 184ms/step - loss: 1.5656\n",
            "Epoch 33/100\n",
            "4/4 [==============================] - 1s 183ms/step - loss: 1.5378\n",
            "Epoch 34/100\n",
            "4/4 [==============================] - 1s 188ms/step - loss: 1.5049\n",
            "Epoch 35/100\n",
            "4/4 [==============================] - 1s 187ms/step - loss: 1.4796\n",
            "Epoch 36/100\n",
            "4/4 [==============================] - 1s 183ms/step - loss: 1.4393\n",
            "Epoch 37/100\n",
            "4/4 [==============================] - 1s 184ms/step - loss: 1.4134\n",
            "Epoch 38/100\n",
            "4/4 [==============================] - 1s 183ms/step - loss: 1.3830\n",
            "Epoch 39/100\n",
            "4/4 [==============================] - 1s 185ms/step - loss: 1.3690\n",
            "Epoch 40/100\n",
            "4/4 [==============================] - 1s 184ms/step - loss: 1.3212\n",
            "Epoch 41/100\n",
            "4/4 [==============================] - 1s 191ms/step - loss: 1.2932\n",
            "Epoch 42/100\n",
            "4/4 [==============================] - 1s 190ms/step - loss: 1.2619\n",
            "Epoch 43/100\n",
            "4/4 [==============================] - 1s 185ms/step - loss: 1.2167\n",
            "Epoch 44/100\n",
            "4/4 [==============================] - 1s 185ms/step - loss: 1.1915\n",
            "Epoch 45/100\n",
            "4/4 [==============================] - 1s 184ms/step - loss: 1.1621\n",
            "Epoch 46/100\n",
            "4/4 [==============================] - 1s 186ms/step - loss: 1.1169\n",
            "Epoch 47/100\n",
            "4/4 [==============================] - 1s 184ms/step - loss: 1.0926\n",
            "Epoch 48/100\n",
            "4/4 [==============================] - 1s 192ms/step - loss: 1.0845\n",
            "Epoch 49/100\n",
            "4/4 [==============================] - 1s 192ms/step - loss: 1.0219\n",
            "Epoch 50/100\n",
            "4/4 [==============================] - 1s 185ms/step - loss: 0.9860\n",
            "Epoch 51/100\n",
            "4/4 [==============================] - 1s 184ms/step - loss: 0.9524\n",
            "Epoch 52/100\n",
            "4/4 [==============================] - 1s 185ms/step - loss: 0.9228\n",
            "Epoch 53/100\n",
            "4/4 [==============================] - 1s 187ms/step - loss: 0.8730\n",
            "Epoch 54/100\n",
            "4/4 [==============================] - 1s 183ms/step - loss: 0.8494\n",
            "Epoch 55/100\n",
            "4/4 [==============================] - 1s 189ms/step - loss: 0.8160\n",
            "Epoch 56/100\n",
            "4/4 [==============================] - 1s 191ms/step - loss: 0.7889\n",
            "Epoch 57/100\n",
            "4/4 [==============================] - 1s 185ms/step - loss: 0.7546\n",
            "Epoch 58/100\n",
            "4/4 [==============================] - 1s 186ms/step - loss: 0.7077\n",
            "Epoch 59/100\n",
            "4/4 [==============================] - 1s 186ms/step - loss: 0.6730\n",
            "Epoch 60/100\n",
            "4/4 [==============================] - 1s 187ms/step - loss: 0.6456\n",
            "Epoch 61/100\n",
            "4/4 [==============================] - 1s 184ms/step - loss: 0.6066\n",
            "Epoch 62/100\n",
            "4/4 [==============================] - 1s 190ms/step - loss: 0.5752\n",
            "Epoch 63/100\n",
            "4/4 [==============================] - 1s 190ms/step - loss: 0.5331\n",
            "Epoch 64/100\n",
            "4/4 [==============================] - 1s 185ms/step - loss: 0.5040\n",
            "Epoch 65/100\n",
            "4/4 [==============================] - 1s 188ms/step - loss: 0.4745\n",
            "Epoch 66/100\n",
            "4/4 [==============================] - 1s 186ms/step - loss: 0.4452\n",
            "Epoch 67/100\n",
            "4/4 [==============================] - 1s 186ms/step - loss: 0.4223\n",
            "Epoch 68/100\n",
            "4/4 [==============================] - 1s 183ms/step - loss: 0.3940\n",
            "Epoch 69/100\n",
            "4/4 [==============================] - 1s 190ms/step - loss: 0.3756\n",
            "Epoch 70/100\n",
            "4/4 [==============================] - 1s 187ms/step - loss: 0.3396\n",
            "Epoch 71/100\n",
            "4/4 [==============================] - 1s 183ms/step - loss: 0.3159\n",
            "Epoch 72/100\n",
            "4/4 [==============================] - 1s 183ms/step - loss: 0.2933\n",
            "Epoch 73/100\n",
            "4/4 [==============================] - 1s 184ms/step - loss: 0.2694\n",
            "Epoch 74/100\n",
            "4/4 [==============================] - 1s 187ms/step - loss: 0.2460\n",
            "Epoch 75/100\n",
            "4/4 [==============================] - 1s 183ms/step - loss: 0.2305\n",
            "Epoch 76/100\n",
            "4/4 [==============================] - 1s 188ms/step - loss: 0.2155\n",
            "Epoch 77/100\n",
            "4/4 [==============================] - 1s 187ms/step - loss: 0.1993\n",
            "Epoch 78/100\n",
            "4/4 [==============================] - 1s 183ms/step - loss: 0.1878\n",
            "Epoch 79/100\n",
            "4/4 [==============================] - 1s 183ms/step - loss: 0.1758\n",
            "Epoch 80/100\n",
            "4/4 [==============================] - 1s 183ms/step - loss: 0.1643\n",
            "Epoch 81/100\n",
            "4/4 [==============================] - 1s 185ms/step - loss: 0.1569\n",
            "Epoch 82/100\n",
            "4/4 [==============================] - 1s 183ms/step - loss: 0.1480\n",
            "Epoch 83/100\n",
            "4/4 [==============================] - 1s 188ms/step - loss: 0.1404\n",
            "Epoch 84/100\n",
            "4/4 [==============================] - 1s 187ms/step - loss: 0.1320\n",
            "Epoch 85/100\n",
            "4/4 [==============================] - 1s 183ms/step - loss: 0.1265\n",
            "Epoch 86/100\n",
            "4/4 [==============================] - 1s 184ms/step - loss: 0.1200\n",
            "Epoch 87/100\n",
            "4/4 [==============================] - 1s 183ms/step - loss: 0.1163\n",
            "Epoch 88/100\n",
            "4/4 [==============================] - 1s 186ms/step - loss: 0.1109\n",
            "Epoch 89/100\n",
            "4/4 [==============================] - 1s 183ms/step - loss: 0.1063\n",
            "Epoch 90/100\n",
            "4/4 [==============================] - 1s 188ms/step - loss: 0.1025\n",
            "Epoch 91/100\n",
            "4/4 [==============================] - 1s 187ms/step - loss: 0.0989\n",
            "Epoch 92/100\n",
            "4/4 [==============================] - 1s 183ms/step - loss: 0.0947\n",
            "Epoch 93/100\n",
            "4/4 [==============================] - 1s 183ms/step - loss: 0.0911\n",
            "Epoch 94/100\n",
            "4/4 [==============================] - 1s 183ms/step - loss: 0.0893\n",
            "Epoch 95/100\n",
            "4/4 [==============================] - 1s 185ms/step - loss: 0.0866\n",
            "Epoch 96/100\n",
            "4/4 [==============================] - 1s 183ms/step - loss: 0.0837\n",
            "Epoch 97/100\n",
            "4/4 [==============================] - 1s 188ms/step - loss: 0.0812\n",
            "Epoch 98/100\n",
            "4/4 [==============================] - 1s 187ms/step - loss: 0.0792\n",
            "Epoch 99/100\n",
            "4/4 [==============================] - 1s 183ms/step - loss: 0.0764\n",
            "Epoch 100/100\n",
            "4/4 [==============================] - 1s 184ms/step - loss: 0.0746\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class OneStep(tf.keras.Model):\n",
        "  def __init__(self, model, chars_from_ids, ids_from_chars, temperature=1.0):\n",
        "    super().__init__()\n",
        "    self.temperature = temperature\n",
        "    self.model = model\n",
        "    self.chars_from_ids = chars_from_ids\n",
        "    self.ids_from_chars = ids_from_chars\n",
        "\n",
        "    # Create a mask to prevent \"[UNK]\" from being generated.\n",
        "    skip_ids = self.ids_from_chars(['[UNK]'])[:, None]\n",
        "    sparse_mask = tf.SparseTensor(\n",
        "        # Put a -inf at each bad index.\n",
        "        values=[-float('inf')]*len(skip_ids),\n",
        "        indices=skip_ids,\n",
        "        # Match the shape to the vocabulary\n",
        "        dense_shape=[len(ids_from_chars.get_vocabulary())])\n",
        "    self.prediction_mask = tf.sparse.to_dense(sparse_mask)\n",
        "\n",
        "  @tf.function\n",
        "  def generate_one_step(self, inputs, states=None):\n",
        "    # Convert strings to token IDs.\n",
        "    input_chars = tf.strings.unicode_split(inputs, 'UTF-8')\n",
        "    input_ids = self.ids_from_chars(input_chars).to_tensor()\n",
        "\n",
        "    # Run the model.\n",
        "    # predicted_logits.shape is [batch, char, next_char_logits]\n",
        "    predicted_logits, states = self.model(inputs=input_ids, states=states,\n",
        "                                          return_state=True)\n",
        "    # Only use the last prediction.\n",
        "    predicted_logits = predicted_logits[:, -1, :]\n",
        "    predicted_logits = predicted_logits/self.temperature\n",
        "    # Apply the prediction mask: prevent \"[UNK]\" from being generated.\n",
        "    predicted_logits = predicted_logits + self.prediction_mask\n",
        "\n",
        "    # Sample the output logits to generate token IDs.\n",
        "    predicted_ids = tf.random.categorical(predicted_logits, num_samples=1)\n",
        "    predicted_ids = tf.squeeze(predicted_ids, axis=-1)\n",
        "\n",
        "    # Convert from token ids to characters\n",
        "    predicted_chars = self.chars_from_ids(predicted_ids)\n",
        "\n",
        "    # Return the characters and model state.\n",
        "    return predicted_chars, states"
      ],
      "metadata": {
        "id": "MAOqImDsnOx8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "one_step_model = OneStep(model,chars_from_ids, ids_from_chars,temperature=0.5)"
      ],
      "metadata": {
        "id": "aGrS3JfVnbDU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "states = None\n",
        "next_char = tf.constant(['Whenever I think back'])\n",
        "result = [next_char]\n",
        "\n",
        "for n in range(200):\n",
        "  next_char, states = one_step_model.generate_one_step(next_char, states=states)\n",
        "  result.append(next_char)\n",
        "\n",
        "result = tf.strings.join(result)\n",
        "print(result[0].numpy().decode('utf-8'), '\\n\\n' + '_'*80)"
      ],
      "metadata": {
        "id": "pSPkJsMWnjbU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ddb9b93f-14f7-41ae-d9ec-ab51c7d5bf12"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Whenever I think back for me\n",
            "In a heartbeat, time has passed us by\n",
            "In a heartbeat, we will reach the sky\n",
            "This will always be\n",
            "Our people, our country, this is our family<VERSE>\n",
            "Over the years, I've grown to be a part of yo \n",
            "\n",
            "________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "verse1= result[0].numpy().decode('utf-8')\n",
        "verse1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "n9TEE8mRqZ1k",
        "outputId": "449715c2-c042-4e5e-a7a8-b69d1594268c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"Whenever I think back for me\\nIn a heartbeat, time has passed us by\\nIn a heartbeat, we will reach the sky\\nThis will always be\\nOur people, our country, this is our family<VERSE>\\nOver the years, I've grown to be a part of yo\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "states = None\n",
        "next_char = tf.constant([\"together we\"])\n",
        "result2 = [next_char]\n",
        "\n",
        "for n in range(200):\n",
        "  next_char, states = one_step_model.generate_one_step(next_char, states=states)\n",
        "  result2.append(next_char)\n",
        "\n",
        "result2 = tf.strings.join(result2)\n",
        "print(result2[0].numpy().decode('utf-8'), '\\n\\n' + '_'*80)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tRvp02vwdj1Z",
        "outputId": "8403febf-6a53-4dcc-ff1d-5835e33623bf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "together we can be\n",
            "The change that we've been longing to see\n",
            "\n",
            "<PRECHORUS>\n",
            "You and me, we'll do our part\n",
            "stand together, heart to heart\n",
            "We're going to show the world where we can\n",
            "We will help our fellow man\n",
            "We ar \n",
            "\n",
            "________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prechorus = result2[0].numpy().decode('utf-8')\n",
        "prechorus"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "GWdBQb0AzanE",
        "outputId": "f3afa8b6-39a4-4e08-e933-34f52576c231"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"together we can be\\nThe change that we've been longing to see\\n\\n<PRECHORUS>\\nYou and me, we'll do our part\\nstand together, heart to heart\\nWe're going to show the world where we can\\nWe will help our fellow man\\nWe ar\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "states = None\n",
        "next_char = tf.constant([\"And so this I know\"])\n",
        "result3 = [next_char]\n",
        "\n",
        "for n in range(200):\n",
        "  next_char, states = one_step_model.generate_one_step(next_char, states=states)\n",
        "  result3.append(next_char)\n",
        "\n",
        "result3 = tf.strings.join(result3)\n",
        "print(result3[0].numpy().decode('utf-8'), '\\n\\n' + '_'*80)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pJTQ3TTuwdR6",
        "outputId": "11fadf3b-bef8-4f64-9c1d-b13736ccf9f7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "And so this I know that love is there for me\n",
            "Here's where I belong\n",
            "We're as close as one big family\n",
            "Here's where I belong\n",
            "Where I keep my heart and soul\n",
            "Where dreams come true for us\n",
            "Where we walk together hand in hand \n",
            "\n",
            "________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "chorus= result3[0].numpy().decode('utf-8')\n",
        "chorus"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "ZMToqD3xyJf-",
        "outputId": "6ae95422-e4b8-402e-feba-747e749c60de"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"And so this I know that love is there for me\\nHere's where I belong\\nWe're as close as one big family\\nHere's where I belong\\nWhere I keep my heart and soul\\nWhere dreams come true for us\\nWhere we walk together hand in hand\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "states = None\n",
        "next_char = tf.constant([\"When I dream about the future\"])\n",
        "result4 = [next_char]\n",
        "\n",
        "for n in range(200):\n",
        "  next_char, states = one_step_model.generate_one_step(next_char, states=states)\n",
        "  result4.append(next_char)\n",
        "\n",
        "result4 = tf.strings.join(result4)\n",
        "print(result4[0].numpy().decode('utf-8'), '\\n\\n' + '_'*80)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "04DdPHJuzIq0",
        "outputId": "14eb482a-96d9-455d-b232-9b950abe0c33"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "When I dream about the future\n",
            "We built it for the ones that dream\n",
            "Hand in hand, we'll find new strengt\n",
            "We are Singapore, \n",
            "we are Singapore\n",
            "We're a nation built with love by you and me\n",
            "A land to treasure right to the core\n",
            "Our home \n",
            "\n",
            "________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "verse2= result4[0].numpy().decode('utf-8')\n",
        "verse2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "JXJTfPss0L7A",
        "outputId": "215f0d27-829b-4544-9cf0-316ab85ccf9b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"When I dream about the future\\nWe built it for the ones that dream\\nHand in hand, we'll find new strengt\\nWe are Singapore, \\nwe are Singapore\\nWe're a nation built with love by you and me\\nA land to treasure right to the core\\nOur home\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 79
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "song_container = [verse1, prechorus,chorus,verse2,prechorus, chorus]\n",
        "\n",
        "def to_song(song_container):\n",
        "  song = ''\n",
        "  for i in range(len(song_container)):\n",
        "    container = []\n",
        "    if i==0 or i ==3:\n",
        "      song+='\\n<VERSE>\\n'\n",
        "      container = song_container[i].split('\\n')[0:5]\n",
        "      song+='\\n'.join(container)\n",
        "    elif i==2 or i ==5:\n",
        "      song+='\\n<CHORUS>\\n'\n",
        "      container = song_container[i].split('\\n')[0:4]\n",
        "      song+='\\n'.join(container)\n",
        "    elif i ==1 or i ==4:\n",
        "      song+='\\n<PRECHORUS>\\n'\n",
        "      container = song_container[i].split('\\n')[0:4]\n",
        "      song+='\\n'.join(container)\n",
        "  \n",
        "  return song\n",
        "\n",
        "song = to_song(song_container)\n",
        "song"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "id": "RrBkxPmo1vOa",
        "outputId": "8ccb6f50-26bf-4de4-ad6f-9ab9bf47fc9f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"\\n<VERSE>\\nWhenever I think back for me\\nIn a heartbeat, time has passed us by\\nIn a heartbeat, we will reach the sky\\nThis will always be\\nOur people, our country, this is our family<VERSE>\\n<PRECHORUS>\\ntogether we can be\\nThe change that we've been longing to see\\n\\n<PRECHORUS>\\n<CHORUS>\\nAnd so this I know that love is there for me\\nHere's where I belong\\nWe're as close as one big family\\nHere's where I belong\\n<VERSE>\\nWhen I dream about the future\\nWe built it for the ones that dream\\nHand in hand, we'll find new strengt\\nWe are Singapore, \\nwe are Singapore\\n<PRECHORUS>\\ntogether we can be\\nThe change that we've been longing to see\\n\\n<PRECHORUS>\\n<CHORUS>\\nAnd so this I know that love is there for me\\nHere's where I belong\\nWe're as close as one big family\\nHere's where I belong\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 89
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for line in song.split('\\n'):\n",
        "  print(line)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v6BgsrA63mG9",
        "outputId": "b9e9115d-0176-42a3-ff43-f1df923fa06e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "<VERSE>\n",
            "Whenever I think back for me\n",
            "In a heartbeat, time has passed us by\n",
            "In a heartbeat, we will reach the sky\n",
            "This will always be\n",
            "Our people, our country, this is our family<VERSE>\n",
            "<PRECHORUS>\n",
            "together we can be\n",
            "The change that we've been longing to see\n",
            "\n",
            "<PRECHORUS>\n",
            "<CHORUS>\n",
            "And so this I know that love is there for me\n",
            "Here's where I belong\n",
            "We're as close as one big family\n",
            "Here's where I belong\n",
            "<VERSE>\n",
            "When I dream about the future\n",
            "We built it for the ones that dream\n",
            "Hand in hand, we'll find new strengt\n",
            "We are Singapore, \n",
            "we are Singapore\n",
            "<PRECHORUS>\n",
            "together we can be\n",
            "The change that we've been longing to see\n",
            "\n",
            "<PRECHORUS>\n",
            "<CHORUS>\n",
            "And so this I know that love is there for me\n",
            "Here's where I belong\n",
            "We're as close as one big family\n",
            "Here's where I belong\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "song_lyrics= song.split('\\n')\n",
        "with open(\"GRUfile.txt\", 'w') as output:\n",
        "    for row in song_lyrics:\n",
        "        output.write(str(row) + '\\n')"
      ],
      "metadata": {
        "id": "nh1EzRsF4bif"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Component specific training"
      ],
      "metadata": {
        "id": "HEQE-oX2hiHm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "path = \"./songs_edit_revised/\"\n",
        "corpus = ''\n",
        "\n",
        "all_files = os.listdir(path)\n",
        "for file in all_files:\n",
        "  with open(os.path.join(path, file)) as f:\n",
        "    text = f.read()\n",
        "    corpus+= text\n",
        "#   corpus+='\\t' #End of song demarcation\n",
        "\n",
        "# corpus = corpus.lower()"
      ],
      "metadata": {
        "id": "_YEItBt-hied"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "songs = corpus.split('\\t')\n",
        "components = [song.split('\\n\\n') for song in songs]"
      ],
      "metadata": {
        "id": "FSjBRkwjhied"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "components[0:2]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "03a34fc6-7a66-4805-c89c-f01b34196c5a",
        "id": "9AxVlAw-hied"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['<verse>\\nwill you make this island\\namazing in all ways\\nsurprises every corner\\ndelightful nights and days\\nwill you take this country\\nand turn it from a place\\nto a home that greets you\\nwith smiles on every face\\nwill you come on this brave journey\\nwill you help to make it real\\nwill you write us grand new stories\\nsongs that everyone will feel',\n",
              "  '<chorus>\\nso will you swim the current\\nwill you scale new heights\\nwill you make it happen\\nwill you let your dreams take flight\\nand will you make the difference\\nwill you seize the day\\nwill you live each moment\\nwill you dare to find new ways',\n",
              "  '<verse>\\nwill you take this city\\nand turn it from a place\\nto a home that greets you\\nwith smiles on every face\\nwill you come on this brave journey\\nwill you help to make it real\\nwill you write us grand new stories\\nsongs that everyone will feel',\n",
              "  '<chorus>\\nso will you swim the current\\nwill you scale new heights\\nwill you make it happen\\nwill you let your dreams take flight\\nand will you make the difference\\nwill you seize the day\\nwill you live each moment\\nwill you dare to find new ways',\n",
              "  '<others>\\ndare to find\\ndare to find\\ndare to find\\nnew ways'],\n",
              " ['<verse>\\nwake up, she said\\nlook it’s a beautiful day\\ndownstairs to the kitchen door\\nand then away\\ninto the light\\nmorning feeling lives on\\ncome the clouds, the moon\\nand morning is gone',\n",
              "  '<verse>\\nborn today some years ago\\nand had a happy childhood\\nbut i fell in love and out\\nnothing changed\\nlived a life of nothing much\\nbut then how much can one expect?\\nso there you are\\nmy life has gone\\nbut i’m the same',\n",
              "  '<chorus>\\njust my life story\\nminute by second a story\\nthat goes on forever with each breath that i take\\nthis is my life story\\nuneventfullest story\\nthat ages with each year and birthday cake',\n",
              "  '<verse>\\nget up, he said\\nhurry or you might be late\\neveryday you hurry off to keep your days\\nlearn something new\\nwhat are you hoping to prove?\\nmake some money\\nfind a wife\\nhave a kid or two',\n",
              "  '<verse>\\nthinking back\\ni like to dream of things i would have done\\nif i were braver then again i’m not\\nwhat’s there to do?\\nmaybe if i had another chance\\ni’d go into my past\\nand make my life a better one\\nfor me and you',\n",
              "  '<chorus>\\njust my life story\\nminute by second a story\\nthat goes on forever with each breath that i take\\nthis is my life story\\nuneventfullest story\\nthat ages with each year and birthday cake',\n",
              "  '<verse>\\nwhen its time\\nand i must close\\ni’ll write a book\\nand sign it x\\nand send it to some true romance type magazine somewhere\\nthen the world will read of me\\nand say there lived a hero\\nbut too late my friends and enemies\\ni guess life isn’t fair',\n",
              "  \"<others>\\nso my life story\\nis self-explanatory\\nwon't you please start from page one\\nand do go on\\ntill i am done\\n\"]]"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def remove_token(token, bucket):\n",
        "  '''\n",
        "  Removes \"<verse>\"\n",
        "  '''\n",
        "  result = bucket.split('\\n')\n",
        "  result.pop(0)\n",
        "  return result\n",
        "\n",
        "def get_text(bucket):\n",
        "  '''\n",
        "  Writing all the sentences of each part into one large text string\n",
        "  '''\n",
        "  result = ''\n",
        "  for i in range(len(bucket)):\n",
        "    for j in range(len(bucket[i])):\n",
        "      result+=bucket[i][j] + ' \\n'\n",
        "  \n",
        "  return result\n",
        "\n",
        "def get_song_part(component_list):\n",
        "  verses = []\n",
        "  choruses = []\n",
        "  bridges = []\n",
        "  others = []\n",
        "  prechoruses = []\n",
        "\n",
        "  for song in component_list:\n",
        "    for part in song:\n",
        "      if \"<verse>\" in part:\n",
        "        verses.append(remove_token(\"<verse>\",part))\n",
        "      elif \"<chorus>\" in part:\n",
        "        choruses.append(remove_token(\"<chorus>\",part))\n",
        "      elif \"<bridge>\" in part:\n",
        "        bridges.append(remove_token(\"<bridge>\",part))\n",
        "      elif \"<others>\" in part:\n",
        "        others.append(remove_token(\"<others>\",part))\n",
        "      else:\n",
        "        prechoruses.append(remove_token(\"<prechorus>\",part))\n",
        "  \n",
        "  verse = get_text(verses)\n",
        "  chorus = get_text(choruses)\n",
        "  bridge = get_text(bridges)\n",
        "  other = get_text(others)\n",
        "  prechorus = get_text(prechoruses)\n",
        "\n",
        "  return verse, chorus, bridge, other, prechorus"
      ],
      "metadata": {
        "id": "Zqwy1nbshiee"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "verse, chorus, bridge, other, prechorus = get_song_part(components)"
      ],
      "metadata": {
        "id": "GSFW13Vqhiee"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "verse[0:200]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "b7f5fee4-3778-427c-9f3a-149ae1759229",
        "id": "Yq6eA0uzhiee"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'will you make this island \\namazing in all ways \\nsurprises every corner \\ndelightful nights and days \\nwill you take this country \\nand turn it from a place \\nto a home that greets you \\nwith smiles on ever'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "words =  verse.split()\n",
        "unique_words = list(set(words))\n",
        "print(f'Number of words: {len(words)}, Number of unique words: {len(unique_words)}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4355c970-6dc6-44c5-a2e5-4b214ca027bd",
        "id": "VozlAWnxhiee"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of words: 4430, Number of unique words: 964\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Deep learning setup"
      ],
      "metadata": {
        "id": "CZNyMMVJdFA1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "characters = sorted(list(set(verse)))\n",
        "n_to_char = {n:char for n, char in enumerate(characters)}\n",
        "char_to_n = {char:n for n, char in enumerate(characters)}"
      ],
      "metadata": {
        "id": "dV_tvwJ8srr6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here, X is our train array, and Y is our target array.\n",
        "\n",
        "seq_length is the length of the sequence of characters that we want to consider before predicting a particular character.\n",
        "\n",
        "The for loop is used to iterate over the entire length of the text and create such sequences (stored in X) and their true values (stored in Y)."
      ],
      "metadata": {
        "id": "8y4uEunxtD4Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X = []\n",
        "Y = []\n",
        "length = len(verse)\n",
        "seq_length = 100\n",
        "for i in range(0, length-seq_length, 1):\n",
        "  sequence = verse[i:i + seq_length]\n",
        "  label =verse[i + seq_length]\n",
        "  X.append([char_to_n[char] for char in sequence])\n",
        "  Y.append(char_to_n[label])"
      ],
      "metadata": {
        "id": "xfi3fbQ2srpk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Transforming inputs to the form of (number_of_sequences, length_of_sequence, number_of_features) for deep learning. To transform the array Y into a one-hot encoded format."
      ],
      "metadata": {
        "id": "YzTKu5W0tJ4e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_modified = np.reshape(X, (len(X), seq_length, 1))\n",
        "X_modified = X_modified / float(len(characters))\n",
        "Y_modified = np_utils.to_categorical(Y)"
      ],
      "metadata": {
        "id": "UzZFBWtRsrnE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Experiment 1"
      ],
      "metadata": {
        "id": "0PdjXoxeHPdx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "model.add(GRU(1024, input_shape=(X_modified.shape[1], X_modified.shape[2]), \n",
        "              return_sequences=True))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(GRU(1024, return_sequences=True))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(GRU(1024))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(Y_modified.shape[1], activation='softmax'))\n",
        "\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam')"
      ],
      "metadata": {
        "id": "ebG6C72xsrk7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(X_modified, Y_modified, epochs=100, batch_size=64)\n",
        "model.save_weights('GRU_text_generator_v2.h5')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2S7LHSsfUmw_",
        "outputId": "ff9f7a27-643c-43fe-e068-8ca461bf7967"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "364/364 [==============================] - 55s 129ms/step - loss: 2.7378\n",
            "Epoch 2/100\n",
            "364/364 [==============================] - 47s 129ms/step - loss: 2.5359\n",
            "Epoch 3/100\n",
            "364/364 [==============================] - 47s 129ms/step - loss: 2.3634\n",
            "Epoch 4/100\n",
            "364/364 [==============================] - 47s 129ms/step - loss: 2.1702\n",
            "Epoch 5/100\n",
            "364/364 [==============================] - 47s 130ms/step - loss: 1.9301\n",
            "Epoch 6/100\n",
            "364/364 [==============================] - 47s 129ms/step - loss: 1.6545\n",
            "Epoch 7/100\n",
            "364/364 [==============================] - 47s 129ms/step - loss: 1.3476\n",
            "Epoch 8/100\n",
            "364/364 [==============================] - 47s 129ms/step - loss: 1.0638\n",
            "Epoch 9/100\n",
            "364/364 [==============================] - 47s 129ms/step - loss: 0.8067\n",
            "Epoch 10/100\n",
            "364/364 [==============================] - 47s 129ms/step - loss: 0.6099\n",
            "Epoch 11/100\n",
            "364/364 [==============================] - 47s 129ms/step - loss: 0.4523\n",
            "Epoch 12/100\n",
            "364/364 [==============================] - 47s 129ms/step - loss: 0.3306\n",
            "Epoch 13/100\n",
            "364/364 [==============================] - 47s 129ms/step - loss: 0.2618\n",
            "Epoch 14/100\n",
            "364/364 [==============================] - 47s 129ms/step - loss: 0.2377\n",
            "Epoch 15/100\n",
            "364/364 [==============================] - 47s 129ms/step - loss: 0.2093\n",
            "Epoch 16/100\n",
            "364/364 [==============================] - 47s 130ms/step - loss: 0.2217\n",
            "Epoch 17/100\n",
            "364/364 [==============================] - 47s 129ms/step - loss: 0.2399\n",
            "Epoch 18/100\n",
            "364/364 [==============================] - 47s 129ms/step - loss: 0.2809\n",
            "Epoch 19/100\n",
            "364/364 [==============================] - 47s 129ms/step - loss: 0.2872\n",
            "Epoch 20/100\n",
            "364/364 [==============================] - 47s 129ms/step - loss: 0.2297\n",
            "Epoch 21/100\n",
            "364/364 [==============================] - 47s 129ms/step - loss: 0.2005\n",
            "Epoch 22/100\n",
            "364/364 [==============================] - 47s 129ms/step - loss: 0.2517\n",
            "Epoch 23/100\n",
            "364/364 [==============================] - 47s 129ms/step - loss: 0.3037\n",
            "Epoch 24/100\n",
            "364/364 [==============================] - 47s 129ms/step - loss: 0.4430\n",
            "Epoch 25/100\n",
            "364/364 [==============================] - 47s 129ms/step - loss: 0.4793\n",
            "Epoch 26/100\n",
            "364/364 [==============================] - 47s 129ms/step - loss: 0.3826\n",
            "Epoch 27/100\n",
            "364/364 [==============================] - 47s 129ms/step - loss: 0.3676\n",
            "Epoch 28/100\n",
            "364/364 [==============================] - 47s 129ms/step - loss: 0.4379\n",
            "Epoch 29/100\n",
            "364/364 [==============================] - 47s 129ms/step - loss: 3.6620\n",
            "Epoch 30/100\n",
            "364/364 [==============================] - 47s 129ms/step - loss: 3.9581\n",
            "Epoch 31/100\n",
            "364/364 [==============================] - 47s 129ms/step - loss: 3.7242\n",
            "Epoch 32/100\n",
            "364/364 [==============================] - 47s 130ms/step - loss: 3.5636\n",
            "Epoch 33/100\n",
            "364/364 [==============================] - 47s 130ms/step - loss: 3.4344\n",
            "Epoch 34/100\n",
            "364/364 [==============================] - 47s 130ms/step - loss: 3.3502\n",
            "Epoch 35/100\n",
            "364/364 [==============================] - 47s 129ms/step - loss: 3.2846\n",
            "Epoch 36/100\n",
            "364/364 [==============================] - 47s 129ms/step - loss: 3.2225\n",
            "Epoch 37/100\n",
            "364/364 [==============================] - 47s 129ms/step - loss: 3.1753\n",
            "Epoch 38/100\n",
            "364/364 [==============================] - 47s 129ms/step - loss: 3.1510\n",
            "Epoch 39/100\n",
            "364/364 [==============================] - 47s 129ms/step - loss: 3.1349\n",
            "Epoch 40/100\n",
            "364/364 [==============================] - 47s 129ms/step - loss: 3.1037\n",
            "Epoch 41/100\n",
            "364/364 [==============================] - 47s 129ms/step - loss: 3.0866\n",
            "Epoch 42/100\n",
            "364/364 [==============================] - 47s 129ms/step - loss: 3.0678\n",
            "Epoch 43/100\n",
            "364/364 [==============================] - 47s 129ms/step - loss: 3.0636\n",
            "Epoch 44/100\n",
            "364/364 [==============================] - 47s 129ms/step - loss: 3.0510\n",
            "Epoch 45/100\n",
            "364/364 [==============================] - 47s 129ms/step - loss: 3.0403\n",
            "Epoch 46/100\n",
            "364/364 [==============================] - 47s 129ms/step - loss: 3.0344\n",
            "Epoch 47/100\n",
            "364/364 [==============================] - 47s 129ms/step - loss: 3.0263\n",
            "Epoch 48/100\n",
            "364/364 [==============================] - 47s 129ms/step - loss: 3.0239\n",
            "Epoch 49/100\n",
            "364/364 [==============================] - 47s 129ms/step - loss: 3.0184\n",
            "Epoch 50/100\n",
            "364/364 [==============================] - 47s 129ms/step - loss: 3.0169\n",
            "Epoch 51/100\n",
            "364/364 [==============================] - 47s 129ms/step - loss: 3.0127\n",
            "Epoch 52/100\n",
            "364/364 [==============================] - 47s 129ms/step - loss: 3.0098\n",
            "Epoch 53/100\n",
            "364/364 [==============================] - 47s 129ms/step - loss: 3.0103\n",
            "Epoch 54/100\n",
            "364/364 [==============================] - 47s 129ms/step - loss: 3.0054\n",
            "Epoch 55/100\n",
            "364/364 [==============================] - 47s 129ms/step - loss: 3.0005\n",
            "Epoch 56/100\n",
            "364/364 [==============================] - 47s 129ms/step - loss: 3.0045\n",
            "Epoch 57/100\n",
            "364/364 [==============================] - 47s 129ms/step - loss: 2.9965\n",
            "Epoch 58/100\n",
            "364/364 [==============================] - 47s 129ms/step - loss: 3.0139\n",
            "Epoch 59/100\n",
            "364/364 [==============================] - 47s 129ms/step - loss: 3.0016\n",
            "Epoch 60/100\n",
            "364/364 [==============================] - 47s 129ms/step - loss: 3.0005\n",
            "Epoch 61/100\n",
            "364/364 [==============================] - 47s 129ms/step - loss: 2.9998\n",
            "Epoch 62/100\n",
            "364/364 [==============================] - 47s 129ms/step - loss: 2.9944\n",
            "Epoch 63/100\n",
            "364/364 [==============================] - 47s 129ms/step - loss: 3.0002\n",
            "Epoch 64/100\n",
            "364/364 [==============================] - 47s 129ms/step - loss: 2.9990\n",
            "Epoch 65/100\n",
            "364/364 [==============================] - 47s 129ms/step - loss: 2.9992\n",
            "Epoch 66/100\n",
            "364/364 [==============================] - 47s 129ms/step - loss: 2.9994\n",
            "Epoch 67/100\n",
            "364/364 [==============================] - 47s 129ms/step - loss: 3.0002\n",
            "Epoch 68/100\n",
            "364/364 [==============================] - 47s 129ms/step - loss: 2.9931\n",
            "Epoch 69/100\n",
            "364/364 [==============================] - 47s 129ms/step - loss: 2.9963\n",
            "Epoch 70/100\n",
            "364/364 [==============================] - 47s 129ms/step - loss: 2.9966\n",
            "Epoch 71/100\n",
            "364/364 [==============================] - 47s 129ms/step - loss: 2.9941\n",
            "Epoch 72/100\n",
            "364/364 [==============================] - 47s 129ms/step - loss: 2.9947\n",
            "Epoch 73/100\n",
            "364/364 [==============================] - 47s 129ms/step - loss: 2.9968\n",
            "Epoch 74/100\n",
            "364/364 [==============================] - 47s 129ms/step - loss: 3.0012\n",
            "Epoch 75/100\n",
            "364/364 [==============================] - 47s 129ms/step - loss: 2.9923\n",
            "Epoch 76/100\n",
            "364/364 [==============================] - 47s 129ms/step - loss: 2.9916\n",
            "Epoch 77/100\n",
            "364/364 [==============================] - 47s 129ms/step - loss: 2.9948\n",
            "Epoch 78/100\n",
            "364/364 [==============================] - 47s 129ms/step - loss: 2.9878\n",
            "Epoch 79/100\n",
            "364/364 [==============================] - 47s 129ms/step - loss: 3.0010\n",
            "Epoch 80/100\n",
            "364/364 [==============================] - 47s 129ms/step - loss: 3.0006\n",
            "Epoch 81/100\n",
            "364/364 [==============================] - 47s 129ms/step - loss: 2.9990\n",
            "Epoch 82/100\n",
            "364/364 [==============================] - 47s 129ms/step - loss: 2.9931\n",
            "Epoch 83/100\n",
            "364/364 [==============================] - 47s 129ms/step - loss: 2.9946\n",
            "Epoch 84/100\n",
            "364/364 [==============================] - 47s 129ms/step - loss: 2.9934\n",
            "Epoch 85/100\n",
            "364/364 [==============================] - 47s 129ms/step - loss: 2.9921\n",
            "Epoch 86/100\n",
            "364/364 [==============================] - 47s 129ms/step - loss: 2.9902\n",
            "Epoch 87/100\n",
            "364/364 [==============================] - 47s 129ms/step - loss: 2.9959\n",
            "Epoch 88/100\n",
            "364/364 [==============================] - 47s 129ms/step - loss: 2.9985\n",
            "Epoch 89/100\n",
            "364/364 [==============================] - 47s 129ms/step - loss: 2.9956\n",
            "Epoch 90/100\n",
            "364/364 [==============================] - 47s 129ms/step - loss: 2.9900\n",
            "Epoch 91/100\n",
            "364/364 [==============================] - 47s 129ms/step - loss: 2.9942\n",
            "Epoch 92/100\n",
            "364/364 [==============================] - 47s 129ms/step - loss: 2.9933\n",
            "Epoch 93/100\n",
            "364/364 [==============================] - 47s 129ms/step - loss: 2.9924\n",
            "Epoch 94/100\n",
            "364/364 [==============================] - 47s 129ms/step - loss: 2.9941\n",
            "Epoch 95/100\n",
            "364/364 [==============================] - 47s 129ms/step - loss: 2.9896\n",
            "Epoch 96/100\n",
            "364/364 [==============================] - 47s 129ms/step - loss: 2.9922\n",
            "Epoch 97/100\n",
            "364/364 [==============================] - 47s 129ms/step - loss: 2.9941\n",
            "Epoch 98/100\n",
            "364/364 [==============================] - 47s 129ms/step - loss: 2.9930\n",
            "Epoch 99/100\n",
            "364/364 [==============================] - 47s 129ms/step - loss: 2.9892\n",
            "Epoch 100/100\n",
            "364/364 [==============================] - 47s 129ms/step - loss: 2.9927\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.load_weights('GRU_text_generator_v2.h5')"
      ],
      "metadata": {
        "id": "-QJcFhKmUmu4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We start off with a random row from the X array, that is an array of 100 characters. After this, we target predicting another 100 characters following X. The input is reshaped and scaled as previously and the next character with maximum probability is predicted.\n",
        "\n",
        "seq is used to store the decoded format of the string that has been predicted till now. Next, the new string is updated, such that the first character is removed and the new predicted character is included."
      ],
      "metadata": {
        "id": "8Fh1M4a3FEmF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "string_mapped = X[108] #The sequence length is only 100 so taking the wrong index of X will cause a word to be axed.\n",
        "full_string = [n_to_char[value] for value in string_mapped]\n",
        "# generating characters\n",
        "for i in range(400):\n",
        "    x = np.reshape(string_mapped,(1,len(string_mapped), 1))\n",
        "    x = x / float(len(characters))\n",
        "\n",
        "    pred_index = np.argmax(model.predict(x, verbose=0))\n",
        "    seq = [n_to_char[value] for value in string_mapped]\n",
        "    full_string.append(n_to_char[pred_index])\n",
        "\n",
        "    string_mapped.append(pred_index)\n",
        "    string_mapped = string_mapped[1:len(string_mapped)]"
      ],
      "metadata": {
        "id": "fhbAJ0SKVhgV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#combining text\n",
        "txt=\"\"\n",
        "for char in full_string:\n",
        "    txt = txt+char\n",
        "txt"
      ],
      "metadata": {
        "id": "sKnyQaYeVhgc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "b47fd665-2ab5-48e6-a824-acf267b63e3a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "' take this country \\nand turn it from a place \\nto a home that greets you \\nwith smiles on every face \\n                                                                                                                                                                                                                                                                                                                                                                                                                '"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "verse1 = txt.split('\\n')\n",
        "print('Verse 1: ')\n",
        "for _ in verse1: print(_)"
      ],
      "metadata": {
        "id": "xC3wtZ8sVhgd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9671e108-6d7a-4fa9-d14f-7f1228dfaa60"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Verse 1: \n",
            " take this country \n",
            "and turn it from a place \n",
            "to a home that greets you \n",
            "with smiles on every face \n",
            "                                                                                                                                                                                                                                                                                                                                                                                                                \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "string_mapped2 = X[4000] #random\n",
        "full_string2 = [n_to_char[value] for value in string_mapped2]\n",
        "# generating characters\n",
        "for i in range(400):\n",
        "    x = np.reshape(string_mapped2,(1,len(string_mapped2), 1))\n",
        "    x = x / float(len(characters))\n",
        "\n",
        "    pred_index2 = np.argmax(model.predict(x, verbose=0))\n",
        "    seq = [n_to_char[value] for value in string_mapped2]\n",
        "    full_string.append(n_to_char[pred_index2])\n",
        "\n",
        "    string_mapped2.append(pred_index2)\n",
        "    string_mapped2 = string_mapped[1:len(string_mapped2)]"
      ],
      "metadata": {
        "id": "XzhvO4pDEP5Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#combining text\n",
        "txt=\"\"\n",
        "for char in full_string2:\n",
        "    txt = txt+char\n",
        "txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "abe80c99-60b7-45e5-e895-ab61d82e4ca0",
        "id": "pAcc6HDiEP5Z"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"way \\nwhat a great divine blessing \\nthat our nation's still progressing \\nwe're singing songs of our b\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "verse2 = txt.split('\\n')\n",
        "print('Verse 2: ')\n",
        "for _ in verse2: print(_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "118e90cd-02fb-4016-bd60-9b1b2a5611cc",
        "id": "YwaTeNpkEP5a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Verse 2: \n",
            "way \n",
            "what a great divine blessing \n",
            "that our nation's still progressing \n",
            "we're singing songs of our b\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Experiment 2"
      ],
      "metadata": {
        "id": "-gh9g6jzbCH_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "model.add(GRU(400, input_shape=(X_modified.shape[1], X_modified.shape[2]), return_sequences=True))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(GRU(400, return_sequences=True))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(GRU(400))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(Y_modified.shape[1], activation='softmax'))\n",
        "\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam')"
      ],
      "metadata": {
        "id": "7plZ0xaoUmlR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(X_modified, Y_modified, epochs=100, batch_size=64)\n",
        "model.save_weights('GRU_text_generator_100.h5')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PH7j9viLsrip",
        "outputId": "a99a53b5-df65-4412-debd-a7f84012cc39"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "364/364 [==============================] - 24s 44ms/step - loss: 2.7983\n",
            "Epoch 2/100\n",
            "364/364 [==============================] - 16s 44ms/step - loss: 2.5842\n",
            "Epoch 3/100\n",
            "364/364 [==============================] - 16s 45ms/step - loss: 2.4444\n",
            "Epoch 4/100\n",
            "364/364 [==============================] - 17s 46ms/step - loss: 2.2782\n",
            "Epoch 5/100\n",
            "364/364 [==============================] - 17s 47ms/step - loss: 2.1207\n",
            "Epoch 6/100\n",
            "364/364 [==============================] - 18s 49ms/step - loss: 1.9541\n",
            "Epoch 7/100\n",
            "364/364 [==============================] - 18s 49ms/step - loss: 1.7823\n",
            "Epoch 8/100\n",
            "364/364 [==============================] - 18s 48ms/step - loss: 1.6232\n",
            "Epoch 9/100\n",
            "364/364 [==============================] - 17s 48ms/step - loss: 1.4433\n",
            "Epoch 10/100\n",
            "364/364 [==============================] - 17s 48ms/step - loss: 1.2870\n",
            "Epoch 11/100\n",
            "364/364 [==============================] - 18s 48ms/step - loss: 1.1422\n",
            "Epoch 12/100\n",
            "364/364 [==============================] - 18s 49ms/step - loss: 1.0144\n",
            "Epoch 13/100\n",
            "364/364 [==============================] - 18s 48ms/step - loss: 0.9017\n",
            "Epoch 14/100\n",
            "364/364 [==============================] - 18s 48ms/step - loss: 0.7979\n",
            "Epoch 15/100\n",
            "364/364 [==============================] - 18s 48ms/step - loss: 0.7147\n",
            "Epoch 16/100\n",
            "364/364 [==============================] - 18s 48ms/step - loss: 0.6396\n",
            "Epoch 17/100\n",
            "364/364 [==============================] - 18s 48ms/step - loss: 0.5852\n",
            "Epoch 18/100\n",
            "364/364 [==============================] - 18s 48ms/step - loss: 0.5227\n",
            "Epoch 19/100\n",
            "364/364 [==============================] - 18s 48ms/step - loss: 0.4816\n",
            "Epoch 20/100\n",
            "364/364 [==============================] - 18s 48ms/step - loss: 0.4288\n",
            "Epoch 21/100\n",
            "364/364 [==============================] - 18s 48ms/step - loss: 0.4128\n",
            "Epoch 22/100\n",
            "364/364 [==============================] - 18s 48ms/step - loss: 0.3814\n",
            "Epoch 23/100\n",
            "364/364 [==============================] - 18s 48ms/step - loss: 0.3687\n",
            "Epoch 24/100\n",
            "364/364 [==============================] - 18s 48ms/step - loss: 0.3450\n",
            "Epoch 25/100\n",
            "364/364 [==============================] - 18s 48ms/step - loss: 0.3367\n",
            "Epoch 26/100\n",
            "364/364 [==============================] - 18s 48ms/step - loss: 0.3270\n",
            "Epoch 27/100\n",
            "364/364 [==============================] - 18s 48ms/step - loss: 0.3069\n",
            "Epoch 28/100\n",
            "364/364 [==============================] - 18s 48ms/step - loss: 0.3059\n",
            "Epoch 29/100\n",
            "364/364 [==============================] - 18s 49ms/step - loss: 0.3054\n",
            "Epoch 30/100\n",
            "364/364 [==============================] - 18s 48ms/step - loss: 0.3053\n",
            "Epoch 31/100\n",
            "364/364 [==============================] - 18s 48ms/step - loss: 0.2855\n",
            "Epoch 32/100\n",
            "364/364 [==============================] - 18s 48ms/step - loss: 0.2869\n",
            "Epoch 33/100\n",
            "364/364 [==============================] - 18s 48ms/step - loss: 0.2844\n",
            "Epoch 34/100\n",
            "364/364 [==============================] - 18s 49ms/step - loss: 0.2845\n",
            "Epoch 35/100\n",
            "364/364 [==============================] - 18s 49ms/step - loss: 0.2675\n",
            "Epoch 36/100\n",
            "364/364 [==============================] - 18s 49ms/step - loss: 0.2658\n",
            "Epoch 37/100\n",
            "364/364 [==============================] - 18s 49ms/step - loss: 0.2537\n",
            "Epoch 38/100\n",
            "364/364 [==============================] - 18s 49ms/step - loss: 0.2700\n",
            "Epoch 39/100\n",
            "364/364 [==============================] - 18s 48ms/step - loss: 0.2829\n",
            "Epoch 40/100\n",
            "364/364 [==============================] - 18s 48ms/step - loss: 0.2535\n",
            "Epoch 41/100\n",
            "364/364 [==============================] - 18s 48ms/step - loss: 0.2779\n",
            "Epoch 42/100\n",
            "364/364 [==============================] - 18s 48ms/step - loss: 0.2795\n",
            "Epoch 43/100\n",
            "364/364 [==============================] - 18s 48ms/step - loss: 0.2624\n",
            "Epoch 44/100\n",
            "364/364 [==============================] - 18s 49ms/step - loss: 0.2443\n",
            "Epoch 45/100\n",
            "364/364 [==============================] - 18s 48ms/step - loss: 0.2768\n",
            "Epoch 46/100\n",
            "364/364 [==============================] - 18s 49ms/step - loss: 0.3316\n",
            "Epoch 47/100\n",
            "364/364 [==============================] - 18s 48ms/step - loss: 0.3411\n",
            "Epoch 48/100\n",
            "364/364 [==============================] - 18s 48ms/step - loss: 0.3058\n",
            "Epoch 49/100\n",
            "364/364 [==============================] - 18s 48ms/step - loss: 0.2832\n",
            "Epoch 50/100\n",
            "364/364 [==============================] - 18s 48ms/step - loss: 0.2868\n",
            "Epoch 51/100\n",
            "364/364 [==============================] - 18s 48ms/step - loss: 0.3211\n",
            "Epoch 52/100\n",
            "364/364 [==============================] - 18s 48ms/step - loss: 0.3356\n",
            "Epoch 53/100\n",
            "364/364 [==============================] - 18s 48ms/step - loss: 0.2973\n",
            "Epoch 54/100\n",
            "364/364 [==============================] - 18s 48ms/step - loss: 0.3168\n",
            "Epoch 55/100\n",
            "364/364 [==============================] - 18s 49ms/step - loss: 0.3900\n",
            "Epoch 56/100\n",
            "364/364 [==============================] - 18s 48ms/step - loss: 0.4320\n",
            "Epoch 57/100\n",
            "364/364 [==============================] - 18s 48ms/step - loss: 0.3457\n",
            "Epoch 58/100\n",
            "364/364 [==============================] - 18s 48ms/step - loss: 0.3146\n",
            "Epoch 59/100\n",
            "364/364 [==============================] - 18s 48ms/step - loss: 0.3152\n",
            "Epoch 60/100\n",
            "364/364 [==============================] - 18s 48ms/step - loss: 0.4228\n",
            "Epoch 61/100\n",
            "364/364 [==============================] - 18s 48ms/step - loss: 1.7503\n",
            "Epoch 62/100\n",
            "364/364 [==============================] - 18s 48ms/step - loss: 4.0751\n",
            "Epoch 63/100\n",
            "364/364 [==============================] - 18s 49ms/step - loss: 3.4591\n",
            "Epoch 64/100\n",
            "364/364 [==============================] - 18s 49ms/step - loss: 2.9894\n",
            "Epoch 65/100\n",
            "364/364 [==============================] - 18s 48ms/step - loss: 2.6237\n",
            "Epoch 66/100\n",
            "364/364 [==============================] - 18s 49ms/step - loss: 2.1175\n",
            "Epoch 67/100\n",
            "364/364 [==============================] - 18s 49ms/step - loss: 1.8009\n",
            "Epoch 68/100\n",
            "364/364 [==============================] - 18s 49ms/step - loss: 1.8736\n",
            "Epoch 69/100\n",
            "364/364 [==============================] - 18s 48ms/step - loss: 3.2229\n",
            "Epoch 70/100\n",
            "364/364 [==============================] - 18s 48ms/step - loss: 2.8618\n",
            "Epoch 71/100\n",
            "364/364 [==============================] - 18s 49ms/step - loss: 2.5460\n",
            "Epoch 72/100\n",
            "364/364 [==============================] - 18s 49ms/step - loss: 2.2860\n",
            "Epoch 73/100\n",
            "364/364 [==============================] - 18s 49ms/step - loss: 1.9091\n",
            "Epoch 74/100\n",
            "364/364 [==============================] - 18s 49ms/step - loss: 2.1223\n",
            "Epoch 75/100\n",
            "364/364 [==============================] - 18s 48ms/step - loss: 2.3841\n",
            "Epoch 76/100\n",
            "364/364 [==============================] - 18s 49ms/step - loss: 1.9481\n",
            "Epoch 77/100\n",
            "364/364 [==============================] - 18s 48ms/step - loss: 2.0378\n",
            "Epoch 78/100\n",
            "364/364 [==============================] - 18s 48ms/step - loss: 2.9131\n",
            "Epoch 79/100\n",
            "364/364 [==============================] - 18s 48ms/step - loss: 2.8542\n",
            "Epoch 80/100\n",
            "364/364 [==============================] - 18s 48ms/step - loss: 2.7388\n",
            "Epoch 81/100\n",
            "364/364 [==============================] - 18s 49ms/step - loss: 2.6614\n",
            "Epoch 82/100\n",
            "364/364 [==============================] - 18s 48ms/step - loss: 2.6031\n",
            "Epoch 83/100\n",
            "364/364 [==============================] - 18s 49ms/step - loss: 2.5350\n",
            "Epoch 84/100\n",
            "364/364 [==============================] - 18s 48ms/step - loss: 2.4969\n",
            "Epoch 85/100\n",
            "364/364 [==============================] - 18s 48ms/step - loss: 2.4496\n",
            "Epoch 86/100\n",
            "364/364 [==============================] - 18s 48ms/step - loss: 2.4052\n",
            "Epoch 87/100\n",
            "364/364 [==============================] - 18s 48ms/step - loss: 2.3618\n",
            "Epoch 88/100\n",
            "364/364 [==============================] - 18s 48ms/step - loss: 2.3181\n",
            "Epoch 89/100\n",
            "364/364 [==============================] - 18s 49ms/step - loss: 2.2727\n",
            "Epoch 90/100\n",
            "364/364 [==============================] - 18s 48ms/step - loss: 2.2411\n",
            "Epoch 91/100\n",
            "364/364 [==============================] - 18s 49ms/step - loss: 2.2095\n",
            "Epoch 92/100\n",
            "364/364 [==============================] - 18s 49ms/step - loss: 2.1584\n",
            "Epoch 93/100\n",
            "364/364 [==============================] - 18s 48ms/step - loss: 2.1196\n",
            "Epoch 94/100\n",
            "364/364 [==============================] - 18s 48ms/step - loss: 2.0911\n",
            "Epoch 95/100\n",
            "364/364 [==============================] - 18s 49ms/step - loss: 2.0495\n",
            "Epoch 96/100\n",
            "364/364 [==============================] - 18s 48ms/step - loss: 2.0022\n",
            "Epoch 97/100\n",
            "364/364 [==============================] - 18s 48ms/step - loss: 1.9652\n",
            "Epoch 98/100\n",
            "364/364 [==============================] - 18s 48ms/step - loss: 1.9287\n",
            "Epoch 99/100\n",
            "364/364 [==============================] - 18s 48ms/step - loss: 1.8864\n",
            "Epoch 100/100\n",
            "364/364 [==============================] - 18s 48ms/step - loss: 1.8600\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.load_weights('GRU_text_generator_100.h5')"
      ],
      "metadata": {
        "id": "pSsvs3TJ400N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "string_mapped = X[99]\n",
        "full_string = [n_to_char[value] for value in string_mapped]\n",
        "# generating characters\n",
        "for i in range(400):\n",
        "    x = np.reshape(string_mapped,(1,len(string_mapped), 1))\n",
        "    x = x / float(len(characters))\n",
        "\n",
        "    pred_index = np.argmax(model.predict(x, verbose=0))\n",
        "    seq = [n_to_char[value] for value in string_mapped]\n",
        "    full_string.append(n_to_char[pred_index])\n",
        "\n",
        "    string_mapped.append(pred_index)\n",
        "    string_mapped = string_mapped[1:len(string_mapped)]"
      ],
      "metadata": {
        "id": "16hf1xdtsrgW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#combining text\n",
        "txt=\"\"\n",
        "for char in full_string:\n",
        "    txt = txt+char\n",
        "txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "id": "E6I3DXHTsrdy",
        "outputId": "88b6ea35-1a85-4cc2-dbe3-0f816d81424b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"\\nwill you take this country \\nand turn it from a place \\nto a home that greets you \\nwith smiles on every \\nwe can pace areac areacan pur fand \\nthere's a pac pace pur for the same \\nwe ll ae wart for \\nwe ll wa can to the streams \\nthere s a pame \\nwe lave aod fore \\nwhere to the make \\nwe can to the streams and free \\nwe can are mane and fand \\nwe ll wa can to facr \\nthe tame that we can a wa whll for the streams \\nwe can are camiere \\nwe can the streams and wou \\nthere s a pan pake and wa are aream ariln \\nwhe\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "verse1 = txt.split('\\n')\n",
        "for _ in verse1: print(_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cJEiZCKWRQWz",
        "outputId": "d78e78f6-10d4-43b3-ed39-0185ee2b5987"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "will you take this country \n",
            "and turn it from a place \n",
            "to a home that greets you \n",
            "with smiles on every \n",
            "we can pace areac areacan pur fand \n",
            "there's a pac pace pur for the same \n",
            "we ll ae wart for \n",
            "we ll wa can to the streams \n",
            "there s a pame \n",
            "we lave aod fore \n",
            "where to the make \n",
            "we can to the streams and free \n",
            "we can are mane and fand \n",
            "we ll wa can to facr \n",
            "the tame that we can a wa whll for the streams \n",
            "we can are camiere \n",
            "we can the streams and wou \n",
            "there s a pan pake and wa are aream ariln \n",
            "whe\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "End of experiment"
      ],
      "metadata": {
        "id": "Sw4rwtXC2-3K"
      }
    }
  ]
}