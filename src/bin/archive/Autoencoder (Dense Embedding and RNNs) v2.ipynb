{"cells":[{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')\n","%cd /content/drive/MyDrive/SMU_MITB_NLP/Group Project/NLP-Lyric-Generator/src/bin"],"metadata":{"id":"1sqwH29gCCae","colab":{"base_uri":"https://localhost:8080/"},"outputId":"981a9ceb-ca94-4caf-a6e0-93d7a8ba5af6","executionInfo":{"status":"ok","timestamp":1654785415278,"user_tz":-480,"elapsed":2540,"user":{"displayName":"QUEK HAO YONG, GABRIEL _","userId":"08861584446371432378"}}},"id":"1sqwH29gCCae","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n","/content/drive/MyDrive/SMU_MITB_NLP/Group Project/NLP-Lyric-Generator/src/bin\n"]}]},{"cell_type":"code","execution_count":null,"id":"eed94d9c","metadata":{"id":"eed94d9c"},"outputs":[],"source":["### Standard Imports\n","import numpy as np\n","import re\n","import sys\n","from collections import Counter\n","\n","import tensorflow as tf\n","from tensorflow.keras import layers"]},{"cell_type":"code","execution_count":null,"id":"18f77d0b","metadata":{"id":"18f77d0b"},"outputs":[],"source":["### Custom Imports\n","sys.path.append('../')\n","import lib.utilities as utils"]},{"cell_type":"code","source":["### Text Parameters\n","start_token = '<cls>'\n","end_token = '<eos>'\n","pad_token = '<pad>'\n","\n","### Model Parameters\n","window_len = 15\n","batch_size = 64\n","embedding_dim = 128\n","rnn_dim = 256\n","learn_rate = 0.001\n","epochs = 30"],"metadata":{"id":"QsvWeCUNxSvd"},"id":"QsvWeCUNxSvd","execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"id":"e1f082fd","metadata":{"id":"e1f082fd"},"outputs":[],"source":["### Load Data\n","corpus = utils.load_corpus()"]},{"cell_type":"code","execution_count":null,"id":"52adf0e5","metadata":{"scrolled":true,"id":"52adf0e5"},"outputs":[],"source":["### Pre-Processing Text\n","words = utils.preprocess_text(corpus, fun_list = [utils.to_lower, utils.decontraction, utils.remove_punct], keep = '\\<|\\>')\n","words = re.sub('\\n',' \\n ', words)\n","words = re.split(' +', words) #Tokenising\n","\n","word_count = Counter(words) # Assumes end_token is already in the corpus\n","word_count[start_token] = 0\n","word_count[pad_token] = 0\n","\n","#Reference Dictionaries to convert one-hot index to string and vice versa\n","index_to_vocab = {i: k for i, k in enumerate(word_count.keys())}\n","vocab_to_index = {k: i for i, k in enumerate(word_count.keys())}\n","\n","songs = ' '.join(words)\n","songs = songs.split(' \\n \\n <eos> \\n \\n ')\n","songs = [song.split(' ') for song in songs]\n","songs = [[pad_token]*(window_len-1) + [start_token] + song + [end_token] + [pad_token]*(window_len-1) for song in songs]\n","songs_token_ind = [[vocab_to_index.get(x) for x in song] for song in songs]"]},{"cell_type":"code","source":["### Creating Dataset\n","x_encoder = []\n","x_decoder = []\n","y = []\n","vocab_size = len(word_count)\n","\n","for song in songs_token_ind:\n","  for i in range(len(song)-window_len):\n","    x_encoder.append(song[(i+1):(i+window_len+1)])\n","    x_decoder.append(song[i:(i+window_len)])\n","    y.append(song[i+window_len])"],"metadata":{"id":"FwuVvlRF-cgL"},"id":"FwuVvlRF-cgL","execution_count":null,"outputs":[]},{"cell_type":"code","source":["# rand_int = np.random.randint(0, len(x_encoder), 1)[0]\n","# print([index_to_vocab.get(x) for x in x_encoder[rand_int]])\n","# print([index_to_vocab.get(x) for x in x_decoder[rand_int]])\n","# print(index_to_vocab.get(y[rand_int]))"],"metadata":{"id":"F19kB2eQfd7M"},"id":"F19kB2eQfd7M","execution_count":null,"outputs":[]},{"cell_type":"code","source":["dataset = tf.data.Dataset.from_tensor_slices(((x_encoder, x_decoder), y))\n","dataset = dataset.batch(batch_size)\n","dataset = dataset.cache().prefetch(buffer_size=tf.data.AUTOTUNE)"],"metadata":{"id":"Dk3I2VI1Nza3"},"id":"Dk3I2VI1Nza3","execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"id":"202bf8be","metadata":{"id":"202bf8be","colab":{"base_uri":"https://localhost:8080/"},"outputId":"a51a99a6-0c31-4848-8892-33b8dabe1299","executionInfo":{"status":"ok","timestamp":1654785421292,"user_tz":-480,"elapsed":9,"user":{"displayName":"QUEK HAO YONG, GABRIEL _","userId":"08861584446371432378"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"autoencoder\"\n","__________________________________________________________________________________________________\n"," Layer (type)                   Output Shape         Param #     Connected to                     \n","==================================================================================================\n"," encoder_input (InputLayer)     [(None, 15)]         0           []                               \n","                                                                                                  \n"," decoder_input (InputLayer)     [(None, 15)]         0           []                               \n","                                                                                                  \n"," encoder_embedding (Embedding)  (None, 15, 128)      134272      ['encoder_input[0][0]']          \n","                                                                                                  \n"," decoder_embedding (Embedding)  (None, 15, 128)      134272      ['decoder_input[0][0]']          \n","                                                                                                  \n"," encoder_rnn (SimpleRNN)        [(None, 256),        98560       ['encoder_embedding[0][0]']      \n","                                 (None, 256)]                                                     \n","                                                                                                  \n"," decoder_rnn (SimpleRNN)        (None, 256)          98560       ['decoder_embedding[0][0]',      \n","                                                                  'encoder_rnn[0][1]']            \n","                                                                                                  \n"," output (Dense)                 (None, 1049)         269593      ['decoder_rnn[0][0]']            \n","                                                                                                  \n","==================================================================================================\n","Total params: 735,257\n","Trainable params: 735,257\n","Non-trainable params: 0\n","__________________________________________________________________________________________________\n"]}],"source":["# Encoder\n","encoder_input = layers.Input(shape=(window_len), name = 'encoder_input')\n","encoder_embedded = layers.Embedding(input_dim=vocab_size, output_dim=embedding_dim, input_length = window_len, name = 'encoder_embedding')(\n","    encoder_input\n",")\n","\n","# Return state in addition to output\n","encoder_output, encoder_state = layers.SimpleRNN(rnn_dim, return_state=True, name = \"encoder_rnn\")(\n","    encoder_embedded\n",")\n","\n","# Decoder\n","decoder_input = layers.Input(shape=(window_len), name = 'decoder_input')\n","decoder_embedded = layers.Embedding(input_dim=vocab_size, output_dim=embedding_dim, input_length = window_len, name = 'decoder_embedding')(\n","    decoder_input\n",")\n","\n","# Pass the encoder state to a new RNN, as initial state\n","decoder_output = layers.SimpleRNN(rnn_dim, name=\"decoder_rnn\")(\n","    decoder_embedded, initial_state=[encoder_state]\n",")\n","output = layers.Dense(vocab_size, name = 'output', activation = 'softmax')(decoder_output)\n","\n","model = tf.keras.Model((encoder_input, decoder_input), output, name = 'autoencoder')\n","model.summary()"]},{"cell_type":"code","execution_count":null,"id":"83bb01d4","metadata":{"id":"83bb01d4"},"outputs":[],"source":["model.compile(loss = 'sparse_categorical_crossentropy', optimizer = tf.keras.optimizers.Adam(learning_rate=learn_rate))"]},{"cell_type":"code","source":["result = model.fit(x = dataset, epochs = epochs, shuffle = True)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hIOwUeQ0E0LD","outputId":"528f26e7-9fa1-40ee-c34e-13ca5f263c55","executionInfo":{"status":"ok","timestamp":1654785694091,"user_tz":-480,"elapsed":272802,"user":{"displayName":"QUEK HAO YONG, GABRIEL _","userId":"08861584446371432378"}}},"id":"hIOwUeQ0E0LD","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/30\n","226/226 [==============================] - 15s 50ms/step - loss: 4.3260\n","Epoch 2/30\n","226/226 [==============================] - 7s 29ms/step - loss: 2.8950\n","Epoch 3/30\n","226/226 [==============================] - 7s 29ms/step - loss: 2.1413\n","Epoch 4/30\n","226/226 [==============================] - 7s 29ms/step - loss: 1.7846\n","Epoch 5/30\n","226/226 [==============================] - 7s 30ms/step - loss: 1.5383\n","Epoch 6/30\n","226/226 [==============================] - 7s 30ms/step - loss: 1.2804\n","Epoch 7/30\n","226/226 [==============================] - 7s 30ms/step - loss: 1.1500\n","Epoch 8/30\n","226/226 [==============================] - 7s 30ms/step - loss: 0.9224\n","Epoch 9/30\n","226/226 [==============================] - 7s 29ms/step - loss: 0.8420\n","Epoch 10/30\n","226/226 [==============================] - 7s 29ms/step - loss: 0.7114\n","Epoch 11/30\n","226/226 [==============================] - 7s 30ms/step - loss: 0.6677\n","Epoch 12/30\n","226/226 [==============================] - 7s 29ms/step - loss: 0.7429\n","Epoch 13/30\n","226/226 [==============================] - 7s 29ms/step - loss: 0.6745\n","Epoch 14/30\n","226/226 [==============================] - 7s 30ms/step - loss: 0.9337\n","Epoch 15/30\n","226/226 [==============================] - 7s 29ms/step - loss: 0.6095\n","Epoch 16/30\n","226/226 [==============================] - 7s 29ms/step - loss: 0.3605\n","Epoch 17/30\n","226/226 [==============================] - 7s 30ms/step - loss: 0.2526\n","Epoch 18/30\n","226/226 [==============================] - 7s 29ms/step - loss: 0.2339\n","Epoch 19/30\n","226/226 [==============================] - 7s 30ms/step - loss: 0.2461\n","Epoch 20/30\n","226/226 [==============================] - 7s 30ms/step - loss: 0.2125\n","Epoch 21/30\n","226/226 [==============================] - 7s 29ms/step - loss: 0.1752\n","Epoch 22/30\n","226/226 [==============================] - 7s 29ms/step - loss: 0.1162\n","Epoch 23/30\n","226/226 [==============================] - 7s 32ms/step - loss: 0.0881\n","Epoch 24/30\n","226/226 [==============================] - 7s 29ms/step - loss: 0.0725\n","Epoch 25/30\n","226/226 [==============================] - 7s 30ms/step - loss: 0.1957\n","Epoch 26/30\n","226/226 [==============================] - 7s 29ms/step - loss: 0.1721\n","Epoch 27/30\n","226/226 [==============================] - 7s 29ms/step - loss: 0.1541\n","Epoch 28/30\n","226/226 [==============================] - 7s 30ms/step - loss: 0.0850\n","Epoch 29/30\n","226/226 [==============================] - 7s 31ms/step - loss: 0.0923\n","Epoch 30/30\n","226/226 [==============================] - 7s 30ms/step - loss: 0.1042\n"]}]},{"cell_type":"code","source":["def generate_text(model, start_string, num_generate = 1000, temperature=1.0, random_seed = 2022):\n","    # Converting our start string to numbers (vectorizing).\n","    input_indices = [vocab_to_index.get(s) for i, s in enumerate(start_string) if i < window_len-1]\n","    input_indices = [vocab_to_index.get(pad_token)]*(window_len - len(input_indices)-1) + [vocab_to_index.get(start_token)] + input_indices\n","\n","    x = tf.expand_dims(input_indices, 0)\n","\n","    # Empty string to store our results.\n","    text_generated = []\n","\n","    # Here batch size == 1.\n","    model.reset_states()\n","    for word_index in range(num_generate):\n","        prediction = model.predict([x,x])\n","\n","        # Using a categorical distribution to predict the character returned by the model.\n","        prediction = prediction / temperature\n","        predicted_id = tf.random.categorical(prediction, num_samples=1, seed = random_seed)[-1,0]\n","        \n","        # We pass the series of previous words (up to window length) as the next input to the model\n","        # along with the previous hidden state.\n","        input_index = tf.cast(tf.expand_dims([predicted_id], 0), tf.int32)\n","        x = tf.concat([x[:,1:],input_index], 1)\n","        \n","        pred_word = index_to_vocab[predicted_id.numpy()]\n","        text_generated.append(pred_word)\n","        if pred_word == end_token:\n","          break\n","    \n","    return (' '.join(start_string) + ' ' + ' '.join(text_generated)), text_generated"],"metadata":{"id":"_ANJJNQGSpdx"},"id":"_ANJJNQGSpdx","execution_count":null,"outputs":[]},{"cell_type":"code","source":["result_str, result = generate_text(model, start_string=['<verse>','\\n','step','by','step'], num_generate=30, temperature=1.0)"],"metadata":{"id":"wo0aCkdPL2EU"},"id":"wo0aCkdPL2EU","execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(result_str)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"smPNycjBnDXa","executionInfo":{"status":"ok","timestamp":1654785696174,"user_tz":-480,"elapsed":4,"user":{"displayName":"QUEK HAO YONG, GABRIEL _","userId":"08861584446371432378"}},"outputId":"ffb1a2b3-b69f-4a97-c3b2-67878023eb43"},"id":"smPNycjBnDXa","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["<verse> \n"," step by step by look wind lift unfurled progress inspiration yea going towards said prove memory feel my twinkling hands cairo four homely shore not dawns seem generation summing cooking in real guess\n"]}]},{"cell_type":"code","source":[""],"metadata":{"id":"PgGgpFvaxDuL"},"id":"PgGgpFvaxDuL","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.8"},"colab":{"name":"Autoencoder (Dense Embedding and RNNs) v2.ipynb","provenance":[{"file_id":"1hJxsyDevUcXdH0dW7L12n1Kt2maU_3BM","timestamp":1654812153906},{"file_id":"1s0I-h_H-57P4mfHpn7K9ARRffBzA2996","timestamp":1654783928696},{"file_id":"1fSgHJcraq0bKZQlGXUqlQ4abpWOsgdIu","timestamp":1654782642697},{"file_id":"1_pyvxTi14GzEPtSGxMTy55XDNlCfsK0h","timestamp":1654781952290},{"file_id":"164GHOXuG8X-6WN_mbIfShYez3xOdSrkL","timestamp":1654771075102}],"collapsed_sections":[]},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":5}