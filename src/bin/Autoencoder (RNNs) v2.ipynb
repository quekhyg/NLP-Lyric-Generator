{"cells":[{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')\n","%cd /content/drive/MyDrive/SMU_MITB_NLP/Group Project/NLP-Lyric-Generator/src/bin"],"metadata":{"id":"1sqwH29gCCae","colab":{"base_uri":"https://localhost:8080/"},"outputId":"45eabfcd-802a-4fa2-d294-a7ef97d2326c","executionInfo":{"status":"ok","timestamp":1654811398331,"user_tz":-480,"elapsed":48175,"user":{"displayName":"QUEK HAO YONG, GABRIEL _","userId":"08861584446371432378"}}},"id":"1sqwH29gCCae","execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n","/content/drive/MyDrive/SMU_MITB_NLP/Group Project/NLP-Lyric-Generator/src/bin\n"]}]},{"cell_type":"code","execution_count":2,"id":"eed94d9c","metadata":{"id":"eed94d9c","executionInfo":{"status":"ok","timestamp":1654811401024,"user_tz":-480,"elapsed":2697,"user":{"displayName":"QUEK HAO YONG, GABRIEL _","userId":"08861584446371432378"}}},"outputs":[],"source":["### Standard Imports\n","import numpy as np\n","import re\n","import sys\n","from collections import Counter\n","\n","import tensorflow as tf\n","from tensorflow.keras import layers"]},{"cell_type":"code","execution_count":3,"id":"18f77d0b","metadata":{"id":"18f77d0b","executionInfo":{"status":"ok","timestamp":1654811401600,"user_tz":-480,"elapsed":579,"user":{"displayName":"QUEK HAO YONG, GABRIEL _","userId":"08861584446371432378"}}},"outputs":[],"source":["### Custom Imports\n","sys.path.append('../')\n","import lib.utilities as utils"]},{"cell_type":"code","source":["### Text Parameters\n","start_token = '<cls>'\n","end_token = '<eos>'\n","pad_token = '<pad>'\n","\n","### Model Parameters\n","window_len = 15\n","batch_size = 64\n","rnn_dim = 256\n","learn_rate = 0.001\n","epochs = 30\n","dropout = 0.1\n","recurrent_dropout = 0.1"],"metadata":{"id":"QsvWeCUNxSvd","executionInfo":{"status":"ok","timestamp":1654811401600,"user_tz":-480,"elapsed":2,"user":{"displayName":"QUEK HAO YONG, GABRIEL _","userId":"08861584446371432378"}}},"id":"QsvWeCUNxSvd","execution_count":4,"outputs":[]},{"cell_type":"code","execution_count":5,"id":"e1f082fd","metadata":{"id":"e1f082fd","executionInfo":{"status":"ok","timestamp":1654811411963,"user_tz":-480,"elapsed":10365,"user":{"displayName":"QUEK HAO YONG, GABRIEL _","userId":"08861584446371432378"}}},"outputs":[],"source":["### Load Data\n","corpus = utils.load_corpus()"]},{"cell_type":"code","execution_count":6,"id":"52adf0e5","metadata":{"scrolled":true,"id":"52adf0e5","executionInfo":{"status":"ok","timestamp":1654811411964,"user_tz":-480,"elapsed":5,"user":{"displayName":"QUEK HAO YONG, GABRIEL _","userId":"08861584446371432378"}}},"outputs":[],"source":["### Pre-Processing Text\n","words = utils.preprocess_text(corpus, fun_list = [utils.to_lower, utils.decontraction, utils.remove_punct], keep = '\\<|\\>')\n","words = re.sub('\\n',' \\n ', words)\n","words = re.split(' +', words) #Tokenising\n","\n","word_count = Counter(words) # Assumes end_token is already in the corpus\n","word_count[start_token] = 0\n","word_count[pad_token] = 0\n","\n","#Reference Dictionaries to convert one-hot index to string and vice versa\n","index_to_vocab = {i: k for i, k in enumerate(word_count.keys())}\n","vocab_to_index = {k: i for i, k in enumerate(word_count.keys())}\n","\n","songs = ' '.join(words)\n","songs = songs.split(' \\n \\n <eos> \\n \\n ')\n","songs = [song.split(' ') for song in songs]\n","songs = [[pad_token]*(window_len-1) + [start_token] + song + [end_token] + [pad_token]*(window_len-1) for song in songs]\n","songs_token_ind = [[vocab_to_index.get(x) for x in song] for song in songs]"]},{"cell_type":"code","source":["### Creating Dataset\n","x_encoder = []\n","x_decoder = []\n","y = []\n","vocab_size = len(word_count)\n","\n","for song in songs_token_ind:\n","  for i in range(len(song)-window_len):\n","    x_encoder.append(song[(i+1):(i+window_len+1)])\n","    x_decoder.append(song[i:(i+window_len)])\n","    y.append(song[i+window_len])"],"metadata":{"id":"FwuVvlRF-cgL","executionInfo":{"status":"ok","timestamp":1654812020217,"user_tz":-480,"elapsed":493,"user":{"displayName":"QUEK HAO YONG, GABRIEL _","userId":"08861584446371432378"}}},"id":"FwuVvlRF-cgL","execution_count":35,"outputs":[]},{"cell_type":"code","source":["# rand_int = np.random.randint(0, len(x_encoder), 1)[0]\n","# print([index_to_vocab.get(x) for x in x_encoder[rand_int]])\n","# print([index_to_vocab.get(x) for x in x_decoder[rand_int]])\n","# print(index_to_vocab.get(y[rand_int]))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"KY-CHZ0CcP2C","executionInfo":{"status":"ok","timestamp":1654812092253,"user_tz":-480,"elapsed":3,"user":{"displayName":"QUEK HAO YONG, GABRIEL _","userId":"08861584446371432378"}},"outputId":"0d6a4156-1bb5-4f7f-af20-873bb19e597b"},"id":"KY-CHZ0CcP2C","execution_count":39,"outputs":[{"output_type":"stream","name":"stdout","text":["['the', 'best', 'is', 'yet', 'to', 'come', '\\n', '\\n', '<chorus>', '\\n', 'oh', 'oh', 'oh', 'oh', 'oh']\n","['cos', 'the', 'best', 'is', 'yet', 'to', 'come', '\\n', '\\n', '<chorus>', '\\n', 'oh', 'oh', 'oh', 'oh']\n","oh\n"]}]},{"cell_type":"code","source":["dataset = tf.data.Dataset.from_tensor_slices(((x_encoder, x_decoder), y))\n","dataset = dataset.batch(batch_size)\n","dataset = dataset.map(lambda x, y: ((tf.one_hot(x[0], depth = vocab_size), tf.one_hot(x[1], depth = vocab_size)),\n","                                 tf.one_hot(y, depth = vocab_size)))\n","dataset = dataset.cache().prefetch(buffer_size=tf.data.AUTOTUNE)"],"metadata":{"id":"Dk3I2VI1Nza3","executionInfo":{"status":"ok","timestamp":1654812107620,"user_tz":-480,"elapsed":1348,"user":{"displayName":"QUEK HAO YONG, GABRIEL _","userId":"08861584446371432378"}}},"id":"Dk3I2VI1Nza3","execution_count":40,"outputs":[]},{"cell_type":"code","execution_count":41,"id":"202bf8be","metadata":{"id":"202bf8be","colab":{"base_uri":"https://localhost:8080/"},"outputId":"a73017c2-b047-41c1-9b36-9d6fcc4fa9a4","executionInfo":{"status":"ok","timestamp":1654812107621,"user_tz":-480,"elapsed":7,"user":{"displayName":"QUEK HAO YONG, GABRIEL _","userId":"08861584446371432378"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"model_1\"\n","__________________________________________________________________________________________________\n"," Layer (type)                   Output Shape         Param #     Connected to                     \n","==================================================================================================\n"," encoder_input (InputLayer)     [(None, 15, 1049)]   0           []                               \n","                                                                                                  \n"," decoder_input (InputLayer)     [(None, 15, 1049)]   0           []                               \n","                                                                                                  \n"," encoder_rnn (SimpleRNN)        [(None, 256),        334336      ['encoder_input[0][0]']          \n","                                 (None, 256)]                                                     \n","                                                                                                  \n"," decoder_rnn (SimpleRNN)        (None, 256)          334336      ['decoder_input[0][0]',          \n","                                                                  'encoder_rnn[0][1]']            \n","                                                                                                  \n"," output (Dense)                 (None, 1049)         269593      ['decoder_rnn[0][0]']            \n","                                                                                                  \n","==================================================================================================\n","Total params: 938,265\n","Trainable params: 938,265\n","Non-trainable params: 0\n","__________________________________________________________________________________________________\n"]}],"source":["# Encoder\n","encoder_input = layers.Input(shape=(window_len,vocab_size), name = 'encoder_input')\n","\n","# Return state in addition to output\n","encoder_output, encoder_state = layers.SimpleRNN(rnn_dim, dropout = dropout, recurrent_dropout = recurrent_dropout, return_state=True, name = \"encoder_rnn\")(\n","    encoder_input\n",")\n","\n","# Decoder\n","decoder_input = layers.Input(shape=(window_len,vocab_size), name = 'decoder_input')\n","\n","# Pass the encoder state to a new RNN, as initial state\n","decoder_output = layers.SimpleRNN(rnn_dim, dropout = dropout, recurrent_dropout = recurrent_dropout, name=\"decoder_rnn\")(\n","    decoder_input, initial_state=[encoder_state]\n",")\n","output = layers.Dense(vocab_size, name = 'output', activation = 'softmax')(decoder_output)\n","\n","model = tf.keras.Model((encoder_input, decoder_input), output)\n","model.summary()"]},{"cell_type":"code","execution_count":42,"id":"83bb01d4","metadata":{"id":"83bb01d4","executionInfo":{"status":"ok","timestamp":1654812107621,"user_tz":-480,"elapsed":3,"user":{"displayName":"QUEK HAO YONG, GABRIEL _","userId":"08861584446371432378"}}},"outputs":[],"source":["model.compile(loss = 'categorical_crossentropy', optimizer = tf.keras.optimizers.Adam(learning_rate=learn_rate))"]},{"cell_type":"code","source":["result = model.fit(x = dataset, epochs = epochs, shuffle = True)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hIOwUeQ0E0LD","outputId":"a7673d70-85fb-4ebe-cac5-f3d3664085f7","executionInfo":{"status":"ok","timestamp":1654812385302,"user_tz":-480,"elapsed":276378,"user":{"displayName":"QUEK HAO YONG, GABRIEL _","userId":"08861584446371432378"}}},"id":"hIOwUeQ0E0LD","execution_count":43,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/30\n","226/226 [==============================] - 12s 45ms/step - loss: 5.2550\n","Epoch 2/30\n","226/226 [==============================] - 8s 36ms/step - loss: 4.6934\n","Epoch 3/30\n","226/226 [==============================] - 8s 36ms/step - loss: 4.4714\n","Epoch 4/30\n","226/226 [==============================] - 9s 38ms/step - loss: 4.2863\n","Epoch 5/30\n","226/226 [==============================] - 8s 36ms/step - loss: 4.0975\n","Epoch 6/30\n","226/226 [==============================] - 8s 36ms/step - loss: 3.9229\n","Epoch 7/30\n","226/226 [==============================] - 8s 37ms/step - loss: 3.7583\n","Epoch 8/30\n","226/226 [==============================] - 8s 37ms/step - loss: 3.5975\n","Epoch 9/30\n","226/226 [==============================] - 8s 36ms/step - loss: 3.4269\n","Epoch 10/30\n","226/226 [==============================] - 9s 39ms/step - loss: 3.2973\n","Epoch 11/30\n","226/226 [==============================] - 8s 37ms/step - loss: 3.0929\n","Epoch 12/30\n","226/226 [==============================] - 8s 37ms/step - loss: 2.9301\n","Epoch 13/30\n","226/226 [==============================] - 8s 37ms/step - loss: 2.7407\n","Epoch 14/30\n","226/226 [==============================] - 8s 36ms/step - loss: 2.5765\n","Epoch 15/30\n","226/226 [==============================] - 8s 36ms/step - loss: 2.4290\n","Epoch 16/30\n","226/226 [==============================] - 8s 36ms/step - loss: 2.2908\n","Epoch 17/30\n","226/226 [==============================] - 8s 36ms/step - loss: 2.1576\n","Epoch 18/30\n","226/226 [==============================] - 10s 44ms/step - loss: 2.0075\n","Epoch 19/30\n","226/226 [==============================] - 8s 36ms/step - loss: 1.8819\n","Epoch 20/30\n","226/226 [==============================] - 8s 36ms/step - loss: 1.7764\n","Epoch 21/30\n","226/226 [==============================] - 8s 36ms/step - loss: 1.6906\n","Epoch 22/30\n","226/226 [==============================] - 8s 36ms/step - loss: 1.5935\n","Epoch 23/30\n","226/226 [==============================] - 8s 36ms/step - loss: 1.5011\n","Epoch 24/30\n","226/226 [==============================] - 8s 35ms/step - loss: 1.4339\n","Epoch 25/30\n","226/226 [==============================] - 8s 36ms/step - loss: 1.3934\n","Epoch 26/30\n","226/226 [==============================] - 8s 36ms/step - loss: 1.3106\n","Epoch 27/30\n","226/226 [==============================] - 8s 36ms/step - loss: 1.2688\n","Epoch 28/30\n","226/226 [==============================] - 8s 36ms/step - loss: 1.2111\n","Epoch 29/30\n","226/226 [==============================] - 8s 36ms/step - loss: 1.1483\n","Epoch 30/30\n","226/226 [==============================] - 8s 36ms/step - loss: 1.1046\n"]}]},{"cell_type":"code","source":["def generate_text(model, start_string, num_generate = 1000, temperature=1.0, random_seed = 2022):\n","    # Converting our start string to numbers (vectorizing).\n","    input_indices = [vocab_to_index.get(s) for i, s in enumerate(start_string) if i < window_len-1]\n","    input_indices = [vocab_to_index.get(pad_token)]*(window_len - len(input_indices)-1) + [vocab_to_index.get(start_token)] + input_indices\n","\n","    input_oh = tf.one_hot(input_indices, depth = vocab_size)\n","    x = tf.expand_dims(input_oh, 0)\n","\n","    # Empty string to store our results.\n","    text_generated = []\n","\n","    # Here batch size == 1.\n","    model.reset_states()\n","    for word_index in range(num_generate):\n","        prediction = model.predict([x,x])\n","\n","        # Using a categorical distribution to predict the character returned by the model.\n","        prediction = prediction / temperature\n","        predicted_id = tf.random.categorical(prediction, num_samples=1, seed = random_seed)[-1,0]\n","        predicted_oh = tf.one_hot(predicted_id, depth = vocab_size)\n","\n","        # We pass the series of previous words (up to window length) as the next input to the model\n","        # along with the previous hidden state.\n","        input_index = tf.expand_dims([predicted_oh], 0)\n","        x = tf.concat([x[:,1:,:],input_index], 1)\n","        \n","        pred_word = index_to_vocab[predicted_id.numpy()]\n","        text_generated.append(pred_word)\n","        if pred_word == end_token:\n","          break\n","    \n","    return (' '.join(start_string) + ' ' + ' '.join(text_generated)), text_generated"],"metadata":{"id":"_ANJJNQGSpdx","executionInfo":{"status":"ok","timestamp":1654812791960,"user_tz":-480,"elapsed":500,"user":{"displayName":"QUEK HAO YONG, GABRIEL _","userId":"08861584446371432378"}}},"id":"_ANJJNQGSpdx","execution_count":47,"outputs":[]},{"cell_type":"code","source":["result_str, result = generate_text(model, start_string=['<verse>','\\n','step','by','step'], num_generate=50, temperature=1.0)"],"metadata":{"id":"wo0aCkdPL2EU","executionInfo":{"status":"ok","timestamp":1654812794527,"user_tz":-480,"elapsed":2059,"user":{"displayName":"QUEK HAO YONG, GABRIEL _","userId":"08861584446371432378"}}},"id":"wo0aCkdPL2EU","execution_count":48,"outputs":[]},{"cell_type":"code","source":["print(result_str)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"smPNycjBnDXa","executionInfo":{"status":"ok","timestamp":1654812794528,"user_tz":-480,"elapsed":3,"user":{"displayName":"QUEK HAO YONG, GABRIEL _","userId":"08861584446371432378"}},"outputId":"b011ed80-ce94-40f5-a9a6-18debc548e11"},"id":"smPNycjBnDXa","execution_count":49,"outputs":[{"output_type":"stream","name":"stdout","text":["<verse> \n"," step by step stories darkness grateful stepping others win riverside near rainbow road should afar brighter if at peace hoping have yearning singing dawn how bell your beyond name very book grateful for things spot stars rest x fortunate worth catch beauty no stay style looking youth quick cross those late refreshed century\n"]}]},{"cell_type":"code","source":[""],"metadata":{"id":"PgGgpFvaxDuL","executionInfo":{"status":"ok","timestamp":1654811720774,"user_tz":-480,"elapsed":6,"user":{"displayName":"QUEK HAO YONG, GABRIEL _","userId":"08861584446371432378"}}},"id":"PgGgpFvaxDuL","execution_count":14,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.8"},"colab":{"name":"Autoencoder (RNNs) v2.ipynb","provenance":[{"file_id":"1s0I-h_H-57P4mfHpn7K9ARRffBzA2996","timestamp":1654811271378},{"file_id":"1fSgHJcraq0bKZQlGXUqlQ4abpWOsgdIu","timestamp":1654782642697},{"file_id":"1_pyvxTi14GzEPtSGxMTy55XDNlCfsK0h","timestamp":1654781952290},{"file_id":"164GHOXuG8X-6WN_mbIfShYez3xOdSrkL","timestamp":1654771075102}],"collapsed_sections":[]},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":5}