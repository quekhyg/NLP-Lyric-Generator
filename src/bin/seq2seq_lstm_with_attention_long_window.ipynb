{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1sqwH29gCCae",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1sqwH29gCCae",
        "outputId": "f92c2b22-32f8-43a4-8e61-a13b19d1363b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "/content/drive/MyDrive/SMU_MITB_NLP/Group Project/NLP-Lyric-Generator/src/bin\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "%cd /content/drive/MyDrive/SMU_MITB_NLP/Group Project/NLP-Lyric-Generator/src/bin"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "eed94d9c",
      "metadata": {
        "id": "eed94d9c"
      },
      "outputs": [],
      "source": [
        "### Standard Imports\n",
        "import numpy as np\n",
        "import re\n",
        "import sys\n",
        "import os\n",
        "from collections import Counter\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "18f77d0b",
      "metadata": {
        "id": "18f77d0b"
      },
      "outputs": [],
      "source": [
        "### Custom Imports\n",
        "sys.path.append('../')\n",
        "import lib.utilities as utils\n",
        "import lib.seq2seq_utilities as s2s_utils"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "QsvWeCUNxSvd",
      "metadata": {
        "id": "QsvWeCUNxSvd"
      },
      "outputs": [],
      "source": [
        "### Text Parameters\n",
        "start_token = '<cls>'\n",
        "end_token = '<eos>'\n",
        "pad_token = '<pad>'\n",
        "unk_token = '<unk>'\n",
        "newline_token = '<new>'\n",
        "mask_token = '<mask>'\n",
        "\n",
        "### General Parameters\n",
        "random_seed = 2022\n",
        "model_folder = '../../../seq2seq/lstm/v3'\n",
        "model_name = 's2s_lstm_att_long_win'\n",
        "\n",
        "### Model Parameters\n",
        "window_len = 50\n",
        "batch_size = 64\n",
        "enc_dim, dec_dim = 256, 256\n",
        "learn_rate = 0.001\n",
        "epochs = 50\n",
        "dropout = 0.05\n",
        "recurrent_dropout = 0.05"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "zy-R6jQR4Ozz",
      "metadata": {
        "id": "zy-R6jQR4Ozz"
      },
      "outputs": [],
      "source": [
        "os.makedirs(model_folder, exist_ok=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e1f082fd",
      "metadata": {
        "id": "e1f082fd"
      },
      "outputs": [],
      "source": [
        "### Load Data\n",
        "corpus = utils.load_corpus()\n",
        "train_corpus, val_corpus, train_files, val_files = utils.split_corpus()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "52adf0e5",
      "metadata": {
        "id": "52adf0e5",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "### Pre-Processing Text\n",
        "_, word_count, index_to_vocab, vocab_to_index, songs, songs_token_ind = utils.tokenize_corpus(corpus,\n",
        "                                                                            window_length = window_len,\n",
        "                                                                            end_token = end_token,\n",
        "                                                                            start_token = start_token,\n",
        "                                                                            pad_token = pad_token,\n",
        "                                                                            unk_token = unk_token,\n",
        "                                                                            newline_token = newline_token,\n",
        "                                                                            mask_token = mask_token)\n",
        "vocab_size = len(word_count)\n",
        "\n",
        "train_words, _, _, _, train_songs, train_songs_token_ind = utils.tokenize_corpus(train_corpus,\n",
        "                                                                       window_length = window_len,\n",
        "                                                                       index_to_vocab = index_to_vocab,\n",
        "                                                                       vocab_to_index = vocab_to_index,\n",
        "                                                                       end_token = end_token,\n",
        "                                                                       start_token = start_token,\n",
        "                                                                       pad_token = pad_token,\n",
        "                                                                       unk_token = unk_token,\n",
        "                                                                       newline_token = newline_token,\n",
        "                                                                       mask_token = mask_token)\n",
        "\n",
        "val_words, _, _, _, _, val_songs_token_ind = utils.tokenize_corpus(val_corpus,\n",
        "                                                           window_length = window_len,\n",
        "                                                           index_to_vocab = index_to_vocab,\n",
        "                                                           vocab_to_index = vocab_to_index,\n",
        "                                                           end_token = end_token,\n",
        "                                                           start_token = start_token,\n",
        "                                                           pad_token = pad_token,\n",
        "                                                           unk_token = unk_token,\n",
        "                                                           newline_token = newline_token,\n",
        "                                                           mask_token = mask_token)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cb1a6431",
      "metadata": {
        "id": "cb1a6431"
      },
      "outputs": [],
      "source": [
        "train_x, train_y = s2s_utils.construct_seq_data(train_songs_token_ind, window_len)\n",
        "val_x, val_y = s2s_utils.construct_seq_data(val_songs_token_ind, window_len)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "KY-CHZ0CcP2C",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KY-CHZ0CcP2C",
        "outputId": "f3a1454f-3b64-4843-9d90-1bd2f819b6ec"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['good', 'we', 'achieve', 'as', 'one', 'nation', '<new>', 'be', 'shared', 'with', 'the', 'world', '<new>', '<new>', '<verse>', '<new>', 'as', 'a', 'new', 'chapter', 'begins', '<new>', 'from', 'where', 'we', 'have', 'come', 'thus', 'far', '<new>', 'once', 'again', 'may', 'it', 'be', 'written', '<new>', 'you', 'are', 'who', 'we', 'are', '<new>', '<new>', '<verse>', '<new>', 'in', 'you', 'may', 'we']\n",
            "see\n",
            "['will', 'all', 'come', 'true', '<new>', 'if', 'you', 'believe', 'that', 'every', 'vision', 'begins', 'with', 'you', '<new>', '<new>', '<chorus>', '<new>', 'shine', 'for', 'singapore', '<new>', 'this', 'is', 'your', 'song', '<new>', 'deep', 'inside', 'your', 'heart', 'where', 'it', 'belongs', '<new>', 'it', 'will', 'always', 'stay', 'strive', 'for', 'your', 'goals', '<new>', 'you', 'will', 'achieve', 'with', 'visions', 'so']\n",
            "bold\n"
          ]
        }
      ],
      "source": [
        "rand_int = np.random.randint(0, len(train_x), 1)[0]\n",
        "print([index_to_vocab.get(x) for x in train_x[rand_int]])\n",
        "print(index_to_vocab.get(train_y[rand_int]))\n",
        "\n",
        "rand_int = np.random.randint(0, len(val_x), 1)[0]\n",
        "print([index_to_vocab.get(x) for x in val_x[rand_int]])\n",
        "print(index_to_vocab.get(val_y[rand_int]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "Dk3I2VI1Nza3",
      "metadata": {
        "id": "Dk3I2VI1Nza3"
      },
      "outputs": [],
      "source": [
        "train_dataset = s2s_utils.construct_datasets(train_x, train_y,\n",
        "                                            random_seed = random_seed,\n",
        "                                            batch_size = batch_size,\n",
        "                                            vocab_size = vocab_size)\n",
        "val_dataset = s2s_utils.construct_datasets(val_x, val_y,\n",
        "                                            random_seed = random_seed,\n",
        "                                            batch_size = batch_size,\n",
        "                                            vocab_size = vocab_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "202bf8be",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "202bf8be",
        "outputId": "847f49cb-6a48-41a4-ab60-173b34ac0610"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:Layer encoder_lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer decoder_lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "Model: \"s2s_lstm_att_long_win\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " encoder_input (InputLayer)     [(None, 50, 1042)]   0           []                               \n",
            "                                                                                                  \n",
            " decoder_input (InputLayer)     [(None, 50, 1042)]   0           []                               \n",
            "                                                                                                  \n",
            " encoder_lstm (LSTM)            [(None, 256),        1330176     ['encoder_input[0][0]']          \n",
            "                                 (None, 256),                                                     \n",
            "                                 (None, 256)]                                                     \n",
            "                                                                                                  \n",
            " decoder_lstm (LSTM)            (None, 256)          1330176     ['decoder_input[0][0]',          \n",
            "                                                                  'encoder_lstm[0][1]',           \n",
            "                                                                  'encoder_lstm[0][2]']           \n",
            "                                                                                                  \n",
            " attention (Attention)          (None, 256)          0           ['decoder_lstm[0][0]',           \n",
            "                                                                  'encoder_lstm[0][0]']           \n",
            "                                                                                                  \n",
            " tf.concat (TFOpLambda)         (None, 512)          0           ['decoder_lstm[0][0]',           \n",
            "                                                                  'attention[0][0]']              \n",
            "                                                                                                  \n",
            " output (Dense)                 (None, 1042)         534546      ['tf.concat[0][0]']              \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 3,194,898\n",
            "Trainable params: 3,194,898\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "# Encoder\n",
        "encoder_input = layers.Input(shape=(window_len,vocab_size), name = 'encoder_input')\n",
        "\n",
        "# Return state in addition to output\n",
        "encoder_output, encoder_hidden_state, encoder_cell_state = layers.LSTM(enc_dim,\n",
        "                                                                       dropout = dropout, recurrent_dropout = recurrent_dropout,\n",
        "                                                                       return_state=True, name = \"encoder_lstm\")(encoder_input)\n",
        "\n",
        "# Decoder\n",
        "decoder_input = layers.Input(shape=(window_len,vocab_size), name = 'decoder_input')\n",
        "\n",
        "# Pass the encoder state to a new LSTM, as initial state\n",
        "decoder_output = layers.LSTM(dec_dim,\n",
        "                             dropout = dropout, recurrent_dropout = recurrent_dropout,\n",
        "                             name=\"decoder_lstm\")(decoder_input, initial_state=[encoder_hidden_state, encoder_cell_state])\n",
        "\n",
        "# Attention\n",
        "attention_context_vector = tf.keras.layers.Attention(name = 'attention')(inputs = [decoder_output, encoder_output])\n",
        "\n",
        "# Output\n",
        "output = layers.Dense(vocab_size, name = 'output', activation = 'softmax')(tf.concat([decoder_output, attention_context_vector], 1))\n",
        "\n",
        "model = tf.keras.Model((encoder_input, decoder_input), output, name = model_name)\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "83bb01d4",
      "metadata": {
        "id": "83bb01d4"
      },
      "outputs": [],
      "source": [
        "model.compile(loss = 'categorical_crossentropy',\n",
        "              optimizer = tf.keras.optimizers.Adam(learning_rate=learn_rate),\n",
        "              metrics = ['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "oxvZ57pCIWWu",
      "metadata": {
        "id": "oxvZ57pCIWWu"
      },
      "outputs": [],
      "source": [
        "### Callbacks\n",
        "callback_es = tf.keras.callbacks.EarlyStopping(\n",
        "    monitor='val_loss',\n",
        "    min_delta=0,\n",
        "    patience=10,\n",
        "    verbose=1,\n",
        "    mode='min',\n",
        "    baseline=None,\n",
        "    restore_best_weights=True\n",
        ")\n",
        "\n",
        "callback_mc = tf.keras.callbacks.ModelCheckpoint(\n",
        "    filepath=model_folder+'/weights.{epoch:02d}-{val_loss:.2f}-{val_accuracy:.2f}.hdf5',\n",
        "    save_weights_only=True,\n",
        "    monitor='val_loss',\n",
        "    mode='min',\n",
        "    save_best_only=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "hIOwUeQ0E0LD",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hIOwUeQ0E0LD",
        "outputId": "e580cf7b-1083-4770-a415-b9dff33caecd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "202/202 [==============================] - 92s 423ms/step - loss: 4.5803 - accuracy: 0.2626 - val_loss: 4.5183 - val_accuracy: 0.2706\n",
            "Epoch 2/50\n",
            "202/202 [==============================] - 73s 364ms/step - loss: 4.0752 - accuracy: 0.3087 - val_loss: 4.4859 - val_accuracy: 0.2801\n",
            "Epoch 3/50\n",
            "202/202 [==============================] - 72s 357ms/step - loss: 3.8007 - accuracy: 0.3226 - val_loss: 4.4281 - val_accuracy: 0.3021\n",
            "Epoch 4/50\n",
            "202/202 [==============================] - 74s 367ms/step - loss: 3.4856 - accuracy: 0.3546 - val_loss: 4.2827 - val_accuracy: 0.3161\n",
            "Epoch 5/50\n",
            "202/202 [==============================] - 72s 357ms/step - loss: 3.0772 - accuracy: 0.3999 - val_loss: 4.1362 - val_accuracy: 0.3290\n",
            "Epoch 6/50\n",
            "202/202 [==============================] - 72s 358ms/step - loss: 2.6927 - accuracy: 0.4436 - val_loss: 4.4924 - val_accuracy: 0.3134\n",
            "Epoch 7/50\n",
            "202/202 [==============================] - 74s 366ms/step - loss: 2.3723 - accuracy: 0.4853 - val_loss: 4.7687 - val_accuracy: 0.2975\n",
            "Epoch 8/50\n",
            "202/202 [==============================] - 71s 353ms/step - loss: 2.0940 - accuracy: 0.5324 - val_loss: 4.8698 - val_accuracy: 0.2963\n",
            "Epoch 9/50\n",
            "202/202 [==============================] - 72s 358ms/step - loss: 1.8626 - accuracy: 0.5714 - val_loss: 4.9695 - val_accuracy: 0.3021\n",
            "Epoch 10/50\n",
            "202/202 [==============================] - 72s 356ms/step - loss: 1.6428 - accuracy: 0.6157 - val_loss: 4.7732 - val_accuracy: 0.3161\n",
            "Epoch 11/50\n",
            "202/202 [==============================] - 71s 352ms/step - loss: 1.4607 - accuracy: 0.6488 - val_loss: 4.7965 - val_accuracy: 0.3262\n",
            "Epoch 12/50\n",
            "202/202 [==============================] - 73s 359ms/step - loss: 1.2723 - accuracy: 0.6930 - val_loss: 5.0722 - val_accuracy: 0.3204\n",
            "Epoch 13/50\n",
            "202/202 [==============================] - 71s 350ms/step - loss: 1.1106 - accuracy: 0.7374 - val_loss: 5.1785 - val_accuracy: 0.3122\n",
            "Epoch 14/50\n",
            "202/202 [==============================] - 72s 359ms/step - loss: 1.0077 - accuracy: 0.7552 - val_loss: 5.0953 - val_accuracy: 0.3265\n",
            "Epoch 15/50\n",
            "202/202 [==============================] - ETA: 0s - loss: 0.9511 - accuracy: 0.7708Restoring model weights from the end of the best epoch: 5.\n",
            "202/202 [==============================] - 71s 351ms/step - loss: 0.9511 - accuracy: 0.7708 - val_loss: 4.9889 - val_accuracy: 0.3290\n",
            "Epoch 15: early stopping\n"
          ]
        }
      ],
      "source": [
        "history = model.fit(x = train_dataset, validation_data = val_dataset, epochs = epochs, callbacks = [callback_es, callback_mc])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "QhFHlI6o06Gz",
      "metadata": {
        "id": "QhFHlI6o06Gz"
      },
      "outputs": [],
      "source": [
        "model.save_weights(f'{model_folder}/final_weights.hdf5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ljTcusxBWCjT",
      "metadata": {
        "id": "ljTcusxBWCjT"
      },
      "outputs": [],
      "source": [
        "# model.load_weights(f'{model_folder}/final_weights.hdf5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "wo0aCkdPL2EU",
      "metadata": {
        "id": "wo0aCkdPL2EU"
      },
      "outputs": [],
      "source": [
        "prompts = ['Whenever I think back', 'And so this I know',\n",
        "           'I am tired of being what you want me to be', 'Feeling so faithless, lost under the surface',\n",
        "           'Relight our fire, we will find our way', 'We will rise stronger together']\n",
        "result_strings = {}\n",
        "results = {}\n",
        "for prompt in prompts:\n",
        "    result_str, result = utils.generate_text(model,\n",
        "                                             s2s_utils.ind_to_input_fun, s2s_utils.update_input_fun,\n",
        "                                             start_string = prompt,\n",
        "                                             window_length = window_len,\n",
        "                                             vocab_to_index_dict = vocab_to_index, index_to_vocab_dict = index_to_vocab,\n",
        "                                             vocab_size = vocab_size,\n",
        "                                             num_generate = 100, temperature = 1.0,\n",
        "                                             random_seed = random_seed,\n",
        "                                             end_token = end_token, start_token = start_token,\n",
        "                                             pad_token = pad_token, unk_token = unk_token,\n",
        "                                             newline_token = newline_token,\n",
        "                                             depth = vocab_size)\n",
        "    result_strings[prompt] = result_str\n",
        "    results[prompt] = result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "smPNycjBnDXa",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "smPNycjBnDXa",
        "outputId": "ddfedd57-8b43-464f-fa07-00131db1426b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'Whenever I think back': 'Whenever I think back \\n look a of unfurled \\n <verse> \\n <chorus> \\n said special struggled singapore \\n we will do uphold \\n \\n not our stronger the stand the in \\n till \\n one out \\n stand \\n now her did sing \\n <others> the world world \\n first is her to be here waiting \\n make i is there aside be \\n it is where a grow \\n to already must \\n lost necessary favourite way your love up to may be \\n stars heart we the singaporean dating soul \\n working will forever as we smile \\n alright together brave', 'And so this I know': 'And so this I know winding for from \\n much for see \\n \\n to enemies we see as together \\n then \\n but you you i \\n as see \\n a you strong there higher \\n who a who grown story \\n <verse> \\n this a out my the leaving tell were is worlds \\n i set one you will will <verse> \\n neighbourhood whole moments it wildest into asking remembered \\n name <chorus> \\n put our mind light your all the \\n to we make they goal \\n as as one up the goal \\n the way share \\n my it \\n <bridge>', 'I am tired of being what you want me to be': 'I am tired of being what you want me to be \\n as singing achieve a that singapore \\n we hold run do like rainbow in to streams shining one nation one \\n will in the \\n and as will regardless stars \\n call race we you there \\n become progress say \\n not for there \\n our it now things here bravely \\n <chorus> grateful \\n all win special \\n your welcome seems \\n we will the always be \\n to this is common light world teacher \\n it a challenge day memories \\n kept one there pretty is everyone memories \\n it made us a wind safe we stars', 'Feeling so faithless, lost under the surface': 'Feeling so faithless, lost under the surface all of more \\n we all can can \\n will here time melody \\n faces a done still up \\n our defend \\n singaporean \\n we tourists stand \\n at nation wonder moment everyone \\n \\n we do be tell we can show we are \\n many one favourite \\n \\n in like the things singapore \\n everyone who to always a to care \\n <verse> \\n means must to mind learn be \\n part race where it is its it \\n help to who be \\n let thankful say mind is our move our \\n put moments we are', 'Relight our fire, we will find our way': 'Relight our fire, we will find our way so pretty red \\n others for to but \\n road a come how if at weathers make have bang and help how \\n your beyond as shining care \\n for \\n lighting a so now now from time make no to be perfect someday \\n hands times up stirred that belong too where million me \\n shining want the comfort to the colour cannot corner pride \\n soul love hour friends my my \\n tiny', 'We will rise stronger together': 'We will rise stronger together \\n help sing this people never together \\n <verse> \\n stand hear is belong \\n our make working as story am place we will build come'}\n"
          ]
        }
      ],
      "source": [
        "print(result_strings)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "PgGgpFvaxDuL",
      "metadata": {
        "id": "PgGgpFvaxDuL"
      },
      "outputs": [],
      "source": [
        "for k, v in result_strings.items():\n",
        "    with open(model_folder+f'/human_{model_name}-{utils.remove_punct(k.lower())}.txt', 'w') as f:\n",
        "        f.write(v)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c2762801",
      "metadata": {
        "id": "c2762801"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "with open('../../output/prompt_ref.json', 'r') as f:\n",
        "    eval_prompts = json.load(f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b4930fe9",
      "metadata": {
        "id": "b4930fe9"
      },
      "outputs": [],
      "source": [
        "result_strings = {}\n",
        "for prompt, actual in eval_prompts.items():\n",
        "    result_str, _ = utils.generate_text(model,\n",
        "                                             s2s_utils.ind_to_input_fun, s2s_utils.update_input_fun,\n",
        "                                             start_string = prompt,\n",
        "                                             window_length = window_len,\n",
        "                                             vocab_to_index_dict = vocab_to_index, index_to_vocab_dict = index_to_vocab,\n",
        "                                             vocab_size = vocab_size,\n",
        "                                             num_generate = 100, temperature = 1.0,\n",
        "                                             random_seed = random_seed,\n",
        "                                             end_token = end_token, start_token = start_token,\n",
        "                                             pad_token = pad_token, unk_token = unk_token,\n",
        "                                             newline_token = newline_token,\n",
        "                                             discard_repeat = False,\n",
        "                                             depth = vocab_size)\n",
        "    result_strings[prompt] = result_str.replace(newline_token, '\\n')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "400dbddc",
      "metadata": {
        "id": "400dbddc"
      },
      "outputs": [],
      "source": [
        "for k, v in result_strings.items():\n",
        "    with open(model_folder+f'/br_{model_name}-{utils.remove_punct(k.lower())}.txt', 'w') as f:\n",
        "        f.write(v)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "Yaerg8RO8F6J"
      },
      "id": "Yaerg8RO8F6J",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "seq2seq_lstm_with_attention_long_window.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}