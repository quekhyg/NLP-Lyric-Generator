{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"AI Generated Music","provenance":[{"file_id":"https://github.com/SMarioMan/jukebox/blob/master/jukebox/Interacting_with_Jukebox.ipynb","timestamp":1654091384367}],"collapsed_sections":[],"machine_shape":"hm"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"uq8uLwZCn0BV"},"source":["IMPORTANT NOTE ON SYSTEM REQUIREMENTS:\n","\n","If you are connecting to a hosted runtime - run !nvidia-smi to confirm. \n","\n","Colab may first assign you a lower memory machine like a Tesla T4 GPU if you are using a hosted runtime.  If so, the first time you try to load the 5B model, it will run out of memory, and then you'll be prompted to restart with more memory (then return to the top of this Colab).  \n","\n","If you continue to have memory issues after this (or run into issues on your own home setup), switch to the 1B model.\n","\n","If you are using a local GPU, we recommend V100 or P100 with 16GB GPU memory for best performance. For GPU’s with less memory, we recommend using the 1B model and a smaller batch size throughout.  "]},{"cell_type":"code","metadata":{"id":"8qEqdj8u0gdN","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1654218270334,"user_tz":-480,"elapsed":1269,"user":{"displayName":"titus lim","userId":"15988225439622456165"}},"outputId":"cf3bc7fe-8efa-4599-a67d-a0baf6c44d31"},"source":["!nvidia-smi -L"],"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["GPU 0: Tesla P100-PCIE-16GB (UUID: GPU-065a23d2-ee5a-51c9-65e9-0b1fa3d0cb45)\n"]}]},{"cell_type":"markdown","source":["Check against this image (you need a P100 GPU to run the best models [5b, 5b_lyrics], otherwise you can only run the 1b model series).\n","\n","![image.png](data:image/png;base64,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)"],"metadata":{"id":"vPFkY8CrXmlh"}},{"cell_type":"markdown","metadata":{"id":"VAMZK4GNA_PM"},"source":["Mount Google Drive to save sample levels as they are generated."]},{"cell_type":"code","metadata":{"id":"ZPdMgaH_BPGN","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1654218301950,"user_tz":-480,"elapsed":22610,"user":{"displayName":"titus lim","userId":"15988225439622456165"}},"outputId":"c2df80a8-80b5-4f5b-f2c8-d47a6bbd9112"},"source":["from google.colab import drive\n","drive.mount('/content/drive')\n","%cd /content/drive/MyDrive/Colab Notebooks/SMU_MITB_NLP/NLP project/"],"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n","/content/drive/.shortcut-targets-by-id/1MmY0pN1b5xL_C2CijM9ImcFM-UFt4bwr/NLP project\n"]}]},{"cell_type":"markdown","metadata":{"id":"Zy4Rehq9ZKv_"},"source":["Prepare the environment."]},{"cell_type":"code","metadata":{"id":"sAdFGF-bqVMY","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1654218382654,"user_tz":-480,"elapsed":56776,"user":{"displayName":"titus lim","userId":"15988225439622456165"}},"outputId":"dd7fdbf6-8eb0-411c-84c6-213cfdf4cd23"},"source":["!pip install git+https://github.com/openai/jukebox.git"],"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting git+https://github.com/openai/jukebox.git\n","  Cloning https://github.com/openai/jukebox.git to /tmp/pip-req-build-lyhfbev3\n","  Running command git clone -q https://github.com/openai/jukebox.git /tmp/pip-req-build-lyhfbev3\n","Collecting fire==0.1.3\n","  Downloading fire-0.1.3.tar.gz (33 kB)\n","Collecting tqdm==4.45.0\n","  Downloading tqdm-4.45.0-py2.py3-none-any.whl (60 kB)\n","\u001b[K     |████████████████████████████████| 60 kB 7.7 MB/s \n","\u001b[?25hRequirement already satisfied: soundfile==0.10.3.post1 in /usr/local/lib/python3.7/dist-packages (from jukebox==1.0) (0.10.3.post1)\n","Collecting unidecode==1.1.1\n","  Downloading Unidecode-1.1.1-py2.py3-none-any.whl (238 kB)\n","\u001b[K     |████████████████████████████████| 238 kB 40.5 MB/s \n","\u001b[?25hCollecting numba==0.48.0\n","  Downloading numba-0.48.0-1-cp37-cp37m-manylinux2014_x86_64.whl (3.5 MB)\n","\u001b[K     |████████████████████████████████| 3.5 MB 79.9 MB/s \n","\u001b[?25hCollecting librosa==0.7.2\n","  Downloading librosa-0.7.2.tar.gz (1.6 MB)\n","\u001b[K     |████████████████████████████████| 1.6 MB 80.2 MB/s \n","\u001b[?25hCollecting mpi4py>=3.0.0\n","  Downloading mpi4py-3.1.3.tar.gz (2.5 MB)\n","\u001b[K     |████████████████████████████████| 2.5 MB 66.5 MB/s \n","\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n","  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n","    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from fire==0.1.3->jukebox==1.0) (1.15.0)\n","Requirement already satisfied: audioread>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from librosa==0.7.2->jukebox==1.0) (2.1.9)\n","Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from librosa==0.7.2->jukebox==1.0) (1.21.6)\n","Requirement already satisfied: scipy>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from librosa==0.7.2->jukebox==1.0) (1.4.1)\n","Requirement already satisfied: scikit-learn!=0.19.0,>=0.14.0 in /usr/local/lib/python3.7/dist-packages (from librosa==0.7.2->jukebox==1.0) (1.0.2)\n","Requirement already satisfied: joblib>=0.12 in /usr/local/lib/python3.7/dist-packages (from librosa==0.7.2->jukebox==1.0) (1.1.0)\n","Requirement already satisfied: decorator>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from librosa==0.7.2->jukebox==1.0) (4.4.2)\n","Requirement already satisfied: resampy>=0.2.2 in /usr/local/lib/python3.7/dist-packages (from librosa==0.7.2->jukebox==1.0) (0.2.2)\n","Collecting llvmlite<0.32.0,>=0.31.0dev0\n","  Downloading llvmlite-0.31.0-cp37-cp37m-manylinux1_x86_64.whl (20.2 MB)\n","\u001b[K     |████████████████████████████████| 20.2 MB 32.7 MB/s \n","\u001b[?25hRequirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from numba==0.48.0->jukebox==1.0) (57.4.0)\n","Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.7/dist-packages (from soundfile==0.10.3.post1->jukebox==1.0) (1.15.0)\n","Requirement already satisfied: pycparser in /usr/local/lib/python3.7/dist-packages (from cffi>=1.0->soundfile==0.10.3.post1->jukebox==1.0) (2.21)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn!=0.19.0,>=0.14.0->librosa==0.7.2->jukebox==1.0) (3.1.0)\n","Building wheels for collected packages: jukebox, fire, librosa, mpi4py\n","  Building wheel for jukebox (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for jukebox: filename=jukebox-1.0-py3-none-any.whl size=197916 sha256=ab332fe52794fdfeaffca174ccc3bbf5b4d686351406a31afab49895a2c95205\n","  Stored in directory: /tmp/pip-ephem-wheel-cache-tomtbij1/wheels/d6/42/39/91f8a32505a445499702ae0f887769e6bb5030c42382d74ae0\n","  Building wheel for fire (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for fire: filename=fire-0.1.3-py2.py3-none-any.whl size=49719 sha256=db00d838b189eab242bedd4ef670b367f78d43bab168b512e9241c08db7e00b2\n","  Stored in directory: /root/.cache/pip/wheels/dd/c5/df/d9bf8223023d31343b65f1cc57d2dc005610ebbcd2b4a5d1e7\n","  Building wheel for librosa (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for librosa: filename=librosa-0.7.2-py3-none-any.whl size=1612902 sha256=0707e49e5be31e54b10c915199aff7a6b6f9fa8b1c2e2b0c8aaf0ca636003985\n","  Stored in directory: /root/.cache/pip/wheels/18/9e/42/3224f85730f92fa2925f0b4fb6ef7f9c5431a64dfc77b95b39\n","  Building wheel for mpi4py (PEP 517) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for mpi4py: filename=mpi4py-3.1.3-cp37-cp37m-linux_x86_64.whl size=2185276 sha256=14c807e93965f9b7c34a1193550c5c6addfb48ca8972377c85f691b19ddf0788\n","  Stored in directory: /root/.cache/pip/wheels/7a/07/14/6a0c63fa2c6e473c6edc40985b7d89f05c61ff25ee7f0ad9ac\n","Successfully built jukebox fire librosa mpi4py\n","Installing collected packages: llvmlite, numba, unidecode, tqdm, mpi4py, librosa, fire, jukebox\n","  Attempting uninstall: llvmlite\n","    Found existing installation: llvmlite 0.34.0\n","    Uninstalling llvmlite-0.34.0:\n","      Successfully uninstalled llvmlite-0.34.0\n","  Attempting uninstall: numba\n","    Found existing installation: numba 0.51.2\n","    Uninstalling numba-0.51.2:\n","      Successfully uninstalled numba-0.51.2\n","  Attempting uninstall: tqdm\n","    Found existing installation: tqdm 4.64.0\n","    Uninstalling tqdm-4.64.0:\n","      Successfully uninstalled tqdm-4.64.0\n","  Attempting uninstall: librosa\n","    Found existing installation: librosa 0.8.1\n","    Uninstalling librosa-0.8.1:\n","      Successfully uninstalled librosa-0.8.1\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","panel 0.12.1 requires tqdm>=4.48.0, but you have tqdm 4.45.0 which is incompatible.\u001b[0m\n","Successfully installed fire-0.1.3 jukebox-1.0 librosa-0.7.2 llvmlite-0.31.0 mpi4py-3.1.3 numba-0.48.0 tqdm-4.45.0 unidecode-1.1.1\n"]}]},{"cell_type":"code","metadata":{"id":"taDHgk1WCC_C","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1654218391441,"user_tz":-480,"elapsed":4219,"user":{"displayName":"titus lim","userId":"15988225439622456165"}},"outputId":"0b7cc000-ec69-41db-be72-d55635356484"},"source":["import jukebox\n","import torch as t\n","import librosa\n","import os\n","from IPython.display import Audio\n","from jukebox.make_models import make_vqvae, make_prior, MODELS, make_model\n","from jukebox.hparams import Hyperparams, setup_hparams\n","from jukebox.sample import sample_single_window, _sample, \\\n","                           sample_partial_window, upsample, \\\n","                           load_prompts\n","from jukebox.utils.dist_utils import setup_dist_from_mpi\n","from jukebox.utils.torch_utils import empty_cache\n","rank, local_rank, device = setup_dist_from_mpi()"],"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["Using cuda True\n"]}]},{"cell_type":"markdown","metadata":{"id":"89FftI5kc-Az"},"source":["# Sample from the 5B or 1B Lyrics Model\n"]},{"cell_type":"markdown","source":["The 5B model is boasts a superior performance to the 1b model, but requires Colab to minimally assign a P100 GPU."],"metadata":{"id":"l-R57my2W-Ef"}},{"cell_type":"code","metadata":{"id":"65aR2OZxmfzq","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1654218539572,"user_tz":-480,"elapsed":126023,"user":{"displayName":"titus lim","userId":"15988225439622456165"}},"outputId":"083c77a1-58cf-47a1-80b7-b8910ef7f4ac"},"source":["model = '5b_lyrics' # or '5b' or '1b', or '1b_lyrics' Depends on the song you want.\n","hps = Hyperparams()\n","hps.sr = 44100\n","hps.n_samples = 3 if model in ('5b', '5b_lyrics') else 8\n","# Specifies the directory to save the sample in.\n","# We set this to the Google Drive mount point.\n","hps.name = '/content/drive/MyDrive/Colab Notebooks/SMU_MITB_NLP/NLP project/Generated Melody/Home_CD_Pop'\n","chunk_size = 16 if model in ('5b', '5b_lyrics') else 32\n","max_batch_size = 3 if model in ('5b', '5b_lyrics') else 16\n","hps.levels = 3\n","hps.hop_fraction = [.5,.5,.125]\n","\n","vqvae, *priors = MODELS[model]\n","vqvae = make_vqvae(setup_hparams(vqvae, dict(sample_length = 1048576)), device)\n","top_prior = make_prior(setup_hparams(priors[-1], dict()), vqvae, device)"],"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading from azure\n","Running  wget -O /root/.cache/jukebox/models/5b/vqvae.pth.tar https://openaipublic.azureedge.net/jukebox/models/5b/vqvae.pth.tar\n","Restored from /root/.cache/jukebox/models/5b/vqvae.pth.tar\n","0: Loading vqvae in eval mode\n","Loading artist IDs from /usr/local/lib/python3.7/dist-packages/jukebox/data/ids/v2_artist_ids.txt\n","Loading artist IDs from /usr/local/lib/python3.7/dist-packages/jukebox/data/ids/v2_genre_ids.txt\n","Level:2, Cond downsample:None, Raw to tokens:128, Sample length:1048576\n","0: Converting to fp16 params\n","Downloading from azure\n","Running  wget -O /root/.cache/jukebox/models/5b_lyrics/prior_level_2.pth.tar https://openaipublic.azureedge.net/jukebox/models/5b_lyrics/prior_level_2.pth.tar\n","Restored from /root/.cache/jukebox/models/5b_lyrics/prior_level_2.pth.tar\n","0: Loading prior in eval mode\n"]}]},{"cell_type":"markdown","metadata":{"id":"rvf-5pnjbmI1"},"source":["# Select mode\n","'Ancestral' mode means that the model generates a new song from scratch. 'Primed' mode continues from an existing song, so you need to supply a .wav file of the song you want to continue from. \n","\n","The results from 'ancestral' mode is random."]},{"cell_type":"code","metadata":{"id":"VVOQ3egdj65y","executionInfo":{"status":"ok","timestamp":1654218547014,"user_tz":-480,"elapsed":299,"user":{"displayName":"titus lim","userId":"15988225439622456165"}}},"source":["# The default mode of operation.\n","# Creates songs based on artist and genre conditioning.\n","mode = 'ancestral'\n","codes_file=None\n","audio_file=None\n","prompt_length_in_seconds=None"],"execution_count":6,"outputs":[]},{"cell_type":"code","metadata":{"id":"Jp7nKnCmk1bx","executionInfo":{"status":"ok","timestamp":1654218550441,"user_tz":-480,"elapsed":3,"user":{"displayName":"titus lim","userId":"15988225439622456165"}}},"source":["sample_hps = Hyperparams(dict(mode=mode, codes_file=codes_file, audio_file=audio_file, prompt_length_in_seconds=prompt_length_in_seconds))"],"execution_count":7,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"JYKiwkzy0Iyf"},"source":["Specify your choice of artist, genre, lyrics, and length of musical sample. \n","\n","IMPORTANT: The sample length is crucial for how long your sample takes to generate. Generating a shorter sample takes less time. You are limited to 12 hours on the Google Colab free tier. A 50 second sample should be short enough to fully generate after 12 hours of processing. "]},{"cell_type":"code","metadata":{"id":"-sY9aGHcZP-u","executionInfo":{"status":"ok","timestamp":1654218604409,"user_tz":-480,"elapsed":375,"user":{"displayName":"titus lim","userId":"15988225439622456165"}}},"source":["sample_length_in_seconds = 50          # Full length of musical sample to generate - we find songs in the 1 to 4 minute\n","                                       # range work well, with generation time proportional to sample length.  \n","                                       # This total length affects how quickly the model \n","                                       # progresses through lyrics (model also generates differently\n","                                       # depending on if it thinks it's in the beginning, middle, or end of sample)\n","hps.sample_length = (int(sample_length_in_seconds*hps.sr)//top_prior.raw_to_tokens)*top_prior.raw_to_tokens\n","assert hps.sample_length >= top_prior.n_ctx*top_prior.raw_to_tokens, f'Please choose a larger sampling rate'"],"execution_count":8,"outputs":[]},{"cell_type":"code","metadata":{"id":"qD0qxQeLaTR0","executionInfo":{"status":"ok","timestamp":1654218611033,"user_tz":-480,"elapsed":349,"user":{"displayName":"titus lim","userId":"15988225439622456165"}}},"source":["# Note: Metas can contain different prompts per sample.\n","# By default, all samples use the same prompt.\n","metas = [dict(artist = \"Céline Dion\",\n","            genre = \"Pop\",\n","            total_length = hps.sample_length,\n","            offset = 0,\n","            lyrics = \"\"\"Whenever I am feeling low\n","I look around me and I know\n","There's a place that will stay within me\n","Wherever I may choose to go\n","I will always recall the city\n","Know every street and shore\n","Sail down that river which brings us life\n","Winding through my Singapore\n","\n","This is home, truly\n","Where I know I must be\n","Where my dreams wait for me\n","Where that river always flows\n","This is home, surely\n","As my senses tell me\n","This is where I won't be alone\n","For this is where I know it's home\n","\n","When there are troubles to go through\n","We'll find a way to start anew\n","There is comfort in the knowledge\n","That home's about its people too\n","So we'll build our dreams together\n","Just like we've done before\n","Just like that river which brings us life\n","There'll always be Singapore\n","\n","This is home, truly\n","Where I know I must be\n","Where my dreams wait for me\n","Where that river always flows\n","This is home, surely\n","As my senses tell me\n","This is where I won't be alone\n","For this is where I know it's home\n","\n","This is home, truly\n","Where I know I must be\n","Where my dreams wait for me\n","Where that river always flows\n","This is home, surely\n","As my senses tell me\n","This is where I won't be alone\n","For this is where I know it's home\n","For this is where I know it's home\n","For this is where I know I'm home\n","\"\"\",\n","            ),\n","          ] * hps.n_samples\n","labels = [None, None, top_prior.labeller.get_batch_labels(metas, 'cuda')]"],"execution_count":9,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"6PHC1XnEfV4Y"},"source":["Optionally adjust the sampling temperature. A value of 1.0 means that you would like the model to stay very close to the exact musical patterns of the artist and the genre. The recommended temperature for novelty is .98 or .99. Alternatively there are some suggested temperatures (https://jukebox.openai.com/) depending on the genre and singer you're using.\n","\n","max_batch_size = 3 means that we're asking the model to generate 3 music samples. We can specify for the model to generate more.\n"]},{"cell_type":"code","metadata":{"id":"eNwKyqYraTR9","executionInfo":{"status":"ok","timestamp":1654218690630,"user_tz":-480,"elapsed":446,"user":{"displayName":"titus lim","userId":"15988225439622456165"}}},"source":["sampling_temperature = .98\n","\n","lower_batch_size = 16\n","max_batch_size = 3 if model in ('5b', '5b_lyrics') else 16\n","lower_level_chunk_size = 32\n","chunk_size = 16 if model in ('5b', '5b_lyrics') else 32\n","sampling_kwargs = [dict(temp=.99, fp16=True, max_batch_size=lower_batch_size,\n","                        chunk_size=lower_level_chunk_size),\n","                    dict(temp=0.99, fp16=True, max_batch_size=lower_batch_size,\n","                         chunk_size=lower_level_chunk_size),\n","                    dict(temp=sampling_temperature, fp16=True, \n","                         max_batch_size=max_batch_size, chunk_size=chunk_size)]"],"execution_count":10,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"S3j0gT3HfrRD"},"source":["Now we're ready to sample from the model. We'll generate the top level (2) first, followed by the first upsampling (level 1), and the second upsampling (0).  In this CoLab we load the top prior separately from the upsamplers, because of memory concerns on the hosted runtimes. If using a local machine, we can also load all models directly with make_models, and then use sample.py's ancestral_sampling to put this all in one step.\n","\n","After each level, we decode to raw audio and save the audio files.   \n","\n","This next cell will take a while (approximately 10 minutes per 20 seconds of music sample)"]},{"cell_type":"code","metadata":{"id":"9a1tlvcVlHhN","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1654221934655,"user_tz":-480,"elapsed":3239105,"user":{"displayName":"titus lim","userId":"15988225439622456165"}},"outputId":"c528bf1a-ea7e-4056-d787-4de255e921d8"},"source":["if sample_hps.mode == 'ancestral':\n","  zs = [t.zeros(hps.n_samples,0,dtype=t.long, device='cuda') for _ in range(len(priors))]\n","  zs = _sample(zs, labels, sampling_kwargs, [None, None, top_prior], [2], hps)\n","elif sample_hps.mode == 'upsample':\n","  assert sample_hps.codes_file is not None\n","  # Load codes.\n","  data = t.load(sample_hps.codes_file, map_location='cpu')\n","  zs = [z.cuda() for z in data['zs']]\n","  assert zs[-1].shape[0] == hps.n_samples, f\"Expected bs = {hps.n_samples}, got {zs[-1].shape[0]}\"\n","  del data\n","  print('Falling through to the upsample step later in the notebook.')\n","elif sample_hps.mode == 'primed':\n","  assert sample_hps.audio_file is not None\n","  audio_files = sample_hps.audio_file.split(',')\n","  duration = (int(sample_hps.prompt_length_in_seconds*hps.sr)//top_prior.raw_to_tokens)*top_prior.raw_to_tokens\n","  x = load_prompts(audio_files, duration, hps)\n","  zs = top_prior.encode(x, start_level=0, end_level=len(priors), bs_chunks=x.shape[0])\n","  zs = _sample(zs, labels, sampling_kwargs, [None, None, top_prior], [2], hps)\n","else:\n","  raise ValueError(f'Unknown sample mode {sample_hps.mode}.')"],"execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["Sampling level 2\n","Sampling 8192 tokens for [0,8192]. Conditioning on 0 tokens\n","Ancestral sampling 3 samples with temp=0.98, top_k=0, top_p=0.0\n","8192/8192 [14:02<00:00,  9.73it/s]\n","Sampling 8192 tokens for [1024,9216]. Conditioning on 7168 tokens\n","Primed sampling 3 samples with temp=0.98, top_k=0, top_p=0.0\n","448/448 [01:37<00:00,  4.62it/s]\n","1024/1024 [02:06<00:00,  8.08it/s]\n","Sampling 8192 tokens for [2048,10240]. Conditioning on 7168 tokens\n","Primed sampling 3 samples with temp=0.98, top_k=0, top_p=0.0\n","448/448 [01:36<00:00,  4.63it/s]\n","1024/1024 [02:07<00:00,  8.06it/s]\n","Sampling 8192 tokens for [3072,11264]. Conditioning on 7168 tokens\n","Primed sampling 3 samples with temp=0.98, top_k=0, top_p=0.0\n","448/448 [01:36<00:00,  4.63it/s]\n","1024/1024 [02:07<00:00,  8.06it/s]\n","Sampling 8192 tokens for [4096,12288]. Conditioning on 7168 tokens\n","Primed sampling 3 samples with temp=0.98, top_k=0, top_p=0.0\n","448/448 [01:36<00:00,  4.63it/s]\n","1024/1024 [02:06<00:00,  8.06it/s]\n","Sampling 8192 tokens for [5120,13312]. Conditioning on 7168 tokens\n","Primed sampling 3 samples with temp=0.98, top_k=0, top_p=0.0\n","448/448 [01:36<00:00,  4.63it/s]\n","1024/1024 [02:07<00:00,  8.06it/s]\n","Sampling 8192 tokens for [6144,14336]. Conditioning on 7168 tokens\n","Primed sampling 3 samples with temp=0.98, top_k=0, top_p=0.0\n","448/448 [01:36<00:00,  4.63it/s]\n","1024/1024 [02:07<00:00,  8.06it/s]\n","Sampling 8192 tokens for [7168,15360]. Conditioning on 7168 tokens\n","Primed sampling 3 samples with temp=0.98, top_k=0, top_p=0.0\n","448/448 [01:36<00:00,  4.63it/s]\n","1024/1024 [02:07<00:00,  8.05it/s]\n","Sampling 8192 tokens for [8192,16384]. Conditioning on 7168 tokens\n","Primed sampling 3 samples with temp=0.98, top_k=0, top_p=0.0\n","448/448 [01:36<00:00,  4.63it/s]\n","1024/1024 [02:07<00:00,  8.06it/s]\n","Sampling 8192 tokens for [9034,17226]. Conditioning on 7350 tokens\n","Primed sampling 3 samples with temp=0.98, top_k=0, top_p=0.0\n","460/460 [01:40<00:00,  4.59it/s]\n","842/842 [01:44<00:00,  8.03it/s]\n"]}]},{"cell_type":"markdown","metadata":{"id":"-gxY9aqHqfLJ"},"source":["Code to listen to the results at the top level. This will sound very noisy until we do the upsampling stage. 'item_0' refers to the very first song sample generated."]},{"cell_type":"code","metadata":{"id":"TPZENDGZqOOb","colab":{"base_uri":"https://localhost:8080/","height":75,"output_embedded_package_id":"15k01pf00fl-iGtJSuIYj9fhwFXR3ffpl"},"executionInfo":{"status":"ok","timestamp":1654221946420,"user_tz":-480,"elapsed":11768,"user":{"displayName":"titus lim","userId":"15988225439622456165"}},"outputId":"abfc9eb3-3247-4002-c4ac-1bb2f0c26e50"},"source":["Audio(f'{hps.name}/level_2/item_0.wav')"],"execution_count":12,"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}]},{"cell_type":"code","source":["Audio(f'{hps.name}/level_2/item_1.wav')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":75,"output_embedded_package_id":"1BvfQlWuMXyqMRXRTRwCKr-NZYpG8k5ar"},"id":"JGxsEwWEmnSd","executionInfo":{"status":"ok","timestamp":1654221946421,"user_tz":-480,"elapsed":117,"user":{"displayName":"titus lim","userId":"15988225439622456165"}},"outputId":"0cafd9dd-2e45-49e6-dd36-932f05d07697"},"execution_count":13,"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}]},{"cell_type":"code","source":["Audio(f'{hps.name}/level_2/item_2.wav')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":75,"output_embedded_package_id":"1YPE10n_wepd6QjLDFI-M83nuKZaGSskr"},"id":"B0M6oeWXmpHo","executionInfo":{"status":"ok","timestamp":1654221951585,"user_tz":-480,"elapsed":5183,"user":{"displayName":"titus lim","userId":"15988225439622456165"}},"outputId":"232c45a2-360b-4e9b-9d47-f95366813428"},"execution_count":14,"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}]},{"cell_type":"markdown","metadata":{"id":"EJc3bQxmusc6"},"source":["We are now done with the large top_prior model, and instead load the upsamplers."]},{"cell_type":"code","metadata":{"id":"W5VLX0zRapIm","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1654222041224,"user_tz":-480,"elapsed":89646,"user":{"displayName":"titus lim","userId":"15988225439622456165"}},"outputId":"bb772870-4f9e-4cec-bc49-f9fe21d4d68f"},"source":["# Set this False if you are on a local machine that has enough memory (this allows you to do the\n","# lyrics alignment visualization during the upsampling stage). For a hosted runtime, \n","# we'll need to go ahead and delete the top_prior if you are using the 5b_lyrics model.\n","if True:\n","  del top_prior\n","  empty_cache()\n","  top_prior=None\n","upsamplers = [make_prior(setup_hparams(prior, dict()), vqvae, 'cpu') for prior in priors[:-1]]\n","labels[:2] = [prior.labeller.get_batch_labels(metas, 'cuda') for prior in upsamplers]"],"execution_count":15,"outputs":[{"output_type":"stream","name":"stdout","text":["Conditioning on 1 above level(s)\n","Checkpointing convs\n","Checkpointing convs\n","Loading artist IDs from /usr/local/lib/python3.7/dist-packages/jukebox/data/ids/v2_artist_ids.txt\n","Loading artist IDs from /usr/local/lib/python3.7/dist-packages/jukebox/data/ids/v2_genre_ids.txt\n","Level:0, Cond downsample:4, Raw to tokens:8, Sample length:65536\n","Downloading from azure\n","Running  wget -O /root/.cache/jukebox/models/5b/prior_level_0.pth.tar https://openaipublic.azureedge.net/jukebox/models/5b/prior_level_0.pth.tar\n","Restored from /root/.cache/jukebox/models/5b/prior_level_0.pth.tar\n","0: Loading prior in eval mode\n","Conditioning on 1 above level(s)\n","Checkpointing convs\n","Checkpointing convs\n","Loading artist IDs from /usr/local/lib/python3.7/dist-packages/jukebox/data/ids/v2_artist_ids.txt\n","Loading artist IDs from /usr/local/lib/python3.7/dist-packages/jukebox/data/ids/v2_genre_ids.txt\n","Level:1, Cond downsample:4, Raw to tokens:32, Sample length:262144\n","Downloading from azure\n","Running  wget -O /root/.cache/jukebox/models/5b/prior_level_1.pth.tar https://openaipublic.azureedge.net/jukebox/models/5b/prior_level_1.pth.tar\n","Restored from /root/.cache/jukebox/models/5b/prior_level_1.pth.tar\n","0: Loading prior in eval mode\n"]}]},{"cell_type":"markdown","metadata":{"id":"eH_jUhGDprAt"},"source":["This next upsampling step will take several hours.  \n","\n","Note: At the free tier, Google Colab only allows a max run of 12 hours.  As the upsampling is completed, samples will appear in the Files tab (you can access this at the left of the Colab), under \"samples\" (or whatever hps.name is currently).  Level 1 is the partially upsampled version, Level 0 is the fully completed version."]},{"cell_type":"code","metadata":{"id":"9lkJgLolpZ6w","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1654245215704,"user_tz":-480,"elapsed":1159046,"user":{"displayName":"titus lim","userId":"15988225439622456165"}},"outputId":"c27394e0-1a71-4291-a7f5-fc9ed2e92f60"},"source":["zs = upsample(zs, labels, sampling_kwargs, [*upsamplers, top_prior], hps)"],"execution_count":16,"outputs":[{"output_type":"stream","name":"stdout","text":["Sampling level 1\n","Sampling 8192 tokens for [0,8192]. Conditioning on 0 tokens\n","Ancestral sampling 3 samples with temp=0.99, top_k=0, top_p=0.0\n","8192/8192 [08:46<00:00, 15.56it/s]\n","Sampling 8192 tokens for [4096,12288]. Conditioning on 4096 tokens\n","Primed sampling 3 samples with temp=0.99, top_k=0, top_p=0.0\n","128/128 [00:09<00:00, 13.13it/s]\n","4096/4096 [04:21<00:00, 15.67it/s]\n","Sampling 8192 tokens for [8192,16384]. Conditioning on 4096 tokens\n","Primed sampling 3 samples with temp=0.99, top_k=0, top_p=0.0\n","128/128 [00:09<00:00, 13.26it/s]\n","4096/4096 [04:22<00:00, 15.59it/s]\n","Sampling 8192 tokens for [12288,20480]. Conditioning on 4096 tokens\n","Primed sampling 3 samples with temp=0.99, top_k=0, top_p=0.0\n","128/128 [00:09<00:00, 13.26it/s]\n","4096/4096 [04:22<00:00, 15.60it/s]\n","Sampling 8192 tokens for [16384,24576]. Conditioning on 4096 tokens\n","Primed sampling 3 samples with temp=0.99, top_k=0, top_p=0.0\n","128/128 [00:09<00:00, 13.22it/s]\n","4096/4096 [04:21<00:00, 15.65it/s]\n","Sampling 8192 tokens for [20480,28672]. Conditioning on 4096 tokens\n","Primed sampling 3 samples with temp=0.99, top_k=0, top_p=0.0\n","128/128 [00:09<00:00, 13.20it/s]\n","4096/4096 [04:22<00:00, 15.61it/s]\n","Sampling 8192 tokens for [24576,32768]. Conditioning on 4096 tokens\n","Primed sampling 3 samples with temp=0.99, top_k=0, top_p=0.0\n","128/128 [00:09<00:00, 13.19it/s]\n","4096/4096 [04:24<00:00, 15.47it/s]\n","Sampling 8192 tokens for [28672,36864]. Conditioning on 4096 tokens\n","Primed sampling 3 samples with temp=0.99, top_k=0, top_p=0.0\n","128/128 [00:09<00:00, 13.23it/s]\n","4096/4096 [04:21<00:00, 15.65it/s]\n","Sampling 8192 tokens for [32768,40960]. Conditioning on 4096 tokens\n","Primed sampling 3 samples with temp=0.99, top_k=0, top_p=0.0\n","128/128 [00:09<00:00, 13.20it/s]\n","4096/4096 [04:23<00:00, 15.53it/s]\n","Sampling 8192 tokens for [36864,45056]. Conditioning on 4096 tokens\n","Primed sampling 3 samples with temp=0.99, top_k=0, top_p=0.0\n","128/128 [00:09<00:00, 13.15it/s]\n","4096/4096 [04:21<00:00, 15.67it/s]\n","Sampling 8192 tokens for [40960,49152]. Conditioning on 4096 tokens\n","Primed sampling 3 samples with temp=0.99, top_k=0, top_p=0.0\n","128/128 [00:09<00:00, 13.23it/s]\n","4096/4096 [04:22<00:00, 15.61it/s]\n","Sampling 8192 tokens for [45056,53248]. Conditioning on 4096 tokens\n","Primed sampling 3 samples with temp=0.99, top_k=0, top_p=0.0\n","128/128 [00:09<00:00, 13.22it/s]\n","4096/4096 [04:22<00:00, 15.63it/s]\n","Sampling 8192 tokens for [49152,57344]. Conditioning on 4096 tokens\n","Primed sampling 3 samples with temp=0.99, top_k=0, top_p=0.0\n","128/128 [00:09<00:00, 13.17it/s]\n","4096/4096 [04:19<00:00, 15.77it/s]\n","Sampling 8192 tokens for [53248,61440]. Conditioning on 4096 tokens\n","Primed sampling 3 samples with temp=0.99, top_k=0, top_p=0.0\n","128/128 [00:09<00:00, 13.31it/s]\n","4096/4096 [04:17<00:00, 15.89it/s]\n","Sampling 8192 tokens for [57344,65536]. Conditioning on 4096 tokens\n","Primed sampling 3 samples with temp=0.99, top_k=0, top_p=0.0\n","128/128 [00:09<00:00, 13.34it/s]\n","4096/4096 [04:20<00:00, 15.74it/s]\n","Sampling 8192 tokens for [60712,68904]. Conditioning on 4824 tokens\n","Primed sampling 3 samples with temp=0.99, top_k=0, top_p=0.0\n","151/151 [00:11<00:00, 13.07it/s]\n","3368/3368 [03:36<00:00, 15.57it/s]\n","Sampling level 0\n","Sampling 8192 tokens for [0,8192]. Conditioning on 0 tokens\n","Ancestral sampling 3 samples with temp=0.99, top_k=0, top_p=0.0\n","8192/8192 [08:47<00:00, 15.53it/s]\n","Sampling 8192 tokens for [4096,12288]. Conditioning on 4096 tokens\n","Primed sampling 3 samples with temp=0.99, top_k=0, top_p=0.0\n","128/128 [00:09<00:00, 13.23it/s]\n","4096/4096 [04:24<00:00, 15.51it/s]\n","Sampling 8192 tokens for [8192,16384]. Conditioning on 4096 tokens\n","Primed sampling 3 samples with temp=0.99, top_k=0, top_p=0.0\n","128/128 [00:09<00:00, 13.28it/s]\n","4096/4096 [04:22<00:00, 15.61it/s]\n","Sampling 8192 tokens for [12288,20480]. Conditioning on 4096 tokens\n","Primed sampling 3 samples with temp=0.99, top_k=0, top_p=0.0\n","128/128 [00:09<00:00, 13.19it/s]\n","4096/4096 [04:23<00:00, 15.53it/s]\n","Sampling 8192 tokens for [16384,24576]. Conditioning on 4096 tokens\n","Primed sampling 3 samples with temp=0.99, top_k=0, top_p=0.0\n","128/128 [00:09<00:00, 13.17it/s]\n","4096/4096 [04:24<00:00, 15.47it/s]\n","Sampling 8192 tokens for [20480,28672]. Conditioning on 4096 tokens\n","Primed sampling 3 samples with temp=0.99, top_k=0, top_p=0.0\n","128/128 [00:09<00:00, 13.22it/s]\n","4096/4096 [04:23<00:00, 15.52it/s]\n","Sampling 8192 tokens for [24576,32768]. Conditioning on 4096 tokens\n","Primed sampling 3 samples with temp=0.99, top_k=0, top_p=0.0\n","128/128 [00:09<00:00, 13.17it/s]\n","4096/4096 [04:24<00:00, 15.51it/s]\n","Sampling 8192 tokens for [28672,36864]. Conditioning on 4096 tokens\n","Primed sampling 3 samples with temp=0.99, top_k=0, top_p=0.0\n","128/128 [00:09<00:00, 13.15it/s]\n","4096/4096 [04:21<00:00, 15.66it/s]\n","Sampling 8192 tokens for [32768,40960]. Conditioning on 4096 tokens\n","Primed sampling 3 samples with temp=0.99, top_k=0, top_p=0.0\n","128/128 [00:09<00:00, 13.35it/s]\n","4096/4096 [04:21<00:00, 15.65it/s]\n","Sampling 8192 tokens for [36864,45056]. Conditioning on 4096 tokens\n","Primed sampling 3 samples with temp=0.99, top_k=0, top_p=0.0\n","128/128 [00:09<00:00, 13.16it/s]\n","4096/4096 [04:23<00:00, 15.52it/s]\n","Sampling 8192 tokens for [40960,49152]. Conditioning on 4096 tokens\n","Primed sampling 3 samples with temp=0.99, top_k=0, top_p=0.0\n","128/128 [00:09<00:00, 13.14it/s]\n","4096/4096 [04:24<00:00, 15.50it/s]\n","Sampling 8192 tokens for [45056,53248]. Conditioning on 4096 tokens\n","Primed sampling 3 samples with temp=0.99, top_k=0, top_p=0.0\n","128/128 [00:09<00:00, 13.22it/s]\n","4096/4096 [04:25<00:00, 15.43it/s]\n","Sampling 8192 tokens for [49152,57344]. Conditioning on 4096 tokens\n","Primed sampling 3 samples with temp=0.99, top_k=0, top_p=0.0\n","128/128 [00:09<00:00, 13.26it/s]\n","4096/4096 [04:25<00:00, 15.42it/s]\n","Sampling 8192 tokens for [53248,61440]. Conditioning on 4096 tokens\n","Primed sampling 3 samples with temp=0.99, top_k=0, top_p=0.0\n","128/128 [00:09<00:00, 13.14it/s]\n","4096/4096 [04:25<00:00, 15.43it/s]\n","Sampling 8192 tokens for [57344,65536]. Conditioning on 4096 tokens\n","Primed sampling 3 samples with temp=0.99, top_k=0, top_p=0.0\n","128/128 [00:09<00:00, 13.20it/s]\n","4096/4096 [04:24<00:00, 15.48it/s]\n","Sampling 8192 tokens for [61440,69632]. Conditioning on 4096 tokens\n","Primed sampling 3 samples with temp=0.99, top_k=0, top_p=0.0\n","128/128 [00:09<00:00, 13.17it/s]\n","4096/4096 [04:25<00:00, 15.43it/s]\n","Sampling 8192 tokens for [65536,73728]. Conditioning on 4096 tokens\n","Primed sampling 3 samples with temp=0.99, top_k=0, top_p=0.0\n","128/128 [00:09<00:00, 13.09it/s]\n","4096/4096 [04:25<00:00, 15.42it/s]\n","Sampling 8192 tokens for [69632,77824]. Conditioning on 4096 tokens\n","Primed sampling 3 samples with temp=0.99, top_k=0, top_p=0.0\n","128/128 [00:09<00:00, 13.18it/s]\n","4096/4096 [04:25<00:00, 15.45it/s]\n","Sampling 8192 tokens for [73728,81920]. Conditioning on 4096 tokens\n","Primed sampling 3 samples with temp=0.99, top_k=0, top_p=0.0\n","128/128 [00:09<00:00, 13.13it/s]\n","4096/4096 [04:25<00:00, 15.43it/s]\n","Sampling 8192 tokens for [77824,86016]. Conditioning on 4096 tokens\n","Primed sampling 3 samples with temp=0.99, top_k=0, top_p=0.0\n","128/128 [00:09<00:00, 13.14it/s]\n","4096/4096 [04:25<00:00, 15.45it/s]\n","Sampling 8192 tokens for [81920,90112]. Conditioning on 4096 tokens\n","Primed sampling 3 samples with temp=0.99, top_k=0, top_p=0.0\n","128/128 [00:09<00:00, 13.19it/s]\n","4096/4096 [04:25<00:00, 15.42it/s]\n","Sampling 8192 tokens for [86016,94208]. Conditioning on 4096 tokens\n","Primed sampling 3 samples with temp=0.99, top_k=0, top_p=0.0\n","128/128 [00:09<00:00, 13.19it/s]\n","4096/4096 [04:26<00:00, 15.36it/s]\n","Sampling 8192 tokens for [90112,98304]. Conditioning on 4096 tokens\n","Primed sampling 3 samples with temp=0.99, top_k=0, top_p=0.0\n","128/128 [00:09<00:00, 13.20it/s]\n","4096/4096 [04:26<00:00, 15.37it/s]\n","Sampling 8192 tokens for [94208,102400]. Conditioning on 4096 tokens\n","Primed sampling 3 samples with temp=0.99, top_k=0, top_p=0.0\n","128/128 [00:09<00:00, 13.15it/s]\n","4096/4096 [04:26<00:00, 15.37it/s]\n","Sampling 8192 tokens for [98304,106496]. Conditioning on 4096 tokens\n","Primed sampling 3 samples with temp=0.99, top_k=0, top_p=0.0\n","128/128 [00:09<00:00, 13.13it/s]\n","4096/4096 [04:26<00:00, 15.36it/s]\n","Sampling 8192 tokens for [102400,110592]. Conditioning on 4096 tokens\n","Primed sampling 3 samples with temp=0.99, top_k=0, top_p=0.0\n","128/128 [00:09<00:00, 13.10it/s]\n","4096/4096 [04:26<00:00, 15.38it/s]\n","Sampling 8192 tokens for [106496,114688]. Conditioning on 4096 tokens\n","Primed sampling 3 samples with temp=0.99, top_k=0, top_p=0.0\n","128/128 [00:09<00:00, 13.13it/s]\n","4096/4096 [04:26<00:00, 15.38it/s]\n","Sampling 8192 tokens for [110592,118784]. Conditioning on 4096 tokens\n","Primed sampling 3 samples with temp=0.99, top_k=0, top_p=0.0\n","128/128 [00:09<00:00, 13.08it/s]\n","4096/4096 [04:25<00:00, 15.41it/s]\n","Sampling 8192 tokens for [114688,122880]. Conditioning on 4096 tokens\n","Primed sampling 3 samples with temp=0.99, top_k=0, top_p=0.0\n","128/128 [00:09<00:00, 13.06it/s]\n","4096/4096 [04:27<00:00, 15.34it/s]\n","Sampling 8192 tokens for [118784,126976]. Conditioning on 4096 tokens\n","Primed sampling 3 samples with temp=0.99, top_k=0, top_p=0.0\n","128/128 [00:09<00:00, 13.11it/s]\n","4096/4096 [04:27<00:00, 15.33it/s]\n","Sampling 8192 tokens for [122880,131072]. Conditioning on 4096 tokens\n","Primed sampling 3 samples with temp=0.99, top_k=0, top_p=0.0\n","128/128 [00:09<00:00, 13.07it/s]\n","4096/4096 [04:27<00:00, 15.32it/s]\n","Sampling 8192 tokens for [126976,135168]. Conditioning on 4096 tokens\n","Primed sampling 3 samples with temp=0.99, top_k=0, top_p=0.0\n","128/128 [00:09<00:00, 13.18it/s]\n","4096/4096 [04:27<00:00, 15.31it/s]\n","Sampling 8192 tokens for [131072,139264]. Conditioning on 4096 tokens\n","Primed sampling 3 samples with temp=0.99, top_k=0, top_p=0.0\n","128/128 [00:09<00:00, 13.18it/s]\n","4096/4096 [04:26<00:00, 15.35it/s]\n","Sampling 8192 tokens for [135168,143360]. Conditioning on 4096 tokens\n","Primed sampling 3 samples with temp=0.99, top_k=0, top_p=0.0\n","128/128 [00:09<00:00, 13.15it/s]\n","4096/4096 [04:27<00:00, 15.31it/s]\n","Sampling 8192 tokens for [139264,147456]. Conditioning on 4096 tokens\n","Primed sampling 3 samples with temp=0.99, top_k=0, top_p=0.0\n","128/128 [00:09<00:00, 13.02it/s]\n","4096/4096 [04:27<00:00, 15.29it/s]\n","Sampling 8192 tokens for [143360,151552]. Conditioning on 4096 tokens\n","Primed sampling 3 samples with temp=0.99, top_k=0, top_p=0.0\n","128/128 [00:09<00:00, 13.11it/s]\n","4096/4096 [04:27<00:00, 15.32it/s]\n","Sampling 8192 tokens for [147456,155648]. Conditioning on 4096 tokens\n","Primed sampling 3 samples with temp=0.99, top_k=0, top_p=0.0\n","128/128 [00:09<00:00, 12.99it/s]\n","4096/4096 [04:26<00:00, 15.35it/s]\n","Sampling 8192 tokens for [151552,159744]. Conditioning on 4096 tokens\n","Primed sampling 3 samples with temp=0.99, top_k=0, top_p=0.0\n","128/128 [00:09<00:00, 13.02it/s]\n","4096/4096 [04:27<00:00, 15.34it/s]\n","Sampling 8192 tokens for [155648,163840]. Conditioning on 4096 tokens\n","Primed sampling 3 samples with temp=0.99, top_k=0, top_p=0.0\n","128/128 [00:09<00:00, 13.08it/s]\n","4096/4096 [04:27<00:00, 15.33it/s]\n","Sampling 8192 tokens for [159744,167936]. Conditioning on 4096 tokens\n","Primed sampling 3 samples with temp=0.99, top_k=0, top_p=0.0\n","128/128 [00:09<00:00, 13.09it/s]\n","4096/4096 [04:26<00:00, 15.38it/s]\n","Sampling 8192 tokens for [163840,172032]. Conditioning on 4096 tokens\n","Primed sampling 3 samples with temp=0.99, top_k=0, top_p=0.0\n","128/128 [00:09<00:00, 13.16it/s]\n","4096/4096 [04:26<00:00, 15.35it/s]\n","Sampling 8192 tokens for [167936,176128]. Conditioning on 4096 tokens\n","Primed sampling 3 samples with temp=0.99, top_k=0, top_p=0.0\n","128/128 [00:09<00:00, 13.07it/s]\n","4096/4096 [04:27<00:00, 15.34it/s]\n","Sampling 8192 tokens for [172032,180224]. Conditioning on 4096 tokens\n","Primed sampling 3 samples with temp=0.99, top_k=0, top_p=0.0\n","128/128 [00:09<00:00, 13.15it/s]\n","4096/4096 [04:26<00:00, 15.38it/s]\n","Sampling 8192 tokens for [176128,184320]. Conditioning on 4096 tokens\n","Primed sampling 3 samples with temp=0.99, top_k=0, top_p=0.0\n","128/128 [00:09<00:00, 13.21it/s]\n","4096/4096 [04:26<00:00, 15.38it/s]\n","Sampling 8192 tokens for [180224,188416]. Conditioning on 4096 tokens\n","Primed sampling 3 samples with temp=0.99, top_k=0, top_p=0.0\n","128/128 [00:09<00:00, 13.11it/s]\n","4096/4096 [04:27<00:00, 15.34it/s]\n","Sampling 8192 tokens for [184320,192512]. Conditioning on 4096 tokens\n","Primed sampling 3 samples with temp=0.99, top_k=0, top_p=0.0\n","128/128 [00:09<00:00, 13.04it/s]\n","4096/4096 [04:27<00:00, 15.28it/s]\n","Sampling 8192 tokens for [188416,196608]. Conditioning on 4096 tokens\n","Primed sampling 3 samples with temp=0.99, top_k=0, top_p=0.0\n","128/128 [00:09<00:00, 13.17it/s]\n","4096/4096 [04:26<00:00, 15.35it/s]\n","Sampling 8192 tokens for [192512,200704]. Conditioning on 4096 tokens\n","Primed sampling 3 samples with temp=0.99, top_k=0, top_p=0.0\n","128/128 [00:09<00:00, 13.18it/s]\n","4096/4096 [04:26<00:00, 15.35it/s]\n","Sampling 8192 tokens for [196608,204800]. Conditioning on 4096 tokens\n","Primed sampling 3 samples with temp=0.99, top_k=0, top_p=0.0\n","128/128 [00:09<00:00, 13.13it/s]\n","4096/4096 [04:27<00:00, 15.29it/s]\n","Sampling 8192 tokens for [200704,208896]. Conditioning on 4096 tokens\n","Primed sampling 3 samples with temp=0.99, top_k=0, top_p=0.0\n","128/128 [00:09<00:00, 13.14it/s]\n","4096/4096 [04:26<00:00, 15.34it/s]\n","Sampling 8192 tokens for [204800,212992]. Conditioning on 4096 tokens\n","Primed sampling 3 samples with temp=0.99, top_k=0, top_p=0.0\n","128/128 [00:09<00:00, 13.07it/s]\n","4096/4096 [04:26<00:00, 15.36it/s]\n","Sampling 8192 tokens for [208896,217088]. Conditioning on 4096 tokens\n","Primed sampling 3 samples with temp=0.99, top_k=0, top_p=0.0\n","128/128 [00:09<00:00, 13.10it/s]\n","4096/4096 [04:26<00:00, 15.37it/s]\n","Sampling 8192 tokens for [212992,221184]. Conditioning on 4096 tokens\n","Primed sampling 3 samples with temp=0.99, top_k=0, top_p=0.0\n","128/128 [00:09<00:00, 13.13it/s]\n","4096/4096 [04:26<00:00, 15.38it/s]\n","Sampling 8192 tokens for [217088,225280]. Conditioning on 4096 tokens\n","Primed sampling 3 samples with temp=0.99, top_k=0, top_p=0.0\n","128/128 [00:09<00:00, 12.95it/s]\n","4096/4096 [04:26<00:00, 15.38it/s]\n","Sampling 8192 tokens for [221184,229376]. Conditioning on 4096 tokens\n","Primed sampling 3 samples with temp=0.99, top_k=0, top_p=0.0\n","128/128 [00:09<00:00, 13.19it/s]\n","4096/4096 [04:25<00:00, 15.40it/s]\n","Sampling 8192 tokens for [225280,233472]. Conditioning on 4096 tokens\n","Primed sampling 3 samples with temp=0.99, top_k=0, top_p=0.0\n","128/128 [00:09<00:00, 13.22it/s]\n","4096/4096 [04:26<00:00, 15.34it/s]\n","Sampling 8192 tokens for [229376,237568]. Conditioning on 4096 tokens\n","Primed sampling 3 samples with temp=0.99, top_k=0, top_p=0.0\n","128/128 [00:09<00:00, 13.18it/s]\n","4096/4096 [04:26<00:00, 15.37it/s]\n","Sampling 8192 tokens for [233472,241664]. Conditioning on 4096 tokens\n","Primed sampling 3 samples with temp=0.99, top_k=0, top_p=0.0\n","128/128 [00:09<00:00, 13.14it/s]\n","4096/4096 [04:26<00:00, 15.35it/s]\n","Sampling 8192 tokens for [237568,245760]. Conditioning on 4096 tokens\n","Primed sampling 3 samples with temp=0.99, top_k=0, top_p=0.0\n","128/128 [00:09<00:00, 13.03it/s]\n","4096/4096 [04:26<00:00, 15.38it/s]\n","Sampling 8192 tokens for [241664,249856]. Conditioning on 4096 tokens\n","Primed sampling 3 samples with temp=0.99, top_k=0, top_p=0.0\n","128/128 [00:09<00:00, 13.08it/s]\n","4096/4096 [04:26<00:00, 15.35it/s]\n","Sampling 8192 tokens for [245760,253952]. Conditioning on 4096 tokens\n","Primed sampling 3 samples with temp=0.99, top_k=0, top_p=0.0\n","128/128 [00:09<00:00, 13.10it/s]\n","4096/4096 [04:26<00:00, 15.37it/s]\n","Sampling 8192 tokens for [249856,258048]. Conditioning on 4096 tokens\n","Primed sampling 3 samples with temp=0.99, top_k=0, top_p=0.0\n","128/128 [00:09<00:00, 13.11it/s]\n","4096/4096 [04:26<00:00, 15.36it/s]\n","Sampling 8192 tokens for [253952,262144]. Conditioning on 4096 tokens\n","Primed sampling 3 samples with temp=0.99, top_k=0, top_p=0.0\n","128/128 [00:09<00:00, 13.11it/s]\n","4096/4096 [04:26<00:00, 15.35it/s]\n","Sampling 8192 tokens for [258048,266240]. Conditioning on 4096 tokens\n","Primed sampling 3 samples with temp=0.99, top_k=0, top_p=0.0\n","128/128 [00:09<00:00, 13.11it/s]\n","4096/4096 [04:25<00:00, 15.42it/s]\n","Sampling 8192 tokens for [262144,270336]. Conditioning on 4096 tokens\n","Primed sampling 3 samples with temp=0.99, top_k=0, top_p=0.0\n","128/128 [00:09<00:00, 13.18it/s]\n","4096/4096 [04:26<00:00, 15.39it/s]\n","Sampling 8192 tokens for [266240,274432]. Conditioning on 4096 tokens\n","Primed sampling 3 samples with temp=0.99, top_k=0, top_p=0.0\n","128/128 [00:09<00:00, 13.17it/s]\n","4096/4096 [04:26<00:00, 15.39it/s]\n","Sampling 8192 tokens for [267424,275616]. Conditioning on 7008 tokens\n","Primed sampling 3 samples with temp=0.99, top_k=0, top_p=0.0\n","219/219 [00:17<00:00, 12.29it/s]\n","1184/1184 [01:16<00:00, 15.40it/s]\n"]}]},{"cell_type":"markdown","metadata":{"id":"3SJgBYJPri55"},"source":["Listen to the final sample!"]},{"cell_type":"code","metadata":{"id":"2ip2PPE0rgAb","colab":{"base_uri":"https://localhost:8080/","height":75,"output_embedded_package_id":"1WNze8smnhJxrvz15lj6jWG5Mc-o25YqA"},"executionInfo":{"status":"ok","timestamp":1654245248923,"user_tz":-480,"elapsed":33218,"user":{"displayName":"titus lim","userId":"15988225439622456165"}},"outputId":"43860909-2308-4302-d21c-01e07d072201"},"source":["Audio(f'{hps.name}/level_0/item_0.wav')"],"execution_count":17,"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}]},{"cell_type":"code","source":["Audio(f'{hps.name}/level_0/item_1.wav')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":75,"output_embedded_package_id":"1XjSln8CpveWdfXrS9UIbyYmI6wr7FdaH"},"id":"HdDEpcL0nLKn","executionInfo":{"status":"ok","timestamp":1654245248923,"user_tz":-480,"elapsed":3,"user":{"displayName":"titus lim","userId":"15988225439622456165"}},"outputId":"da03f577-ecf4-4b8a-b950-7731f1ae6531"},"execution_count":18,"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}]},{"cell_type":"code","source":["Audio(f'{hps.name}/level_0/item_2.wav')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":75,"output_embedded_package_id":"1D9DrDKql7H3sAgUNoRMtbaJXPt4mpqiD"},"id":"EDPbq97JnK5r","executionInfo":{"status":"ok","timestamp":1654245250254,"user_tz":-480,"elapsed":1,"user":{"displayName":"titus lim","userId":"15988225439622456165"}},"outputId":"d1cc5980-edb8-43ab-859f-109febd9df3a"},"execution_count":19,"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}]},{"cell_type":"code","metadata":{"id":"8JAgFxytwrLG","executionInfo":{"status":"ok","timestamp":1654245248924,"user_tz":-480,"elapsed":2,"user":{"displayName":"titus lim","userId":"15988225439622456165"}}},"source":["del upsamplers\n","empty_cache()"],"execution_count":20,"outputs":[]},{"cell_type":"code","source":[""],"metadata":{"id":"EVOV4EnvHl0W"},"execution_count":null,"outputs":[]}]}