{"cells":[{"cell_type":"code","execution_count":null,"id":"1sqwH29gCCae","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3876,"status":"ok","timestamp":1655028131236,"user":{"displayName":"QUEK HAO YONG, GABRIEL _","userId":"08861584446371432378"},"user_tz":-480},"id":"1sqwH29gCCae","outputId":"50a97957-fb6b-46d2-9369-530add28d852"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n","/content/drive/MyDrive/SMU_MITB_NLP/Group Project/NLP-Lyric-Generator/src/bin\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')\n","%cd /content/drive/MyDrive/SMU_MITB_NLP/Group Project/NLP-Lyric-Generator/src/bin"]},{"cell_type":"code","execution_count":null,"id":"eed94d9c","metadata":{"id":"eed94d9c"},"outputs":[],"source":["### Standard Imports\n","import numpy as np\n","import re\n","import sys\n","import os\n","from collections import Counter\n","\n","import tensorflow as tf\n","from tensorflow.keras import layers"]},{"cell_type":"code","execution_count":null,"id":"18f77d0b","metadata":{"id":"18f77d0b"},"outputs":[],"source":["### Custom Imports\n","sys.path.append('../')\n","import lib.utilities as utils\n","import lib.autoencoder_utilities as ae_utils"]},{"cell_type":"code","execution_count":null,"id":"QsvWeCUNxSvd","metadata":{"id":"QsvWeCUNxSvd"},"outputs":[],"source":["### Text Parameters\n","start_token = '<cls>'\n","end_token = '<eos>'\n","pad_token = '<pad>'\n","unk_token = '<unk>'\n","newline_token = '<new>'\n","\n","### General Parameters\n","random_seed = 2022\n","model_folder = '../../../autoencoder/lstm/v2'\n","model_name = 'autoencoder_lstm_with_attention'\n","\n","### Model Parameters\n","val_split = 0.2\n","window_len = 15\n","batch_size = 64\n","enc_dim, dec_dim = 256, 256\n","learn_rate = 0.001\n","epochs = 50\n","dropout = 0.05\n","recurrent_dropout = 0.05"]},{"cell_type":"code","execution_count":null,"id":"zy-R6jQR4Ozz","metadata":{"id":"zy-R6jQR4Ozz"},"outputs":[],"source":["os.makedirs(model_folder, exist_ok=True)"]},{"cell_type":"code","execution_count":null,"id":"e1f082fd","metadata":{"id":"e1f082fd"},"outputs":[],"source":["### Load Data\n","corpus = utils.load_corpus()\n","train_corpus, val_corpus, train_files, val_files = utils.split_corpus()"]},{"cell_type":"code","execution_count":null,"id":"52adf0e5","metadata":{"id":"52adf0e5","scrolled":true},"outputs":[],"source":["### Pre-Processing Text\n","_, word_count, index_to_vocab, vocab_to_index, _, _ = utils.tokenize_corpus(corpus,\n","                                                                            window_length = window_len,\n","                                                                            end_token = end_token,\n","                                                                            start_token = start_token,\n","                                                                            pad_token = pad_token,\n","                                                                            unk_token = unk_token,\n","                                                                            newline_token = newline_token)\n","vocab_size = len(word_count)\n","\n","train_words, _, _, _, train_songs, train_songs_token_ind = utils.tokenize_corpus(train_corpus,\n","                                                                       window_length = window_len,\n","                                                                       index_to_vocab = index_to_vocab,\n","                                                                       vocab_to_index = vocab_to_index,\n","                                                                       end_token = end_token,\n","                                                                       start_token = start_token,\n","                                                                       pad_token = pad_token,\n","                                                                       unk_token = unk_token,\n","                                                                       newline_token = newline_token)\n","\n","val_words, _, _, _, _, val_songs_token_ind = utils.tokenize_corpus(val_corpus,\n","                                                           window_length = window_len,\n","                                                           index_to_vocab = index_to_vocab,\n","                                                           vocab_to_index = vocab_to_index,\n","                                                           end_token = end_token,\n","                                                           start_token = start_token,\n","                                                           pad_token = pad_token,\n","                                                           unk_token = unk_token,\n","                                                           newline_token = newline_token)"]},{"cell_type":"code","execution_count":null,"id":"cb1a6431","metadata":{"id":"cb1a6431"},"outputs":[],"source":["train_x_encoder, train_x_decoder, train_y = ae_utils.construct_seq_data(train_songs_token_ind, window_len)\n","val_x_encoder, val_x_decoder, val_y = ae_utils.construct_seq_data(val_songs_token_ind, window_len)"]},{"cell_type":"code","execution_count":null,"id":"KY-CHZ0CcP2C","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":14,"status":"ok","timestamp":1655028134843,"user":{"displayName":"QUEK HAO YONG, GABRIEL _","userId":"08861584446371432378"},"user_tz":-480},"id":"KY-CHZ0CcP2C","outputId":"a408bfac-4fab-4fba-9815-409748f6e3ce"},"outputs":[{"output_type":"stream","name":"stdout","text":["['be', 'the', 'best', '<new>', 'there', 'is', 'so', 'much', 'to', 'reach', 'out', 'for', '<new>', 'stars', 'and']\n","['to', 'be', 'the', 'best', '<new>', 'there', 'is', 'so', 'much', 'to', 'reach', 'out', 'for', '<new>', 'stars']\n","and\n","['i', 'miss', 'when', 'i', 'am', 'away', '<new>', '<new>', '<chorus>', '<new>', 'there', 'is', 'no', 'place', 'i']\n","['you', 'i', 'miss', 'when', 'i', 'am', 'away', '<new>', '<new>', '<chorus>', '<new>', 'there', 'is', 'no', 'place']\n","i\n"]}],"source":["rand_int = np.random.randint(0, len(train_x_encoder), 1)[0]\n","print([index_to_vocab.get(x) for x in train_x_encoder[rand_int]])\n","print([index_to_vocab.get(x) for x in train_x_decoder[rand_int]])\n","print(index_to_vocab.get(train_y[rand_int]))\n","\n","rand_int = np.random.randint(0, len(val_x_encoder), 1)[0]\n","print([index_to_vocab.get(x) for x in val_x_encoder[rand_int]])\n","print([index_to_vocab.get(x) for x in val_x_decoder[rand_int]])\n","print(index_to_vocab.get(val_y[rand_int]))"]},{"cell_type":"code","execution_count":null,"id":"Dk3I2VI1Nza3","metadata":{"id":"Dk3I2VI1Nza3"},"outputs":[],"source":["train_dataset = ae_utils.construct_datasets(train_x_encoder, train_x_decoder, train_y,\n","                                            random_seed = random_seed,\n","                                            batch_size = batch_size,\n","                                            vocab_size = vocab_size)\n","val_dataset = ae_utils.construct_datasets(val_x_encoder, val_x_decoder, val_y,\n","                                            random_seed = random_seed,\n","                                            batch_size = batch_size,\n","                                            vocab_size = vocab_size)"]},{"cell_type":"code","execution_count":null,"id":"202bf8be","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2049,"status":"ok","timestamp":1655028143443,"user":{"displayName":"QUEK HAO YONG, GABRIEL _","userId":"08861584446371432378"},"user_tz":-480},"id":"202bf8be","outputId":"ae840b14-15b4-481e-b169-4c8a832d8f6e"},"outputs":[{"output_type":"stream","name":"stdout","text":["WARNING:tensorflow:Layer encoder_lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n","WARNING:tensorflow:Layer decoder_lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n","Model: \"model\"\n","__________________________________________________________________________________________________\n"," Layer (type)                   Output Shape         Param #     Connected to                     \n","==================================================================================================\n"," encoder_input (InputLayer)     [(None, 15, 1041)]   0           []                               \n","                                                                                                  \n"," decoder_input (InputLayer)     [(None, 15, 1041)]   0           []                               \n","                                                                                                  \n"," encoder_lstm (LSTM)            [(None, 256),        1329152     ['encoder_input[0][0]']          \n","                                 (None, 256),                                                     \n","                                 (None, 256)]                                                     \n","                                                                                                  \n"," decoder_lstm (LSTM)            (None, 256)          1329152     ['decoder_input[0][0]',          \n","                                                                  'encoder_lstm[0][1]',           \n","                                                                  'encoder_lstm[0][2]']           \n","                                                                                                  \n"," attention (Attention)          (None, 256)          0           ['decoder_lstm[0][0]',           \n","                                                                  'encoder_lstm[0][0]']           \n","                                                                                                  \n"," tf.concat (TFOpLambda)         (None, 512)          0           ['decoder_lstm[0][0]',           \n","                                                                  'attention[0][0]']              \n","                                                                                                  \n"," output (Dense)                 (None, 1041)         534033      ['tf.concat[0][0]']              \n","                                                                                                  \n","==================================================================================================\n","Total params: 3,192,337\n","Trainable params: 3,192,337\n","Non-trainable params: 0\n","__________________________________________________________________________________________________\n"]}],"source":["# Encoder\n","encoder_input = layers.Input(shape=(window_len,vocab_size), name = 'encoder_input')\n","\n","# Return state in addition to output\n","encoder_output, encoder_hidden_state, encoder_cell_state = layers.LSTM(enc_dim,\n","                                                                       dropout = dropout, recurrent_dropout = recurrent_dropout,\n","                                                                       return_state=True, name = \"encoder_lstm\")(encoder_input)\n","\n","# Decoder\n","decoder_input = layers.Input(shape=(window_len,vocab_size), name = 'decoder_input')\n","\n","# Pass the encoder state to a new LSTM, as initial state\n","decoder_output = layers.LSTM(dec_dim,\n","                             dropout = dropout, recurrent_dropout = recurrent_dropout,\n","                             name=\"decoder_lstm\")(decoder_input, initial_state=[encoder_hidden_state, encoder_cell_state])\n","\n","# Attention\n","attention_context_vector = tf.keras.layers.Attention(name = 'attention')(inputs = [decoder_output, encoder_output])\n","\n","# Output\n","output = layers.Dense(vocab_size, name = 'output', activation = 'softmax')(tf.concat([decoder_output, attention_context_vector], 1))\n","\n","model = tf.keras.Model((encoder_input, decoder_input), output, name = model_name)\n","model.summary()"]},{"cell_type":"code","execution_count":null,"id":"83bb01d4","metadata":{"id":"83bb01d4"},"outputs":[],"source":["model.compile(loss = 'categorical_crossentropy',\n","              optimizer = tf.keras.optimizers.Adam(learning_rate=learn_rate),\n","              metrics = ['accuracy'])"]},{"cell_type":"code","execution_count":null,"id":"oxvZ57pCIWWu","metadata":{"id":"oxvZ57pCIWWu"},"outputs":[],"source":["### Callbacks\n","callback_es = tf.keras.callbacks.EarlyStopping(\n","    monitor='val_loss',\n","    min_delta=0,\n","    patience=10,\n","    verbose=1,\n","    mode='min',\n","    baseline=None,\n","    restore_best_weights=True\n",")\n","\n","callback_mc = tf.keras.callbacks.ModelCheckpoint(\n","    filepath=model_folder+'/weights.{epoch:02d}-{val_loss:.2f}-{val_accuracy:.2f}.hdf5',\n","    save_weights_only=True,\n","    monitor='val_loss',\n","    mode='min',\n","    save_best_only=False)"]},{"cell_type":"code","execution_count":null,"id":"hIOwUeQ0E0LD","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1577583,"status":"ok","timestamp":1655029721022,"user":{"displayName":"QUEK HAO YONG, GABRIEL _","userId":"08861584446371432378"},"user_tz":-480},"id":"hIOwUeQ0E0LD","outputId":"79147d00-7b0b-4011-c0ca-c933a21e86eb"},"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/50\n","180/180 [==============================] - 32s 134ms/step - loss: 4.9736 - accuracy: 0.1896 - val_loss: 4.6455 - val_accuracy: 0.2102\n","Epoch 2/50\n","180/180 [==============================] - 23s 130ms/step - loss: 3.7933 - accuracy: 0.2831 - val_loss: 3.6799 - val_accuracy: 0.3007\n","Epoch 3/50\n","180/180 [==============================] - 22s 121ms/step - loss: 2.8493 - accuracy: 0.4515 - val_loss: 2.6112 - val_accuracy: 0.5544\n","Epoch 4/50\n","180/180 [==============================] - 26s 146ms/step - loss: 2.0590 - accuracy: 0.6087 - val_loss: 2.2000 - val_accuracy: 0.6544\n","Epoch 5/50\n","180/180 [==============================] - 22s 122ms/step - loss: 1.6342 - accuracy: 0.6808 - val_loss: 1.8939 - val_accuracy: 0.6997\n","Epoch 6/50\n","180/180 [==============================] - 22s 121ms/step - loss: 1.4485 - accuracy: 0.7113 - val_loss: 1.6712 - val_accuracy: 0.7541\n","Epoch 7/50\n","180/180 [==============================] - 22s 122ms/step - loss: 1.2496 - accuracy: 0.7469 - val_loss: 1.5509 - val_accuracy: 0.7616\n","Epoch 8/50\n","180/180 [==============================] - 22s 120ms/step - loss: 1.1666 - accuracy: 0.7551 - val_loss: 1.5074 - val_accuracy: 0.7663\n","Epoch 9/50\n","180/180 [==============================] - 26s 142ms/step - loss: 1.0356 - accuracy: 0.7791 - val_loss: 1.4423 - val_accuracy: 0.7854\n","Epoch 10/50\n","180/180 [==============================] - 22s 121ms/step - loss: 0.9827 - accuracy: 0.7837 - val_loss: 1.4865 - val_accuracy: 0.7793\n","Epoch 11/50\n","180/180 [==============================] - 22s 121ms/step - loss: 0.9199 - accuracy: 0.7956 - val_loss: 1.3532 - val_accuracy: 0.8031\n","Epoch 12/50\n","180/180 [==============================] - 22s 121ms/step - loss: 0.8342 - accuracy: 0.8147 - val_loss: 1.3166 - val_accuracy: 0.8160\n","Epoch 13/50\n","180/180 [==============================] - 22s 120ms/step - loss: 0.8076 - accuracy: 0.8144 - val_loss: 1.3112 - val_accuracy: 0.8092\n","Epoch 14/50\n","180/180 [==============================] - 22s 120ms/step - loss: 0.7439 - accuracy: 0.8292 - val_loss: 1.3437 - val_accuracy: 0.8020\n","Epoch 15/50\n","180/180 [==============================] - 21s 119ms/step - loss: 0.7072 - accuracy: 0.8345 - val_loss: 1.3009 - val_accuracy: 0.8211\n","Epoch 16/50\n","180/180 [==============================] - 21s 119ms/step - loss: 0.6477 - accuracy: 0.8475 - val_loss: 1.2254 - val_accuracy: 0.8299\n","Epoch 17/50\n","180/180 [==============================] - 21s 119ms/step - loss: 0.6059 - accuracy: 0.8582 - val_loss: 1.2066 - val_accuracy: 0.8473\n","Epoch 18/50\n","180/180 [==============================] - 23s 127ms/step - loss: 0.5866 - accuracy: 0.8625 - val_loss: 1.4680 - val_accuracy: 0.7925\n","Epoch 19/50\n","180/180 [==============================] - 22s 122ms/step - loss: 0.5960 - accuracy: 0.8579 - val_loss: 1.1754 - val_accuracy: 0.8473\n","Epoch 20/50\n","180/180 [==============================] - 22s 122ms/step - loss: 0.5006 - accuracy: 0.8809 - val_loss: 1.1070 - val_accuracy: 0.8609\n","Epoch 21/50\n","180/180 [==============================] - 22s 120ms/step - loss: 0.4836 - accuracy: 0.8832 - val_loss: 1.1127 - val_accuracy: 0.8466\n","Epoch 22/50\n","180/180 [==============================] - 22s 120ms/step - loss: 0.4622 - accuracy: 0.8895 - val_loss: 1.1166 - val_accuracy: 0.8667\n","Epoch 23/50\n","180/180 [==============================] - 23s 130ms/step - loss: 0.4481 - accuracy: 0.8923 - val_loss: 1.1830 - val_accuracy: 0.8548\n","Epoch 24/50\n","180/180 [==============================] - 22s 120ms/step - loss: 0.4196 - accuracy: 0.9016 - val_loss: 1.1041 - val_accuracy: 0.8619\n","Epoch 25/50\n","180/180 [==============================] - 22s 120ms/step - loss: 0.3519 - accuracy: 0.9175 - val_loss: 1.0737 - val_accuracy: 0.8684\n","Epoch 26/50\n","180/180 [==============================] - 22s 120ms/step - loss: 0.3610 - accuracy: 0.9139 - val_loss: 1.1408 - val_accuracy: 0.8684\n","Epoch 27/50\n","180/180 [==============================] - 21s 119ms/step - loss: 0.3490 - accuracy: 0.9179 - val_loss: 1.0683 - val_accuracy: 0.8874\n","Epoch 28/50\n","180/180 [==============================] - 22s 120ms/step - loss: 0.3214 - accuracy: 0.9261 - val_loss: 1.0785 - val_accuracy: 0.8670\n","Epoch 29/50\n","180/180 [==============================] - 22s 120ms/step - loss: 0.3047 - accuracy: 0.9278 - val_loss: 1.0760 - val_accuracy: 0.8803\n","Epoch 30/50\n","180/180 [==============================] - 22s 120ms/step - loss: 0.2888 - accuracy: 0.9322 - val_loss: 1.0116 - val_accuracy: 0.8959\n","Epoch 31/50\n","180/180 [==============================] - 23s 128ms/step - loss: 0.3023 - accuracy: 0.9274 - val_loss: 1.0522 - val_accuracy: 0.8871\n","Epoch 32/50\n","180/180 [==============================] - 21s 119ms/step - loss: 0.2630 - accuracy: 0.9394 - val_loss: 1.0401 - val_accuracy: 0.8980\n","Epoch 33/50\n","180/180 [==============================] - 22s 121ms/step - loss: 0.2547 - accuracy: 0.9422 - val_loss: 1.0334 - val_accuracy: 0.8888\n","Epoch 34/50\n","180/180 [==============================] - 22s 120ms/step - loss: 0.2276 - accuracy: 0.9499 - val_loss: 1.0950 - val_accuracy: 0.8830\n","Epoch 35/50\n","180/180 [==============================] - 22s 121ms/step - loss: 0.2186 - accuracy: 0.9489 - val_loss: 1.0907 - val_accuracy: 0.8779\n","Epoch 36/50\n","180/180 [==============================] - 22s 120ms/step - loss: 0.2188 - accuracy: 0.9505 - val_loss: 0.9674 - val_accuracy: 0.9058\n","Epoch 37/50\n","180/180 [==============================] - 22s 121ms/step - loss: 0.1886 - accuracy: 0.9570 - val_loss: 1.0279 - val_accuracy: 0.9061\n","Epoch 38/50\n","180/180 [==============================] - 22s 121ms/step - loss: 0.1809 - accuracy: 0.9627 - val_loss: 0.9508 - val_accuracy: 0.9010\n","Epoch 39/50\n","180/180 [==============================] - 23s 129ms/step - loss: 0.1762 - accuracy: 0.9602 - val_loss: 1.0209 - val_accuracy: 0.9000\n","Epoch 40/50\n","180/180 [==============================] - 22s 120ms/step - loss: 0.1739 - accuracy: 0.9641 - val_loss: 0.9856 - val_accuracy: 0.9037\n","Epoch 41/50\n","180/180 [==============================] - 22s 121ms/step - loss: 0.1716 - accuracy: 0.9627 - val_loss: 0.9861 - val_accuracy: 0.9034\n","Epoch 42/50\n","180/180 [==============================] - 22s 121ms/step - loss: 0.1459 - accuracy: 0.9675 - val_loss: 0.9156 - val_accuracy: 0.9041\n","Epoch 43/50\n","180/180 [==============================] - 21s 116ms/step - loss: 0.1492 - accuracy: 0.9681 - val_loss: 0.9669 - val_accuracy: 0.9031\n","Epoch 44/50\n","180/180 [==============================] - 21s 116ms/step - loss: 0.1881 - accuracy: 0.9569 - val_loss: 0.9849 - val_accuracy: 0.9020\n","Epoch 45/50\n","180/180 [==============================] - 21s 116ms/step - loss: 0.1554 - accuracy: 0.9647 - val_loss: 0.9888 - val_accuracy: 0.9000\n","Epoch 46/50\n","180/180 [==============================] - 21s 118ms/step - loss: 0.1511 - accuracy: 0.9667 - val_loss: 0.9997 - val_accuracy: 0.8976\n","Epoch 47/50\n","180/180 [==============================] - 21s 115ms/step - loss: 0.1293 - accuracy: 0.9708 - val_loss: 0.9535 - val_accuracy: 0.9133\n","Epoch 48/50\n","180/180 [==============================] - 21s 116ms/step - loss: 0.1223 - accuracy: 0.9740 - val_loss: 0.9954 - val_accuracy: 0.9102\n","Epoch 49/50\n","180/180 [==============================] - 21s 116ms/step - loss: 0.1201 - accuracy: 0.9745 - val_loss: 1.0796 - val_accuracy: 0.9099\n","Epoch 50/50\n","180/180 [==============================] - 21s 116ms/step - loss: 0.1078 - accuracy: 0.9757 - val_loss: 0.9320 - val_accuracy: 0.9146\n"]}],"source":["history = model.fit(x = train_dataset, validation_data = val_dataset, epochs = epochs, callbacks = [callback_es, callback_mc])"]},{"cell_type":"code","execution_count":null,"id":"QhFHlI6o06Gz","metadata":{"id":"QhFHlI6o06Gz"},"outputs":[],"source":["model.save_weights(f'{model_folder}/final_weights.hdf5')"]},{"cell_type":"code","source":["#model.load_weights(f'{model_folder}/final_weights.hdf5')"],"metadata":{"id":"ljTcusxBWCjT"},"id":"ljTcusxBWCjT","execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"id":"wo0aCkdPL2EU","metadata":{"id":"wo0aCkdPL2EU"},"outputs":[],"source":["prompts = ['Whenever I think back', 'And so this I know',\n","           'I am tired of being what you want me to be', 'Feeling so faithless, lost under the surface',\n","           'Relight our fire, we will find our way', 'We will rise stronger together']\n","result_strings = {}\n","results = {}\n","for prompt in prompts:\n","    result_str, result = utils.generate_text(model,\n","                                             ae_utils.ind_to_input_fun, ae_utils.update_input_fun,\n","                                             start_string = prompt,\n","                                             window_length = window_len,\n","                                             vocab_to_index_dict = vocab_to_index, index_to_vocab_dict = index_to_vocab,\n","                                             vocab_size = vocab_size,\n","                                             num_generate = 100, temperature = 1.0,\n","                                             random_seed = random_seed,\n","                                             end_token = end_token, start_token = start_token,\n","                                             pad_token = pad_token, unk_token = unk_token,\n","                                             newline_token = newline_token,\n","                                             depth = vocab_size)\n","    result_strings[prompt] = result_str\n","    results[prompt] = result"]},{"cell_type":"code","execution_count":null,"id":"smPNycjBnDXa","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":12,"status":"ok","timestamp":1655029755195,"user":{"displayName":"QUEK HAO YONG, GABRIEL _","userId":"08861584446371432378"},"user_tz":-480},"id":"smPNycjBnDXa","outputId":"020a79f8-2caf-496f-fb6d-df827a18c0b7"},"outputs":[{"output_type":"stream","name":"stdout","text":["{'Whenever I think back': 'Whenever I think back beside beside beside beside beside beside beside beside beside beside beside beside dedicated dedicated dedicated tried daylight daylight four kept kept kept kept streams streams streams streams streams streams streams streams hardly might might hardly hardly hardly hardly hardly hardly went went went went went tourists tourists aside aside began began began touch touch touch touch touch touch aside aside unfurled unfurled another another another soldiers slow slow changed fills fills weak weak fills fills changed changed changed seek seek better seek seek seek better read read read read blessing refreshed refreshed braver calling calling calling calling calling calling calling', 'And so this I know': 'And so this I know know know know know know know know know know know know know know know the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the', 'I am tired of being what you want me to be': 'I am tired of being what you want me to be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be', 'Feeling so faithless, lost under the surface': 'Feeling so faithless, lost under the surface echoing echoing echoing close close close close close close close close close close close close close close close close close close close close close close close close close close close close close close close close close close close close close close close close close close close close close close close close close close close close close close close close close close close close close close close close close close close close close close close close close close close close close close close close close close close close close close close close close close close close close close close close close', 'Relight our fire, we will find our way': 'Relight our fire, we will find our way way way way way way way way way way way way way way way way way way way way way way way way way way way way way way way way way way way way way way way way way way way way way way way way way way way way way way way way way way way way way way way way way way way way way way way way way way way way way way way way way way way way way way way way way way way way way way way way way way way way way', 'We will rise stronger together': 'We will rise stronger together together together together together together together together together together together together together together together together together together together together together together together together together together together together together together together together together together together together together together together together together together together together together together together together together together together together together together together together together together together together together together together together together together together together together together together together together together together together together together together together together together together together together together together together together together together together together together together together together together together together together'}\n"]}],"source":["print(result_strings)"]},{"cell_type":"code","execution_count":null,"id":"PgGgpFvaxDuL","metadata":{"id":"PgGgpFvaxDuL"},"outputs":[],"source":["for k, v in result_strings.items():\n","  with open(model_folder+f'/{model_name}-{k.lower()}.txt', 'w') as f:\n","      f.write(v)"]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":[],"name":"Autoencoder (LSTM) with Attention.ipynb","provenance":[{"file_id":"1KbPSOprQ0mhAGFUtVsBjF4O_vkFuvgL9","timestamp":1654815454538},{"file_id":"1L31juRVcjedsJQLb65vDeIYnGfc5VeMn","timestamp":1654812818685},{"file_id":"1s0I-h_H-57P4mfHpn7K9ARRffBzA2996","timestamp":1654811271378},{"file_id":"1fSgHJcraq0bKZQlGXUqlQ4abpWOsgdIu","timestamp":1654782642697},{"file_id":"1_pyvxTi14GzEPtSGxMTy55XDNlCfsK0h","timestamp":1654781952290},{"file_id":"164GHOXuG8X-6WN_mbIfShYez3xOdSrkL","timestamp":1654771075102}]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.8"}},"nbformat":4,"nbformat_minor":5}