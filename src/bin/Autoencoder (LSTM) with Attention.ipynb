{"cells":[{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')\n","%cd /content/drive/MyDrive/SMU_MITB_NLP/Group Project/NLP-Lyric-Generator/src/bin"],"metadata":{"id":"1sqwH29gCCae","colab":{"base_uri":"https://localhost:8080/"},"outputId":"cab998de-5dcf-4e76-c11f-73c0e5dbb501","executionInfo":{"status":"ok","timestamp":1654841112882,"user_tz":-480,"elapsed":2965,"user":{"displayName":"QUEK HAO YONG, GABRIEL _","userId":"08861584446371432378"}}},"id":"1sqwH29gCCae","execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n","/content/drive/MyDrive/SMU_MITB_NLP/Group Project/NLP-Lyric-Generator/src/bin\n"]}]},{"cell_type":"code","execution_count":2,"id":"eed94d9c","metadata":{"id":"eed94d9c","executionInfo":{"status":"ok","timestamp":1654841118145,"user_tz":-480,"elapsed":5265,"user":{"displayName":"QUEK HAO YONG, GABRIEL _","userId":"08861584446371432378"}}},"outputs":[],"source":["### Standard Imports\n","import numpy as np\n","import re\n","import os\n","import sys\n","from collections import Counter\n","\n","import tensorflow as tf\n","from tensorflow.keras import layers"]},{"cell_type":"code","execution_count":3,"id":"18f77d0b","metadata":{"id":"18f77d0b","executionInfo":{"status":"ok","timestamp":1654841118146,"user_tz":-480,"elapsed":6,"user":{"displayName":"QUEK HAO YONG, GABRIEL _","userId":"08861584446371432378"}}},"outputs":[],"source":["### Custom Imports\n","sys.path.append('../')\n","import lib.utilities as utils"]},{"cell_type":"code","source":["### Text Parameters\n","start_token = '<cls>'\n","end_token = '<eos>'\n","pad_token = '<pad>'\n","unk_token = '<unk>'\n","\n","### General Parameters\n","random_seed = 2022\n","model_folder = '../../models/autoencoder/lstm/v2'\n","\n","### Model Parameters\n","val_split = 0.2\n","window_len = 15\n","batch_size = 64\n","enc_dim, dec_dim = 256, 256\n","learn_rate = 0.001\n","epochs = 80\n","dropout = 0.05\n","recurrent_dropout = 0.05"],"metadata":{"id":"QsvWeCUNxSvd","executionInfo":{"status":"ok","timestamp":1654852658176,"user_tz":-480,"elapsed":338,"user":{"displayName":"QUEK HAO YONG, GABRIEL _","userId":"08861584446371432378"}}},"id":"QsvWeCUNxSvd","execution_count":45,"outputs":[]},{"cell_type":"code","source":["os.makedirs(model_folder, exist_ok=True)"],"metadata":{"id":"zy-R6jQR4Ozz","executionInfo":{"status":"ok","timestamp":1654852347234,"user_tz":-480,"elapsed":290,"user":{"displayName":"QUEK HAO YONG, GABRIEL _","userId":"08861584446371432378"}}},"id":"zy-R6jQR4Ozz","execution_count":35,"outputs":[]},{"cell_type":"code","execution_count":5,"id":"e1f082fd","metadata":{"id":"e1f082fd","executionInfo":{"status":"ok","timestamp":1654841118146,"user_tz":-480,"elapsed":5,"user":{"displayName":"QUEK HAO YONG, GABRIEL _","userId":"08861584446371432378"}}},"outputs":[],"source":["### Load Data\n","corpus = utils.load_corpus()"]},{"cell_type":"code","execution_count":6,"id":"52adf0e5","metadata":{"scrolled":true,"id":"52adf0e5","executionInfo":{"status":"ok","timestamp":1654841118147,"user_tz":-480,"elapsed":5,"user":{"displayName":"QUEK HAO YONG, GABRIEL _","userId":"08861584446371432378"}}},"outputs":[],"source":["### Pre-Processing Text\n","words = utils.preprocess_text(corpus, fun_list = [utils.to_lower, utils.decontraction, utils.remove_punct], keep = '\\<|\\>')\n","words = re.sub('\\n',' \\n ', words)\n","words = re.split(' +', words) #Tokenising\n","\n","word_count = Counter(words) # Assumes end_token is already in the corpus\n","word_count[start_token] = 0\n","word_count[pad_token] = 0\n","\n","#Reference Dictionaries to convert one-hot index to string and vice versa\n","index_to_vocab = {i: k for i, k in enumerate(word_count.keys())}\n","vocab_to_index = {k: i for i, k in enumerate(word_count.keys())}\n","\n","songs = ' '.join(words)\n","songs = songs.split(' \\n \\n <eos> \\n \\n ')\n","songs = [song.split(' ') for song in songs]\n","songs = [[pad_token]*(window_len-1) + [start_token] + song + [end_token] + [pad_token]*(window_len-1) for song in songs]\n","songs_token_ind = [[vocab_to_index.get(x) for x in song] for song in songs]"]},{"cell_type":"code","source":["### Creating Dataset\n","x_encoder = []\n","x_decoder = []\n","y = []\n","vocab_size = len(word_count)\n","\n","for song in songs_token_ind:\n","  for i in range(len(song)-window_len):\n","    x_encoder.append(song[(i+1):(i+window_len+1)])\n","    x_decoder.append(song[i:(i+window_len)])\n","    y.append(song[i+window_len])"],"metadata":{"id":"FwuVvlRF-cgL","executionInfo":{"status":"ok","timestamp":1654841118147,"user_tz":-480,"elapsed":5,"user":{"displayName":"QUEK HAO YONG, GABRIEL _","userId":"08861584446371432378"}}},"id":"FwuVvlRF-cgL","execution_count":7,"outputs":[]},{"cell_type":"code","source":["rand_int = np.random.randint(0, len(x_encoder), 1)[0]\n","print([index_to_vocab.get(x) for x in x_encoder[rand_int]])\n","print([index_to_vocab.get(x) for x in x_decoder[rand_int]])\n","print(index_to_vocab.get(y[rand_int]))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"KY-CHZ0CcP2C","executionInfo":{"status":"ok","timestamp":1654841118651,"user_tz":-480,"elapsed":509,"user":{"displayName":"QUEK HAO YONG, GABRIEL _","userId":"08861584446371432378"}},"outputId":"ffd4ba59-57d9-4149-ceba-f1e510f0fa16"},"id":"KY-CHZ0CcP2C","execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["['future', '\\n', 'together', 'you', 'and', 'i', 'we', 'are', '\\n', '\\n', '<chorus>', '\\n', 'one', 'singapore', '\\n']\n","['brighter', 'future', '\\n', 'together', 'you', 'and', 'i', 'we', 'are', '\\n', '\\n', '<chorus>', '\\n', 'one', 'singapore']\n","\n","\n"]}]},{"cell_type":"code","source":["dataset = tf.data.Dataset.from_tensor_slices(((x_encoder, x_decoder), y))\n","dataset = dataset.shuffle(buffer_size = 10000, seed = random_seed)\n","dataset = dataset.map(lambda x, y: ((tf.one_hot(x[0], depth = vocab_size), tf.one_hot(x[1], depth = vocab_size)),\n","                                 tf.one_hot(y, depth = vocab_size)))\n","train_dataset = dataset.take(int((1-val_split)*len(dataset)))\n","val_dataset = dataset.skip(int((1-val_split)*len(dataset)))\n","\n","train_dataset_final = train_dataset.batch(batch_size).cache().prefetch(buffer_size=tf.data.AUTOTUNE)\n","val_dataset_final = val_dataset.batch(batch_size).cache().prefetch(buffer_size=tf.data.AUTOTUNE)"],"metadata":{"id":"Dk3I2VI1Nza3","executionInfo":{"status":"ok","timestamp":1654841122439,"user_tz":-480,"elapsed":3789,"user":{"displayName":"QUEK HAO YONG, GABRIEL _","userId":"08861584446371432378"}}},"id":"Dk3I2VI1Nza3","execution_count":9,"outputs":[]},{"cell_type":"code","execution_count":26,"id":"202bf8be","metadata":{"id":"202bf8be","colab":{"base_uri":"https://localhost:8080/"},"outputId":"4ff0272f-ca93-48d1-be52-a4294da370db","executionInfo":{"status":"ok","timestamp":1654843680063,"user_tz":-480,"elapsed":812,"user":{"displayName":"QUEK HAO YONG, GABRIEL _","userId":"08861584446371432378"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"model_1\"\n","__________________________________________________________________________________________________\n"," Layer (type)                   Output Shape         Param #     Connected to                     \n","==================================================================================================\n"," encoder_input (InputLayer)     [(None, 15, 1049)]   0           []                               \n","                                                                                                  \n"," decoder_input (InputLayer)     [(None, 15, 1049)]   0           []                               \n","                                                                                                  \n"," encoder_lstm (LSTM)            [(None, 256),        1337344     ['encoder_input[0][0]']          \n","                                 (None, 256),                                                     \n","                                 (None, 256)]                                                     \n","                                                                                                  \n"," decoder_lstm (LSTM)            (None, 256)          1337344     ['decoder_input[0][0]',          \n","                                                                  'encoder_lstm[0][1]',           \n","                                                                  'encoder_lstm[0][2]']           \n","                                                                                                  \n"," attention (Attention)          (None, 256)          0           ['decoder_lstm[0][0]',           \n","                                                                  'encoder_lstm[0][0]']           \n","                                                                                                  \n"," tf.concat_1 (TFOpLambda)       (None, 512)          0           ['decoder_lstm[0][0]',           \n","                                                                  'attention[0][0]']              \n","                                                                                                  \n"," output (Dense)                 (None, 1049)         538137      ['tf.concat_1[0][0]']            \n","                                                                                                  \n","==================================================================================================\n","Total params: 3,212,825\n","Trainable params: 3,212,825\n","Non-trainable params: 0\n","__________________________________________________________________________________________________\n"]}],"source":["# Encoder\n","encoder_input = layers.Input(shape=(window_len,vocab_size), name = 'encoder_input')\n","\n","# Return state in addition to output\n","encoder_output, encoder_hidden_state, encoder_cell_state = layers.LSTM(enc_dim,\n","                                                                       dropout = dropout, recurrent_dropout = recurrent_dropout,\n","                                                                       return_state=True, name = \"encoder_lstm\")(encoder_input)\n","\n","# Decoder\n","decoder_input = layers.Input(shape=(window_len,vocab_size), name = 'decoder_input')\n","\n","# Pass the encoder state to a new LSTM, as initial state\n","decoder_output = layers.LSTM(dec_dim,\n","                             dropout = dropout, recurrent_dropout = recurrent_dropout,\n","                             name=\"decoder_lstm\")(decoder_input, initial_state=[encoder_hidden_state, encoder_cell_state])\n","\n","# Attention\n","attention_context_vector = tf.keras.layers.Attention(name = 'attention')(inputs = [decoder_output, encoder_output])\n","\n","# Output\n","output = layers.Dense(vocab_size, name = 'output', activation = 'softmax')(tf.concat([decoder_output, attention_context_vector], 1))\n","\n","model = tf.keras.Model((encoder_input, decoder_input), output)\n","model.summary()"]},{"cell_type":"code","execution_count":27,"id":"83bb01d4","metadata":{"id":"83bb01d4","executionInfo":{"status":"ok","timestamp":1654843680063,"user_tz":-480,"elapsed":2,"user":{"displayName":"QUEK HAO YONG, GABRIEL _","userId":"08861584446371432378"}}},"outputs":[],"source":["model.compile(loss = 'categorical_crossentropy',\n","              optimizer = tf.keras.optimizers.Adam(learning_rate=learn_rate),\n","              metrics = ['accuracy'])"]},{"cell_type":"code","source":["### Callbacks\n","callback_es = tf.keras.callbacks.EarlyStopping(\n","    monitor='val_loss',\n","    min_delta=0,\n","    patience=5,\n","    verbose=1,\n","    mode='min',\n","    baseline=None,\n","    restore_best_weights=True\n",")\n","\n","callback_mc = tf.keras.callbacks.ModelCheckpoint(\n","    filepath=model_folder+'/weights.{epoch:02d}-{val_loss:.2f}-{val_accuracy:.2f}.hdf5',\n","    save_weights_only=True,\n","    monitor='val_loss',\n","    mode='min',\n","    save_best_only=True)"],"metadata":{"id":"oxvZ57pCIWWu","executionInfo":{"status":"ok","timestamp":1654843682904,"user_tz":-480,"elapsed":296,"user":{"displayName":"QUEK HAO YONG, GABRIEL _","userId":"08861584446371432378"}}},"id":"oxvZ57pCIWWu","execution_count":28,"outputs":[]},{"cell_type":"code","source":["history = model.fit(x = train_dataset_final, validation_data = val_dataset_final, epochs = epochs, callbacks = [callback_es, callback_mc])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hIOwUeQ0E0LD","outputId":"75206bbd-3829-4085-affd-6f23b6822fa4","executionInfo":{"status":"ok","timestamp":1654851144941,"user_tz":-480,"elapsed":7458610,"user":{"displayName":"QUEK HAO YONG, GABRIEL _","userId":"08861584446371432378"}}},"id":"hIOwUeQ0E0LD","execution_count":29,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/80\n","181/181 [==============================] - 133s 705ms/step - loss: 5.0912 - accuracy: 0.1840 - val_loss: 4.6535 - val_accuracy: 0.2197\n","Epoch 2/80\n","181/181 [==============================] - 124s 684ms/step - loss: 4.2379 - accuracy: 0.2520 - val_loss: 3.5873 - val_accuracy: 0.2997\n","Epoch 3/80\n","181/181 [==============================] - 126s 694ms/step - loss: 3.0037 - accuracy: 0.4063 - val_loss: 2.2561 - val_accuracy: 0.5703\n","Epoch 4/80\n","181/181 [==============================] - 124s 686ms/step - loss: 2.0851 - accuracy: 0.5957 - val_loss: 1.6548 - val_accuracy: 0.6895\n","Epoch 5/80\n","181/181 [==============================] - 126s 697ms/step - loss: 1.6361 - accuracy: 0.6735 - val_loss: 1.3503 - val_accuracy: 0.7266\n","Epoch 6/80\n","181/181 [==============================] - 126s 699ms/step - loss: 1.3772 - accuracy: 0.7214 - val_loss: 1.2353 - val_accuracy: 0.7495\n","Epoch 7/80\n","181/181 [==============================] - 126s 695ms/step - loss: 1.2427 - accuracy: 0.7422 - val_loss: 1.1605 - val_accuracy: 0.7564\n","Epoch 8/80\n","181/181 [==============================] - 126s 698ms/step - loss: 1.0849 - accuracy: 0.7652 - val_loss: 0.9748 - val_accuracy: 0.8105\n","Epoch 9/80\n","181/181 [==============================] - 124s 683ms/step - loss: 0.9546 - accuracy: 0.7936 - val_loss: 0.8181 - val_accuracy: 0.8413\n","Epoch 10/80\n","181/181 [==============================] - 127s 700ms/step - loss: 0.8544 - accuracy: 0.8133 - val_loss: 0.7769 - val_accuracy: 0.8510\n","Epoch 11/80\n","181/181 [==============================] - 131s 725ms/step - loss: 0.7734 - accuracy: 0.8326 - val_loss: 0.7022 - val_accuracy: 0.8680\n","Epoch 12/80\n","181/181 [==============================] - 150s 827ms/step - loss: 0.6651 - accuracy: 0.8545 - val_loss: 0.6292 - val_accuracy: 0.8857\n","Epoch 13/80\n","181/181 [==============================] - 126s 699ms/step - loss: 0.6288 - accuracy: 0.8601 - val_loss: 0.6341 - val_accuracy: 0.8947\n","Epoch 14/80\n","181/181 [==============================] - 129s 712ms/step - loss: 0.5709 - accuracy: 0.8707 - val_loss: 0.5792 - val_accuracy: 0.8999\n","Epoch 15/80\n","181/181 [==============================] - 126s 697ms/step - loss: 0.5409 - accuracy: 0.8773 - val_loss: 0.6072 - val_accuracy: 0.8850\n","Epoch 16/80\n","181/181 [==============================] - 128s 705ms/step - loss: 0.5451 - accuracy: 0.8734 - val_loss: 0.5137 - val_accuracy: 0.9175\n","Epoch 17/80\n","181/181 [==============================] - 125s 693ms/step - loss: 0.4812 - accuracy: 0.8890 - val_loss: 0.4989 - val_accuracy: 0.9158\n","Epoch 18/80\n","181/181 [==============================] - 152s 840ms/step - loss: 0.4849 - accuracy: 0.8865 - val_loss: 0.5080 - val_accuracy: 0.9196\n","Epoch 19/80\n","181/181 [==============================] - 158s 876ms/step - loss: 0.4138 - accuracy: 0.9055 - val_loss: 0.4655 - val_accuracy: 0.9238\n","Epoch 20/80\n","181/181 [==============================] - 127s 702ms/step - loss: 0.4082 - accuracy: 0.9058 - val_loss: 0.4260 - val_accuracy: 0.9349\n","Epoch 21/80\n","181/181 [==============================] - 126s 695ms/step - loss: 0.3879 - accuracy: 0.9106 - val_loss: 0.4213 - val_accuracy: 0.9338\n","Epoch 22/80\n","181/181 [==============================] - 125s 693ms/step - loss: 0.3712 - accuracy: 0.9135 - val_loss: 0.4128 - val_accuracy: 0.9328\n","Epoch 23/80\n","181/181 [==============================] - 127s 702ms/step - loss: 0.3669 - accuracy: 0.9161 - val_loss: 0.4069 - val_accuracy: 0.9352\n","Epoch 24/80\n","181/181 [==============================] - 126s 698ms/step - loss: 0.3220 - accuracy: 0.9264 - val_loss: 0.4369 - val_accuracy: 0.9186\n","Epoch 25/80\n","181/181 [==============================] - 125s 688ms/step - loss: 0.3381 - accuracy: 0.9220 - val_loss: 0.3641 - val_accuracy: 0.9404\n","Epoch 26/80\n","181/181 [==============================] - 127s 704ms/step - loss: 0.3181 - accuracy: 0.9264 - val_loss: 0.3021 - val_accuracy: 0.9501\n","Epoch 27/80\n","181/181 [==============================] - 125s 693ms/step - loss: 0.2911 - accuracy: 0.9308 - val_loss: 0.3513 - val_accuracy: 0.9383\n","Epoch 28/80\n","181/181 [==============================] - 126s 695ms/step - loss: 0.2570 - accuracy: 0.9398 - val_loss: 0.2698 - val_accuracy: 0.9574\n","Epoch 29/80\n","181/181 [==============================] - 125s 692ms/step - loss: 0.2622 - accuracy: 0.9388 - val_loss: 0.3049 - val_accuracy: 0.9494\n","Epoch 30/80\n","181/181 [==============================] - 126s 697ms/step - loss: 0.2643 - accuracy: 0.9367 - val_loss: 0.2410 - val_accuracy: 0.9636\n","Epoch 31/80\n","181/181 [==============================] - 125s 692ms/step - loss: 0.2761 - accuracy: 0.9351 - val_loss: 0.2542 - val_accuracy: 0.9622\n","Epoch 32/80\n","181/181 [==============================] - 125s 689ms/step - loss: 0.2433 - accuracy: 0.9425 - val_loss: 0.2466 - val_accuracy: 0.9636\n","Epoch 33/80\n","181/181 [==============================] - 126s 699ms/step - loss: 0.2166 - accuracy: 0.9492 - val_loss: 0.3089 - val_accuracy: 0.9439\n","Epoch 34/80\n","181/181 [==============================] - 126s 698ms/step - loss: 0.2111 - accuracy: 0.9502 - val_loss: 0.2386 - val_accuracy: 0.9667\n","Epoch 35/80\n","181/181 [==============================] - 127s 701ms/step - loss: 0.1835 - accuracy: 0.9581 - val_loss: 0.2114 - val_accuracy: 0.9719\n","Epoch 36/80\n","181/181 [==============================] - 125s 692ms/step - loss: 0.1765 - accuracy: 0.9593 - val_loss: 0.1912 - val_accuracy: 0.9761\n","Epoch 37/80\n","181/181 [==============================] - 126s 699ms/step - loss: 0.1563 - accuracy: 0.9647 - val_loss: 0.1887 - val_accuracy: 0.9761\n","Epoch 38/80\n","181/181 [==============================] - 124s 687ms/step - loss: 0.1747 - accuracy: 0.9595 - val_loss: 0.2008 - val_accuracy: 0.9712\n","Epoch 39/80\n","181/181 [==============================] - 126s 699ms/step - loss: 0.1606 - accuracy: 0.9636 - val_loss: 0.1931 - val_accuracy: 0.9740\n","Epoch 40/80\n","181/181 [==============================] - 125s 688ms/step - loss: 0.1426 - accuracy: 0.9690 - val_loss: 0.1996 - val_accuracy: 0.9737\n","Epoch 41/80\n","181/181 [==============================] - 126s 699ms/step - loss: 0.1268 - accuracy: 0.9712 - val_loss: 0.1874 - val_accuracy: 0.9751\n","Epoch 42/80\n","181/181 [==============================] - 124s 687ms/step - loss: 0.1302 - accuracy: 0.9708 - val_loss: 0.1997 - val_accuracy: 0.9733\n","Epoch 43/80\n","181/181 [==============================] - 123s 682ms/step - loss: 0.1874 - accuracy: 0.9564 - val_loss: 0.1982 - val_accuracy: 0.9737\n","Epoch 44/80\n","181/181 [==============================] - 126s 696ms/step - loss: 0.1356 - accuracy: 0.9662 - val_loss: 0.2045 - val_accuracy: 0.9726\n","Epoch 45/80\n","181/181 [==============================] - 125s 693ms/step - loss: 0.1337 - accuracy: 0.9703 - val_loss: 0.1888 - val_accuracy: 0.9726\n","Epoch 46/80\n","181/181 [==============================] - 127s 704ms/step - loss: 0.1253 - accuracy: 0.9718 - val_loss: 0.1837 - val_accuracy: 0.9792\n","Epoch 47/80\n","181/181 [==============================] - 125s 693ms/step - loss: 0.1123 - accuracy: 0.9757 - val_loss: 0.1899 - val_accuracy: 0.9733\n","Epoch 48/80\n","181/181 [==============================] - 126s 697ms/step - loss: 0.0969 - accuracy: 0.9778 - val_loss: 0.1751 - val_accuracy: 0.9792\n","Epoch 49/80\n","181/181 [==============================] - 124s 686ms/step - loss: 0.1058 - accuracy: 0.9764 - val_loss: 0.1828 - val_accuracy: 0.9789\n","Epoch 50/80\n","181/181 [==============================] - 126s 695ms/step - loss: 0.1087 - accuracy: 0.9745 - val_loss: 0.1867 - val_accuracy: 0.9789\n","Epoch 51/80\n","181/181 [==============================] - 124s 685ms/step - loss: 0.1092 - accuracy: 0.9746 - val_loss: 0.1901 - val_accuracy: 0.9740\n","Epoch 52/80\n","181/181 [==============================] - 124s 686ms/step - loss: 0.0976 - accuracy: 0.9764 - val_loss: 0.2095 - val_accuracy: 0.9685\n","Epoch 53/80\n","181/181 [==============================] - ETA: 0s - loss: 0.1041 - accuracy: 0.9746Restoring model weights from the end of the best epoch: 48.\n","181/181 [==============================] - 128s 707ms/step - loss: 0.1041 - accuracy: 0.9746 - val_loss: 0.1958 - val_accuracy: 0.9775\n","Epoch 53: early stopping\n"]}]},{"cell_type":"code","source":["model.save_weights(model_folder+'/final_weights.{epoch:02d}-{val_loss:.2f}-{val_accuracy:.2f}.hdf5')"],"metadata":{"id":"QhFHlI6o06Gz","executionInfo":{"status":"ok","timestamp":1654852354618,"user_tz":-480,"elapsed":346,"user":{"displayName":"QUEK HAO YONG, GABRIEL _","userId":"08861584446371432378"}}},"id":"QhFHlI6o06Gz","execution_count":36,"outputs":[]},{"cell_type":"code","source":["def generate_text(model, start_string, num_generate = 1000, temperature=1.0, random_seed = 2022):\n","    # Converting our start string to numbers (vectorizing).\n","    input_indices = [vocab_to_index.get(s) for i, s in enumerate(start_string) if i < window_len-1]\n","    input_indices = [i if i is not None else vocab_to_index.get(pad_token) for i in input_indices]\n","    input_indices = [vocab_to_index.get(pad_token)]*(window_len - len(input_indices)-1) + [vocab_to_index.get(start_token)] + input_indices\n","\n","    input_oh = tf.one_hot(input_indices, depth = vocab_size)\n","    x = tf.expand_dims(input_oh, 0)\n","\n","    # Empty string to store our results.\n","    text_generated = []\n","\n","    # Here batch size == 1.\n","    model.reset_states()\n","    for word_index in range(num_generate):\n","        prediction = model.predict([x,x])\n","\n","        # Using a categorical distribution to predict the character returned by the model.\n","        prediction = prediction / temperature\n","        predicted_id = tf.random.categorical(prediction, num_samples=1, seed = random_seed)[-1,0]\n","        predicted_oh = tf.one_hot(predicted_id, depth = vocab_size)\n","\n","        # We pass the series of previous words (up to window length) as the next input to the model\n","        # along with the previous hidden state.\n","        input_index = tf.expand_dims([predicted_oh], 0)\n","        x = tf.concat([x[:,1:,:],input_index], 1)\n","        \n","        pred_word = index_to_vocab[predicted_id.numpy()]\n","        text_generated.append(pred_word)\n","        if pred_word == end_token:\n","            break\n","    \n","    return (' '.join(start_string) + ' ' + ' '.join(text_generated)), text_generated"],"metadata":{"id":"_ANJJNQGSpdx","executionInfo":{"status":"ok","timestamp":1654852801115,"user_tz":-480,"elapsed":2,"user":{"displayName":"QUEK HAO YONG, GABRIEL _","userId":"08861584446371432378"}}},"id":"_ANJJNQGSpdx","execution_count":47,"outputs":[]},{"cell_type":"code","source":["def tokenize_text(text):\n","    words = utils.preprocess_text(text, fun_list = [utils.to_lower, utils.decontraction, utils.remove_punct], keep = '\\<|\\>')\n","    words = re.sub('\\n',' \\n ', words)\n","    words = re.split(' +', words) #Tokenising\n","    return words"],"metadata":{"id":"PVdlteA_5MAn","executionInfo":{"status":"ok","timestamp":1654852801512,"user_tz":-480,"elapsed":2,"user":{"displayName":"QUEK HAO YONG, GABRIEL _","userId":"08861584446371432378"}}},"id":"PVdlteA_5MAn","execution_count":48,"outputs":[]},{"cell_type":"code","source":["prompts = ['Whenever I think back', 'And so this I know',\n","           'I am tired of being what you want me to be', 'Feeling so faithless, lost under the surface',\n","           'Relight our fire, we will find our way', 'We will rise stronger together']\n","result_strings = {}\n","results = {}\n","for prompt in prompts:\n","    tokenized_prompt = tokenize_text(prompt)\n","    result_str, result = generate_text(model, start_string=tokenized_prompt, num_generate=100, temperature=1.0)\n","    result_strings[prompt] = result_str\n","    results[prompt] = result\n","\n","final_str = f'\\n\\n{end_token}\\n\\n'.join([f'{k}:\\n{v}' for k, v in result_strings.items()])"],"metadata":{"id":"wo0aCkdPL2EU","executionInfo":{"status":"ok","timestamp":1654852870845,"user_tz":-480,"elapsed":67869,"user":{"displayName":"QUEK HAO YONG, GABRIEL _","userId":"08861584446371432378"}}},"id":"wo0aCkdPL2EU","execution_count":49,"outputs":[]},{"cell_type":"code","source":["print(final_str)"],"metadata":{"id":"smPNycjBnDXa","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1654852870846,"user_tz":-480,"elapsed":13,"user":{"displayName":"QUEK HAO YONG, GABRIEL _","userId":"08861584446371432378"}},"outputId":"1a78830f-49fe-4ce4-e929-6315fbe3c0ce"},"id":"smPNycjBnDXa","execution_count":50,"outputs":[{"output_type":"stream","name":"stdout","text":["Whenever I think back:\n","whenever i think back turning breath peace fabric say bloom warm island stars amazed breathe needs yourself candle started religion way gave everywhere enduring blue close unwind add seems isle blood sail built international zeal mine the language candle early stepping sunny wide distance colleagues send alone then neighbourhood plays many when miracles old race contradict embrace test am strides conquer raise met give stay ours out land brand amazed why common starting dreaming wishes yet under candle towards strides dawn else core roar sons quay cos toil hands means men land wait used heartbeat mornings seemed ago cares bursts unreal summing ooh wave\n","\n","<eos>\n","\n","And so this I know:\n","and so this i know ocean moments bay begin wherever climbing start forget steady gave failing brings recess surprises knowledge name sons yeah let anthem unfold map about again takes wide tears carried daunting brighter rocky write could citizens okay over passing room news chance minute those above broadway name dawns remain sown us fine wherever bombay <verse> scale road drop amazed brother lion try courage expect stage wind over walking a pledge current waiting run flame set streams seems who get warmth forward future workplace collyer bright minute travelling thoughts old from build melody wherever care strides last find excited loud quarter look peaceful\n","\n","<eos>\n","\n","I am tired of being what you want me to be:\n","i am tired of being what you want me to be better fine worlds forevermore low ordinary lively memories moving sea finding come others sand divine memories highest cares songs reality speak we dark firm done real start set fall sit belong nice guess put town youth loyal united garden matter minds rainbow workplace little hidden senses granted each mountain make roads heart letting gem peaceful grand amazed than see familiar book roads lend beautiful joyful <prelude> this simple heritage win step sounds beyond climbed bloom nor learn experienced miracles bombay colour unforgettable thinking skies feels safe learn raffles kitchen happy may difference stage full stars carry needs as melody uncertain\n","\n","<eos>\n","\n","Feeling so faithless, lost under the surface:\n","feeling so faithless lost under the surface creed lived perfect and bring swim got hard aloud song passing echoing stirred singaporean singing ben could far blood page living drum greenery journey stories surprises paved vast it’s teach he aloud waiting lights values brings raffles selfexplanatory peers fall colours an try mine recess scale creed means given achieve down uncertain ages melody word pioneers seeds youthful different heartaches sunrise words even with choices its corner lamp <others> begin hardly alive heed yeah enchanting braver sensation hardly sign dark struggle find united climbed love neighbour lands that signs prosperity far amazing undivided voices here such pushed creed starting pleasure\n","\n","<eos>\n","\n","Relight our fire, we will find our way:\n","relight our fire we will find our way cared tiny simple word come flight care step downstairs grain religion standing beside think would hopes spirit magazine surprises take swim breakfast leaving knowledge tall journey excited their realize page on island into visions adore around went air bursts visions welcome hurry twinkling verge part tourists spirit moment wave keeping firm thankful morning dating blend star send parks memories full keeping walking amazed ourselves bus magic working knew spirit move live cos the plays horizon bring warmth clean their grand democratic greenery beginning thee home city really written amazed full trust win imagine window near somewhere quiet visions fresh then\n","\n","<eos>\n","\n","We will rise stronger together:\n","we will rise stronger together hoping get lift spot neon here opened tall set can hold each whatever brightly we isle creating sometimes quick cooled grows pains style <eos>\n"]}]},{"cell_type":"code","source":["with open(model_folder+'/generated_text.txt', 'w') as f:\n","    f.write(final_str)"],"metadata":{"id":"PgGgpFvaxDuL","executionInfo":{"status":"ok","timestamp":1654852870846,"user_tz":-480,"elapsed":11,"user":{"displayName":"QUEK HAO YONG, GABRIEL _","userId":"08861584446371432378"}}},"id":"PgGgpFvaxDuL","execution_count":51,"outputs":[]},{"cell_type":"code","source":[""],"metadata":{"id":"0khfSuko6eX5"},"id":"0khfSuko6eX5","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.8"},"colab":{"name":"Autoencoder (LSTM) with Attention.ipynb","provenance":[{"file_id":"1KbPSOprQ0mhAGFUtVsBjF4O_vkFuvgL9","timestamp":1654815454538},{"file_id":"1L31juRVcjedsJQLb65vDeIYnGfc5VeMn","timestamp":1654812818685},{"file_id":"1s0I-h_H-57P4mfHpn7K9ARRffBzA2996","timestamp":1654811271378},{"file_id":"1fSgHJcraq0bKZQlGXUqlQ4abpWOsgdIu","timestamp":1654782642697},{"file_id":"1_pyvxTi14GzEPtSGxMTy55XDNlCfsK0h","timestamp":1654781952290},{"file_id":"164GHOXuG8X-6WN_mbIfShYez3xOdSrkL","timestamp":1654771075102}],"collapsed_sections":[]},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":5}