{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'pip' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n"
     ]
    }
   ],
   "source": [
    "!pip install rouge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import re\n",
    "import json \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Custom Imports\n",
    "sys.path.append('../')\n",
    "import lib.utilities as utils\n",
    "from lib.bleu_rouge import bleu_rouge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../../output/prompt_ref.json') as f:\n",
    "    prompt_ref = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    text = re.sub(r'<[A-Z]+>|', '', text)\n",
    "    text = re.sub(r' +', ' ', text).strip()\n",
    "    text = re.sub(r'\\n\\n', '\\n', text)\n",
    "    text = re.sub(r'\\n \\n', '\\n', text)\n",
    "    text = re.sub(r' \\n', '\\n', text)\n",
    "    text = re.sub(r'\\n ', '\\n', text)\n",
    "    text = re.sub(r'\\n+', '\\n', text)\n",
    "    text = text.split('\\n')\n",
    "    if len(text) > 1:\n",
    "        prompt, generated = text[0], text[1]\n",
    "    else:\n",
    "        prompt, generated = text[0], text[-1]\n",
    "    return prompt, generated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = '../../output/'\n",
    "all_files = os.listdir(PATH)\n",
    "text_files = [file for file in all_files if re.search(r'\\.txt$', file)]\n",
    "br_files, human_files = [], []\n",
    "for file in text_files:\n",
    "    if 'br_' in file:\n",
    "        br_files.append(file)\n",
    "    elif 'human_' in file:\n",
    "        human_files.append(file)\n",
    "\n",
    "br_text = []\n",
    "for file in br_files:\n",
    "    with open(PATH + file) as f:\n",
    "        file = file.replace('-', '_')\n",
    "        text = clean_text(f.read())\n",
    "        prompt = file.split('_')[-1].replace('.txt', '')\n",
    "        if 'ae_' in file:            \n",
    "            br_text.append(('_'.join(file.split('_')[1:-1]), prompt, text[-1].replace(prompt+' ', '')))\n",
    "        else:\n",
    "            br_text.append(('_'.join(file.split('_')[1:-1]), prompt, text[1]))\n",
    "\n",
    "# human_text = []\n",
    "# for file in human_files:\n",
    "#     with open(PATH + file) as f:\n",
    "#         text = clean_text(f.read())\n",
    "#         human_text.append((file.split('_')[1], text[0], text[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate Bleu and Rouge Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('ae_lstm_att_mask', 'amazing in all ways', 'a new heart day that')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "br_text[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "br = bleu_rouge(prompt_ref)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\TeYang\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\nltk\\translate\\bleu_score.py:516: UserWarning: \n",
      "The hypothesis contains 0 counts of 2-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Users\\TeYang\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\nltk\\translate\\bleu_score.py:516: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Users\\TeYang\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\nltk\\translate\\bleu_score.py:516: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n"
     ]
    }
   ],
   "source": [
    "for i,x in enumerate(br_text):\n",
    "    bleu = br.compute_bleu(x[1], x[2], verbose=False)['Avg']\n",
    "    rouge = br.compute_rouge(x[1], x[2], verbose=False)\n",
    "    rouge = (rouge['rouge-1']['r'] + rouge['rouge-2']['r'] + rouge['rouge-l']['r']) / 3\n",
    "    br_text[i] = x + (bleu, rouge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>bleu</th>\n",
       "      <th>rouge</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>GPT2</td>\n",
       "      <td>0.072678</td>\n",
       "      <td>0.074489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>GRU</td>\n",
       "      <td>0.054326</td>\n",
       "      <td>0.074581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LSTM</td>\n",
       "      <td>0.053776</td>\n",
       "      <td>0.070360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RNN</td>\n",
       "      <td>0.034844</td>\n",
       "      <td>0.040848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>ae_lstm_att_mask</td>\n",
       "      <td>0.022745</td>\n",
       "      <td>0.029675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ae_gru_att</td>\n",
       "      <td>0.005446</td>\n",
       "      <td>0.023640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ae_lstm</td>\n",
       "      <td>0.004096</td>\n",
       "      <td>0.010997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>ae_rnn</td>\n",
       "      <td>0.002783</td>\n",
       "      <td>0.019138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>ae_rnn_att</td>\n",
       "      <td>0.001207</td>\n",
       "      <td>0.015922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ae_lstm_att</td>\n",
       "      <td>0.000898</td>\n",
       "      <td>0.012788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ae_gru</td>\n",
       "      <td>0.000692</td>\n",
       "      <td>0.010334</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               model      bleu     rouge\n",
       "0               GPT2  0.072678  0.074489\n",
       "1                GRU  0.054326  0.074581\n",
       "2               LSTM  0.053776  0.070360\n",
       "3                RNN  0.034844  0.040848\n",
       "8   ae_lstm_att_mask  0.022745  0.029675\n",
       "5         ae_gru_att  0.005446  0.023640\n",
       "6            ae_lstm  0.004096  0.010997\n",
       "9             ae_rnn  0.002783  0.019138\n",
       "10        ae_rnn_att  0.001207  0.015922\n",
       "7        ae_lstm_att  0.000898  0.012788\n",
       "4             ae_gru  0.000692  0.010334"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "br_df = pd.DataFrame.from_records(br_text, columns=['model','prompt','generated', 'bleu', 'rouge'])\n",
    "br_df = br_df.groupby(['model']).agg({'bleu':'mean', 'rouge':'mean'}).reset_index()\n",
    "br_df = br_df.sort_values(['bleu', 'rouge'], ascending=False)\n",
    "br_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>bleu</th>\n",
       "      <th>rouge</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>GPT2</td>\n",
       "      <td>0.072678</td>\n",
       "      <td>0.074489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>GRU</td>\n",
       "      <td>0.054326</td>\n",
       "      <td>0.074581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LSTM</td>\n",
       "      <td>0.053776</td>\n",
       "      <td>0.070360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RNN</td>\n",
       "      <td>0.034844</td>\n",
       "      <td>0.040848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>s2s_lstm_att</td>\n",
       "      <td>0.032500</td>\n",
       "      <td>0.039589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ae_lstm_att_mask</td>\n",
       "      <td>0.022745</td>\n",
       "      <td>0.029675</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              model      bleu     rouge\n",
       "0              GPT2  0.072678  0.074489\n",
       "1               GRU  0.054326  0.074581\n",
       "2              LSTM  0.053776  0.070360\n",
       "3               RNN  0.034844  0.040848\n",
       "5      s2s_lstm_att  0.032500  0.039589\n",
       "4  ae_lstm_att_mask  0.022745  0.029675"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "br_df = pd.DataFrame.from_records(br_text, columns=['model','prompt','generated', 'bleu', 'rouge'])\n",
    "br_df = br_df.groupby(['model']).agg({'bleu':'mean', 'rouge':'mean'}).reset_index()\n",
    "br_df = br_df.sort_values(['bleu', 'rouge'], ascending=False)\n",
    "br_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate bleu and rouge for 6 standard prompts?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "standard_prompt_ref = {\n",
    "    \n",
    "}\n",
    "br = bleu_rouge(prompt_ref)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "PROMPT does NOT exist in sampled prompts.\n            Run get_prompt_reference() to get prompt samples and check\n            bleu_rogue.prompt_ref for the set of prompts and references",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-16-ee729a0ba615>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhuman_text\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m     \u001b[0mbleu\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompute_bleu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Avg'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m     \u001b[0mrouge\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompute_rouge\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mrouge\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mrouge\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'rouge-1'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'r'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mrouge\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'rouge-2'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'r'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mrouge\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'rouge-l'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'r'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m/\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mhuman_text\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mbleu\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrouge\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\TeYang\\OneDrive\\School\\SMU\\Modules\\CS605_NLP_for_Smart_Assistants\\Project\\NLP-Lyric-Generator\\src\\lib\\bleu_rouge.py\u001b[0m in \u001b[0;36mcompute_bleu\u001b[1;34m(self, prompt, generated_text, verbose)\u001b[0m\n\u001b[0;32m     68\u001b[0m             \u001b[0mRun\u001b[0m \u001b[0mget_prompt_reference\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[0mto\u001b[0m \u001b[0mget\u001b[0m \u001b[0mprompt\u001b[0m \u001b[0msamples\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mcheck\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m             bleu_rogue.prompt_ref for the set of prompts and references\"\"\"\n\u001b[1;32m---> 70\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0merror_text\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     71\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     72\u001b[0m         \u001b[0mref\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mref\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m' '\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;31m# ref is list of tokens in list of ref\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: PROMPT does NOT exist in sampled prompts.\n            Run get_prompt_reference() to get prompt samples and check\n            bleu_rogue.prompt_ref for the set of prompts and references"
     ]
    }
   ],
   "source": [
    "for i,x in enumerate(human_text):\n",
    "    bleu = br.compute_bleu(x[1], x[2], verbose=False)['Avg']\n",
    "    rouge = br.compute_rouge(x[1], x[2], verbose=False)\n",
    "    rouge = (rouge['rouge-1']['r'] + rouge['rouge-2']['r'] + rouge['rouge-l']['r']) / 3\n",
    "    human_text[i] = x + (bleu, rouge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "586d209818bf684a449db8f551e5b280da9ad8c053944ce342fb8dd6eec39ab8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
