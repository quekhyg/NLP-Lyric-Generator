{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "57ce8745",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "start_time = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "587e21d5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['home', '<new>', 'wherever', 'i', 'may', 'be', '<new>', 'i', 'never', 'will', 'forget', 'her', '<new>', 'nor', 'will']\n",
      "['island', 'home', '<new>', 'wherever', 'i', 'may', 'be', '<new>', 'i', 'never', 'will', 'forget', 'her', '<new>', 'nor']\n",
      "will\n",
      "['what', 'singapore', 'can', 'be', '<new>', 'we', 'can', 'achieve', 'we', 'can', 'achieve', '<new>', '<new>', '<verse>', '<new>']\n",
      "['world', 'what', 'singapore', 'can', 'be', '<new>', 'we', 'can', 'achieve', 'we', 'can', 'achieve', '<new>', '<new>', '<verse>']\n",
      "<new>\n",
      "Model: \"ae_rnn\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " encoder_input (InputLayer)     [(None, 15, 1042)]   0           []                               \n",
      "                                                                                                  \n",
      " decoder_input (InputLayer)     [(None, 15, 1042)]   0           []                               \n",
      "                                                                                                  \n",
      " encoder_rnn (SimpleRNN)        [(None, 256),        332544      ['encoder_input[0][0]']          \n",
      "                                 (None, 256)]                                                     \n",
      "                                                                                                  \n",
      " decoder_rnn (SimpleRNN)        (None, 256)          332544      ['decoder_input[0][0]',          \n",
      "                                                                  'encoder_rnn[0][1]']            \n",
      "                                                                                                  \n",
      " output (Dense)                 (None, 1042)         267794      ['decoder_rnn[0][0]']            \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 932,882\n",
      "Trainable params: 932,882\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "%run autoencoder_rnn.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "265474fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken: 35.9min\n"
     ]
    }
   ],
   "source": [
    "print(f'Time taken: {(time.time()-start_time)/60:.1f}min')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1ab81a26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['world', 'just', 'where', 'we', 'stand', '<new>', 'and', 'reach', 'out', 'for', 'singapore', 'join', 'our', 'hands', 'forevermore']\n",
      "['the', 'world', 'just', 'where', 'we', 'stand', '<new>', 'and', 'reach', 'out', 'for', 'singapore', 'join', 'our', 'hands']\n",
      "forevermore\n",
      "['our', 'singaporean', 'life', '<new>', 'everyone', 'is', 'family', 'friend', 'and', 'neighbour', '<new>', 'living', 'in', 'harmony', '<new>']\n",
      "['is', 'our', 'singaporean', 'life', '<new>', 'everyone', 'is', 'family', 'friend', 'and', 'neighbour', '<new>', 'living', 'in', 'harmony']\n",
      "<new>\n",
      "Model: \"ae_rnn_att\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " encoder_input (InputLayer)     [(None, 15, 1042)]   0           []                               \n",
      "                                                                                                  \n",
      " decoder_input (InputLayer)     [(None, 15, 1042)]   0           []                               \n",
      "                                                                                                  \n",
      " encoder_rnn (SimpleRNN)        [(None, 256),        332544      ['encoder_input[0][0]']          \n",
      "                                 (None, 256)]                                                     \n",
      "                                                                                                  \n",
      " decoder_rnn (SimpleRNN)        (None, 256)          332544      ['decoder_input[0][0]',          \n",
      "                                                                  'encoder_rnn[0][1]']            \n",
      "                                                                                                  \n",
      " attention (Attention)          (None, 256)          0           ['decoder_rnn[0][0]',            \n",
      "                                                                  'encoder_rnn[0][0]']            \n",
      "                                                                                                  \n",
      " tf.concat (TFOpLambda)         (None, 512)          0           ['decoder_rnn[0][0]',            \n",
      "                                                                  'attention[0][0]']              \n",
      "                                                                                                  \n",
      " output (Dense)                 (None, 1042)         534546      ['tf.concat[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 1,199,634\n",
      "Trainable params: 1,199,634\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "%run autoencoder_rnn_with_attention.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "39c43513",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken: 44.8min\n"
     ]
    }
   ],
   "source": [
    "print(f'Time taken: {(time.time()-start_time)/60:.1f}min')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "42e1a944",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['oh', '<new>', 'our', 'home', '<new>', 'our', 'heart', '<new>', 'our', 'dream', '<eos>', '<pad>', '<pad>', '<pad>', '<pad>']\n",
      "['oh', 'oh', '<new>', 'our', 'home', '<new>', 'our', 'heart', '<new>', 'our', 'dream', '<eos>', '<pad>', '<pad>', '<pad>']\n",
      "<pad>\n",
      "['<pad>', '<pad>', '<pad>', '<pad>', '<cls>', '<verse>', '<new>', 'have', 'you', 'seen', 'a', 'star', '<new>', 'one', 'that']\n",
      "['<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<cls>', '<verse>', '<new>', 'have', 'you', 'seen', 'a', 'star', '<new>', 'one']\n",
      "that\n",
      "WARNING:tensorflow:Layer encoder_gru will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer decoder_gru will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Model: \"ae_gru\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " encoder_input (InputLayer)     [(None, 15, 1042)]   0           []                               \n",
      "                                                                                                  \n",
      " decoder_input (InputLayer)     [(None, 15, 1042)]   0           []                               \n",
      "                                                                                                  \n",
      " encoder_gru (GRU)              [(None, 256),        998400      ['encoder_input[0][0]']          \n",
      "                                 (None, 256)]                                                     \n",
      "                                                                                                  \n",
      " decoder_gru (GRU)              (None, 256)          998400      ['decoder_input[0][0]',          \n",
      "                                                                  'encoder_gru[0][1]']            \n",
      "                                                                                                  \n",
      " output (Dense)                 (None, 1042)         267794      ['decoder_gru[0][0]']            \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 2,264,594\n",
      "Trainable params: 2,264,594\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "%run autoencoder_gru.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "07607741",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken: 56.3min\n"
     ]
    }
   ],
   "source": [
    "print(f'Time taken: {(time.time()-start_time)/60:.1f}min')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5e2ff22b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['with', 'me', '<new>', 'so', 'i', 'will', 'cross', 'the', 'skies', 'and', 'sail', 'the', 'seas', '<new>', 'to']\n",
      "['up', 'with', 'me', '<new>', 'so', 'i', 'will', 'cross', 'the', 'skies', 'and', 'sail', 'the', 'seas', '<new>']\n",
      "to\n",
      "['<new>', '<new>', '<chorus>', '<new>', 'together', 'we', 'make', 'a', 'difference', '<new>', 'one', 'voice', 'one', 'destiny', '<new>']\n",
      "['heartbeat', '<new>', '<new>', '<chorus>', '<new>', 'together', 'we', 'make', 'a', 'difference', '<new>', 'one', 'voice', 'one', 'destiny']\n",
      "<new>\n",
      "WARNING:tensorflow:Layer encoder_gru will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer decoder_gru will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Model: \"ae_gru_att\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " encoder_input (InputLayer)     [(None, 15, 1042)]   0           []                               \n",
      "                                                                                                  \n",
      " decoder_input (InputLayer)     [(None, 15, 1042)]   0           []                               \n",
      "                                                                                                  \n",
      " encoder_gru (GRU)              [(None, 256),        998400      ['encoder_input[0][0]']          \n",
      "                                 (None, 256)]                                                     \n",
      "                                                                                                  \n",
      " decoder_gru (GRU)              (None, 256)          998400      ['decoder_input[0][0]',          \n",
      "                                                                  'encoder_gru[0][1]']            \n",
      "                                                                                                  \n",
      " attention (Attention)          (None, 256)          0           ['decoder_gru[0][0]',            \n",
      "                                                                  'encoder_gru[0][0]']            \n",
      "                                                                                                  \n",
      " tf.concat_1 (TFOpLambda)       (None, 512)          0           ['decoder_gru[0][0]',            \n",
      "                                                                  'attention[0][0]']              \n",
      "                                                                                                  \n",
      " output (Dense)                 (None, 1042)         534546      ['tf.concat_1[0][0]']            \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 2,531,346\n",
      "Trainable params: 2,531,346\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "%run autoencoder_gru_with_attention.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ec8ccd96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken: 67.5min\n"
     ]
    }
   ],
   "source": [
    "print(f'Time taken: {(time.time()-start_time)/60:.1f}min')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1b2dd87b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['afar', '<new>', 'into', 'the', 'world', 'to', 'be', 'the', 'best', '<new>', 'there', 'is', 'so', 'much', 'to']\n",
      "['us', 'afar', '<new>', 'into', 'the', 'world', 'to', 'be', 'the', 'best', '<new>', 'there', 'is', 'so', 'much']\n",
      "to\n",
      "['we', 'will', 'make', 'it', '<new>', 'you', 'and', 'me', 'we', 'will', 'work', 'together', '<new>', 'hand', 'in']\n",
      "['day', 'we', 'will', 'make', 'it', '<new>', 'you', 'and', 'me', 'we', 'will', 'work', 'together', '<new>', 'hand']\n",
      "in\n",
      "WARNING:tensorflow:Layer encoder_lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer decoder_lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Model: \"ae_lstm\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " encoder_input (InputLayer)     [(None, 15, 1042)]   0           []                               \n",
      "                                                                                                  \n",
      " decoder_input (InputLayer)     [(None, 15, 1042)]   0           []                               \n",
      "                                                                                                  \n",
      " encoder_lstm (LSTM)            [(None, 256),        1330176     ['encoder_input[0][0]']          \n",
      "                                 (None, 256),                                                     \n",
      "                                 (None, 256)]                                                     \n",
      "                                                                                                  \n",
      " decoder_lstm (LSTM)            (None, 256)          1330176     ['decoder_input[0][0]',          \n",
      "                                                                  'encoder_lstm[0][1]',           \n",
      "                                                                  'encoder_lstm[0][2]']           \n",
      "                                                                                                  \n",
      " output (Dense)                 (None, 1042)         267794      ['decoder_lstm[0][0]']           \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 2,928,146\n",
      "Trainable params: 2,928,146\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "%run autoencoder_lstm.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "84c81678",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken: 79.0min\n"
     ]
    }
   ],
   "source": [
    "print(f'Time taken: {(time.time()-start_time)/60:.1f}min')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "13385ef1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['to', 'strive', 'and', 'to', 'achieve', '<new>', 'with', 'hopes', 'within', 'our', 'hearts', '<new>', 'as', 'one', 'hand']\n",
      "['<new>', 'to', 'strive', 'and', 'to', 'achieve', '<new>', 'with', 'hopes', 'within', 'our', 'hearts', '<new>', 'as', 'one']\n",
      "hand\n",
      "['<new>', 'there', 'is', 'a', 'new', 'moon', 'arising', '<new>', 'out', 'of', 'the', 'stormy', 'sea', '<new>', 'youthful']\n",
      "['<verse>', '<new>', 'there', 'is', 'a', 'new', 'moon', 'arising', '<new>', 'out', 'of', 'the', 'stormy', 'sea', '<new>']\n",
      "youthful\n",
      "WARNING:tensorflow:Layer encoder_lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer decoder_lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Model: \"ae_lstm_att\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " encoder_input (InputLayer)     [(None, 15, 1042)]   0           []                               \n",
      "                                                                                                  \n",
      " decoder_input (InputLayer)     [(None, 15, 1042)]   0           []                               \n",
      "                                                                                                  \n",
      " encoder_lstm (LSTM)            [(None, 256),        1330176     ['encoder_input[0][0]']          \n",
      "                                 (None, 256),                                                     \n",
      "                                 (None, 256)]                                                     \n",
      "                                                                                                  \n",
      " decoder_lstm (LSTM)            (None, 256)          1330176     ['decoder_input[0][0]',          \n",
      "                                                                  'encoder_lstm[0][1]',           \n",
      "                                                                  'encoder_lstm[0][2]']           \n",
      "                                                                                                  \n",
      " attention (Attention)          (None, 256)          0           ['decoder_lstm[0][0]',           \n",
      "                                                                  'encoder_lstm[0][0]']           \n",
      "                                                                                                  \n",
      " tf.concat_2 (TFOpLambda)       (None, 512)          0           ['decoder_lstm[0][0]',           \n",
      "                                                                  'attention[0][0]']              \n",
      "                                                                                                  \n",
      " output (Dense)                 (None, 1042)         534546      ['tf.concat_2[0][0]']            \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 3,194,898\n",
      "Trainable params: 3,194,898\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "%run autoencoder_lstm_with_attention.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "81d3537c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken: 90.8min\n"
     ]
    }
   ],
   "source": [
    "print(f'Time taken: {(time.time()-start_time)/60:.1f}min')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0a5190fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for lstm v3 (with masking)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "067a5cee",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['<new>', 'because', 'in', 'singapore', 'singapore', '<new>', 'you', 'will', 'find', 'happiness', 'for', 'everyone', '<new>', '<new>', '<mask>']\n",
      "['find', '<new>', 'because', 'in', 'singapore', 'singapore', '<new>', 'you', 'will', 'find', 'happiness', 'for', 'everyone', '<new>', '<new>']\n",
      "<verse>\n",
      "['new', '<new>', 'in', 'every', 'place', 'so', 'fresh', 'and', 'clean', 'on', 'sunny', 'beaches', 'too', '<new>', '<mask>']\n",
      "['housings', 'new', '<new>', 'in', 'every', 'place', 'so', 'fresh', 'and', 'clean', 'on', 'sunny', 'beaches', 'too', '<new>']\n",
      "<new>\n",
      "WARNING:tensorflow:Layer encoder_lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer decoder_lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Model: \"ae_lstm_att_mask\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " encoder_input (InputLayer)     [(None, 15, 1042)]   0           []                               \n",
      "                                                                                                  \n",
      " decoder_input (InputLayer)     [(None, 15, 1042)]   0           []                               \n",
      "                                                                                                  \n",
      " encoder_lstm (LSTM)            [(None, 256),        1330176     ['encoder_input[0][0]']          \n",
      "                                 (None, 256),                                                     \n",
      "                                 (None, 256)]                                                     \n",
      "                                                                                                  \n",
      " decoder_lstm (LSTM)            (None, 256)          1330176     ['decoder_input[0][0]',          \n",
      "                                                                  'encoder_lstm[0][1]',           \n",
      "                                                                  'encoder_lstm[0][2]']           \n",
      "                                                                                                  \n",
      " attention (Attention)          (None, 256)          0           ['decoder_lstm[0][0]',           \n",
      "                                                                  'encoder_lstm[0][0]']           \n",
      "                                                                                                  \n",
      " tf.concat_3 (TFOpLambda)       (None, 512)          0           ['decoder_lstm[0][0]',           \n",
      "                                                                  'attention[0][0]']              \n",
      "                                                                                                  \n",
      " output (Dense)                 (None, 1042)         534546      ['tf.concat_3[0][0]']            \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 3,194,898\n",
      "Trainable params: 3,194,898\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "%run autoencoder_lstm_with_attention_and_masking.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "98e3b15f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken: 100.5min\n"
     ]
    }
   ],
   "source": [
    "print(f'Time taken: {(time.time()-start_time)/60:.1f}min')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bcd86274",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['there', 'for', 'me', '<new>', '<new>', '<chorus>', '<new>', 'this', 'is', 'where', 'we', 'will', 'see', '<new>', 'familiar']\n",
      "faces\n",
      "['for', 'today', '<new>', 'foundations', 'that', 'are', 'here', 'to', 'stay', '<new>', 'we', 'are', 'the', 'ones', 'who']\n",
      "find\n",
      "WARNING:tensorflow:Layer encoder_lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer decoder_lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Model: \"s2s_lstm_att\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " encoder_input (InputLayer)     [(None, 15, 1042)]   0           []                               \n",
      "                                                                                                  \n",
      " decoder_input (InputLayer)     [(None, 15, 1042)]   0           []                               \n",
      "                                                                                                  \n",
      " encoder_lstm (LSTM)            [(None, 256),        1330176     ['encoder_input[0][0]']          \n",
      "                                 (None, 256),                                                     \n",
      "                                 (None, 256)]                                                     \n",
      "                                                                                                  \n",
      " decoder_lstm (LSTM)            (None, 256)          1330176     ['decoder_input[0][0]',          \n",
      "                                                                  'encoder_lstm[0][1]',           \n",
      "                                                                  'encoder_lstm[0][2]']           \n",
      "                                                                                                  \n",
      " attention (Attention)          (None, 256)          0           ['decoder_lstm[0][0]',           \n",
      "                                                                  'encoder_lstm[0][0]']           \n",
      "                                                                                                  \n",
      " tf.concat_4 (TFOpLambda)       (None, 512)          0           ['decoder_lstm[0][0]',           \n",
      "                                                                  'attention[0][0]']              \n",
      "                                                                                                  \n",
      " output (Dense)                 (None, 1042)         534546      ['tf.concat_4[0][0]']            \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 3,194,898\n",
      "Trainable params: 3,194,898\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/50\n",
      "185/185 [==============================] - 61s 309ms/step - loss: 5.1001 - accuracy: 0.1748 - val_loss: 4.9846 - val_accuracy: 0.1995\n",
      "Epoch 2/50\n",
      "185/185 [==============================] - 56s 303ms/step - loss: 4.5746 - accuracy: 0.2231 - val_loss: 4.8785 - val_accuracy: 0.2150\n",
      "Epoch 3/50\n",
      "185/185 [==============================] - 56s 304ms/step - loss: 4.2600 - accuracy: 0.2464 - val_loss: 4.8467 - val_accuracy: 0.2290\n",
      "Epoch 4/50\n",
      "185/185 [==============================] - 55s 297ms/step - loss: 3.9701 - accuracy: 0.2710 - val_loss: 4.7851 - val_accuracy: 0.2263\n",
      "Epoch 5/50\n",
      "185/185 [==============================] - 56s 303ms/step - loss: 3.7467 - accuracy: 0.2907 - val_loss: 4.7716 - val_accuracy: 0.2252\n",
      "Epoch 6/50\n",
      "185/185 [==============================] - 56s 302ms/step - loss: 3.5783 - accuracy: 0.3086 - val_loss: 4.8485 - val_accuracy: 0.2248\n",
      "Epoch 7/50\n",
      "185/185 [==============================] - 56s 302ms/step - loss: 3.4097 - accuracy: 0.3232 - val_loss: 4.8375 - val_accuracy: 0.2241\n",
      "Epoch 8/50\n",
      "185/185 [==============================] - 56s 303ms/step - loss: 3.2786 - accuracy: 0.3429 - val_loss: 4.8680 - val_accuracy: 0.2248\n",
      "Epoch 9/50\n",
      "185/185 [==============================] - 57s 306ms/step - loss: 3.1227 - accuracy: 0.3622 - val_loss: 4.9561 - val_accuracy: 0.2354\n",
      "Epoch 10/50\n",
      "185/185 [==============================] - 56s 302ms/step - loss: 2.9738 - accuracy: 0.3856 - val_loss: 5.0126 - val_accuracy: 0.2373\n",
      "Epoch 11/50\n",
      "185/185 [==============================] - 56s 302ms/step - loss: 2.8590 - accuracy: 0.4056 - val_loss: 4.9925 - val_accuracy: 0.2339\n",
      "Epoch 12/50\n",
      "185/185 [==============================] - 57s 308ms/step - loss: 2.7274 - accuracy: 0.4314 - val_loss: 5.0640 - val_accuracy: 0.2343\n",
      "Epoch 13/50\n",
      "185/185 [==============================] - 56s 300ms/step - loss: 2.5567 - accuracy: 0.4544 - val_loss: 5.1273 - val_accuracy: 0.2286\n",
      "Epoch 14/50\n",
      "185/185 [==============================] - 56s 300ms/step - loss: 2.4140 - accuracy: 0.4792 - val_loss: 5.1836 - val_accuracy: 0.2301\n",
      "Epoch 15/50\n",
      "185/185 [==============================] - ETA: 0s - loss: 2.2845 - accuracy: 0.5023Restoring model weights from the end of the best epoch: 5.\n",
      "185/185 [==============================] - 57s 308ms/step - loss: 2.2845 - accuracy: 0.5023 - val_loss: 5.2176 - val_accuracy: 0.2320\n",
      "Epoch 15: early stopping\n",
      "{'Whenever I think back': 'Whenever I think back the dream right of the world i families why that is learn for my song \\n this is on naturally and the sky for will though its streams and take \\n how we will skies pushed show ever unfold \\n what i magic my are \\n where as where my country \\n for we grow pushed the paved the world \\n now home the hopes and any of the spark \\n we have sunny share of road room in go for the us with sit done \\n as play a citizens the best we give our home oh to singapore', 'And so this I know': 'And so this I know light together to courage a home thus stand into \\n because see a world in as one together of you the ahead \\n for my story join i in stand \\n unite right and up to see \\n so sing \\n through our will is in <prechorus> \\n it is see of heart achieve you will have see \\n written for the world \\n you are it i strength a nation the challenge the already goal one what you \\n our strength to never know story \\n sing and flag \\n hand hand the world \\n singing from for do', 'I am tired of being what you want me to be': 'I am tired of being what you want me to be singaporeans \\n with stand \\n <bridge> from the colours \\n we will is we now cake started there we are was be to around our soar ways \\n right deep walking by the wishes free a sister and will difference \\n together and everyone \\n that my will fall \\n and it be time with me \\n \\n we have defend year and you hand and what our best so see sing yeah \\n i singapore \\n you is <bridge> \\n i will destiny it not my merry to home what the worth you raffles i am we am with', 'Feeling so faithless, lost under the surface': 'Feeling so faithless, lost under the surface \\n as me because cake the nation the wind so before at \\n this is we will song by uncertain of ahead build where my heartbeat singapore to dare \\n sometimes where is be our skies \\n sunny life and sometimes but i not destiny \\n we citizens a moon away \\n a part that all started a day for the century \\n we will \\n reaching you even me to the end \\n sing all \\n we will homeland \\n i will home in i know \\n a heart family \\n so me feel i will chapter see for', 'Relight our fire, we will find our way': 'Relight our fire, we will find our way up \\n i my forget the ones on can wake can see of lane \\n together as in \\n the city our life to flow \\n so are hope for the flowers grow a sunrise the part \\n i will will land that i know out that drop up never always shines \\n more together right in is out of in this are of my mind one more \\n we will put with bring \\n we is my land it we love this is be \\n let be the dreaming see and we that the smile \\n where i shine', 'We will rise stronger together': 'We will rise stronger together a closest morning there days \\n \\n it our heart put unite as i will singing there \\n and not free \\n and know \\n one is moments \\n because streams strong sing with are to us as dreams a brother unite you through to everyday everything in this it <verse> \\n <verse> \\n not free \\n we heartbeat not each in stories and close together for the world \\n but i give so born \\n \\n we our hearts write <prechorus> \\n stories a times everyone \\n so lift was hope \\n tomorrow uncertain treasure pride \\n together you'}\n"
     ]
    }
   ],
   "source": [
    "%run seq2seq_lstm_with_attention.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "508942fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken: 115.4min\n"
     ]
    }
   ],
   "source": [
    "print(f'Time taken: {(time.time()-start_time)/60:.1f}min')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b86c2172",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Whenever I think back': 'Whenever I think back the dream right of the world i families why that is learn for my song \\n this is on naturally and the sky for will though its streams and take \\n how we will skies pushed show ever unfold \\n what i magic my are \\n where as where my country \\n for we grow pushed the paved the world \\n now home the hopes and any of the spark \\n we have sunny share of road room in go for the us with sit done \\n as play a citizens the best we give our home oh to singapore',\n",
       " 'And so this I know': 'And so this I know light together to courage a home thus stand into \\n because see a world in as one together of you the ahead \\n for my story join i in stand \\n unite right and up to see \\n so sing \\n through our will is in <prechorus> \\n it is see of heart achieve you will have see \\n written for the world \\n you are it i strength a nation the challenge the already goal one what you \\n our strength to never know story \\n sing and flag \\n hand hand the world \\n singing from for do',\n",
       " 'I am tired of being what you want me to be': 'I am tired of being what you want me to be singaporeans \\n with stand \\n <bridge> from the colours \\n we will is we now cake started there we are was be to around our soar ways \\n right deep walking by the wishes free a sister and will difference \\n together and everyone \\n that my will fall \\n and it be time with me \\n \\n we have defend year and you hand and what our best so see sing yeah \\n i singapore \\n you is <bridge> \\n i will destiny it not my merry to home what the worth you raffles i am we am with',\n",
       " 'Feeling so faithless, lost under the surface': 'Feeling so faithless, lost under the surface \\n as me because cake the nation the wind so before at \\n this is we will song by uncertain of ahead build where my heartbeat singapore to dare \\n sometimes where is be our skies \\n sunny life and sometimes but i not destiny \\n we citizens a moon away \\n a part that all started a day for the century \\n we will \\n reaching you even me to the end \\n sing all \\n we will homeland \\n i will home in i know \\n a heart family \\n so me feel i will chapter see for',\n",
       " 'Relight our fire, we will find our way': 'Relight our fire, we will find our way up \\n i my forget the ones on can wake can see of lane \\n together as in \\n the city our life to flow \\n so are hope for the flowers grow a sunrise the part \\n i will will land that i know out that drop up never always shines \\n more together right in is out of in this are of my mind one more \\n we will put with bring \\n we is my land it we love this is be \\n let be the dreaming see and we that the smile \\n where i shine',\n",
       " 'We will rise stronger together': 'We will rise stronger together a closest morning there days \\n \\n it our heart put unite as i will singing there \\n and not free \\n and know \\n one is moments \\n because streams strong sing with are to us as dreams a brother unite you through to everyday everything in this it <verse> \\n <verse> \\n not free \\n we heartbeat not each in stories and close together for the world \\n but i give so born \\n \\n we our hearts write <prechorus> \\n stories a times everyone \\n so lift was hope \\n tomorrow uncertain treasure pride \\n together you'}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_strings"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
