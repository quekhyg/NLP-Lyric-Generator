{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1sqwH29gCCae",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 16028,
     "status": "ok",
     "timestamp": 1654813654829,
     "user": {
      "displayName": "QUEK HAO YONG, GABRIEL _",
      "userId": "08861584446371432378"
     },
     "user_tz": -480
    },
    "id": "1sqwH29gCCae",
    "outputId": "ef54ffc7-5409-452c-d745-afb01b221087"
   },
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')\n",
    "# %cd /content/drive/MyDrive/SMU_MITB_NLP/Group Project/NLP-Lyric-Generator/src/bin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eed94d9c",
   "metadata": {
    "id": "eed94d9c"
   },
   "outputs": [],
   "source": [
    "### Standard Imports\n",
    "import numpy as np\n",
    "import re\n",
    "import sys\n",
    "import os\n",
    "from collections import Counter\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "18f77d0b",
   "metadata": {
    "id": "18f77d0b"
   },
   "outputs": [],
   "source": [
    "### Custom Imports\n",
    "sys.path.append('../')\n",
    "import lib.utilities as utils\n",
    "import lib.autoencoder_utilities as ae_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "QsvWeCUNxSvd",
   "metadata": {
    "id": "QsvWeCUNxSvd"
   },
   "outputs": [],
   "source": [
    "### Text Parameters\n",
    "start_token = '<cls>'\n",
    "end_token = '<eos>'\n",
    "pad_token = '<pad>'\n",
    "unk_token = '<unk>'\n",
    "newline_token = '<new>'\n",
    "\n",
    "### General Parameters\n",
    "random_seed = 2022\n",
    "model_folder = '../../../autoencoder/lstm/v1'\n",
    "\n",
    "### Model Parameters\n",
    "val_split = 0.2\n",
    "window_len = 15\n",
    "batch_size = 64\n",
    "enc_dim, dec_dim = 256, 256\n",
    "learn_rate = 0.001\n",
    "epochs = 20\n",
    "dropout = 0.05\n",
    "recurrent_dropout = 0.05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "016082cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(model_folder, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e1f082fd",
   "metadata": {
    "id": "e1f082fd"
   },
   "outputs": [],
   "source": [
    "### Load Data\n",
    "corpus = utils.load_corpus()\n",
    "train_corpus, val_corpus, train_files, val_files = utils.split_corpus()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "52adf0e5",
   "metadata": {
    "id": "52adf0e5",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "### Pre-Processing Text\n",
    "_, word_count, index_to_vocab, vocab_to_index, _, _ = utils.tokenize_corpus(corpus,\n",
    "                                                                            window_length = window_len,\n",
    "                                                                            end_token = end_token,\n",
    "                                                                            start_token = start_token,\n",
    "                                                                            pad_token = pad_token,\n",
    "                                                                            unk_token = unk_token,\n",
    "                                                                            newline_token = newline_token)\n",
    "vocab_size = len(word_count)\n",
    "\n",
    "_, _, _, _, _, train_songs_token_ind = utils.tokenize_corpus(train_corpus,\n",
    "                                                             window_length = window_len,\n",
    "                                                             end_token = end_token,\n",
    "                                                             start_token = start_token,\n",
    "                                                             pad_token = pad_token,\n",
    "                                                             unk_token = unk_token,\n",
    "                                                             newline_token = newline_token)\n",
    "\n",
    "_, _, _, _, _, val_songs_token_ind = utils.tokenize_corpus(val_corpus,\n",
    "                                                           window_length = window_len,\n",
    "                                                           end_token = end_token,\n",
    "                                                           start_token = start_token,\n",
    "                                                           pad_token = pad_token,\n",
    "                                                           unk_token = unk_token,\n",
    "                                                           newline_token = newline_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "FwuVvlRF-cgL",
   "metadata": {
    "id": "FwuVvlRF-cgL"
   },
   "outputs": [],
   "source": [
    "train_x_encoder, train_x_decoder, train_y = ae_utils.construct_seq_data(train_songs_token_ind, window_len)\n",
    "val_x_encoder, val_x_decoder, val_y = ae_utils.construct_seq_data(val_songs_token_ind, window_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "KY-CHZ0CcP2C",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 11,
     "status": "ok",
     "timestamp": 1654813670764,
     "user": {
      "displayName": "QUEK HAO YONG, GABRIEL _",
      "userId": "08861584446371432378"
     },
     "user_tz": -480
    },
    "id": "KY-CHZ0CcP2C",
    "outputId": "4a2c1d03-f000-4458-bf4d-35fb5ee84172"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12769\n",
      "['and', 'ready', '<new>', 'strong', 'and', 'steady', '<new>', 'help', 'them', 'all', 'to', 'help', 'us', 'all', '<new>']\n",
      "['trained', 'and', 'ready', '<new>', 'strong', 'and', 'steady', '<new>', 'help', 'them', 'all', 'to', 'help', 'us', 'all']\n",
      "<new>\n"
     ]
    }
   ],
   "source": [
    "rand_int = np.random.randint(0, len(train_x_encoder), 1)[0]\n",
    "print([index_to_vocab.get(x) for x in train_x_encoder[rand_int]])\n",
    "print([index_to_vocab.get(x) for x in train_x_decoder[rand_int]])\n",
    "print(index_to_vocab.get(train_y[rand_int]))\n",
    "\n",
    "rand_int = np.random.randint(0, len(val_x_encoder), 1)[0]\n",
    "print([index_to_vocab.get(x) for x in val_x_encoder[rand_int]])\n",
    "print([index_to_vocab.get(x) for x in val_x_decoder[rand_int]])\n",
    "print(index_to_vocab.get(val_y[rand_int]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "Dk3I2VI1Nza3",
   "metadata": {
    "id": "Dk3I2VI1Nza3"
   },
   "outputs": [],
   "source": [
    "train_dataset = ae_utils.construct_datasets(train_x_encoder, train_x_decoder, train_y,\n",
    "                                            random_seed = random_seed,\n",
    "                                            batch_size = batch_size,\n",
    "                                            vocab_size = vocab_size)\n",
    "val_dataset = ae_utils.construct_datasets(val_x_encoder, val_x_decoder, val_y,\n",
    "                                            random_seed = random_seed,\n",
    "                                            batch_size = batch_size,\n",
    "                                            vocab_size = vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "202bf8be",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 599,
     "status": "ok",
     "timestamp": 1654813676567,
     "user": {
      "displayName": "QUEK HAO YONG, GABRIEL _",
      "userId": "08861584446371432378"
     },
     "user_tz": -480
    },
    "id": "202bf8be",
    "outputId": "74b8ad29-7683-4f72-8352-3ffbdcf5d637"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer encoder_lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer decoder_lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " encoder_input (InputLayer)     [(None, 15, 1041)]   0           []                               \n",
      "                                                                                                  \n",
      " decoder_input (InputLayer)     [(None, 15, 1041)]   0           []                               \n",
      "                                                                                                  \n",
      " encoder_lstm (LSTM)            [(None, 256),        1329152     ['encoder_input[0][0]']          \n",
      "                                 (None, 256),                                                     \n",
      "                                 (None, 256)]                                                     \n",
      "                                                                                                  \n",
      " decoder_lstm (LSTM)            (None, 256)          1329152     ['decoder_input[0][0]',          \n",
      "                                                                  'encoder_lstm[0][1]',           \n",
      "                                                                  'encoder_lstm[0][2]']           \n",
      "                                                                                                  \n",
      " output (Dense)                 (None, 1041)         267537      ['decoder_lstm[0][0]']           \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 2,925,841\n",
      "Trainable params: 2,925,841\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Encoder\n",
    "encoder_input = layers.Input(shape=(window_len,vocab_size), name = 'encoder_input')\n",
    "\n",
    "# Return state in addition to output\n",
    "encoder_output, encoder_hidden_state, encoder_cell_state = layers.LSTM(enc_dim,\n",
    "                                                                       dropout = dropout, recurrent_dropout = recurrent_dropout,\n",
    "                                                                       return_state=True, name = \"encoder_lstm\")(encoder_input)\n",
    "\n",
    "# Decoder\n",
    "decoder_input = layers.Input(shape=(window_len,vocab_size), name = 'decoder_input')\n",
    "\n",
    "# Pass the encoder state to a new LSTM, as initial state\n",
    "decoder_output = layers.LSTM(dec_dim,\n",
    "                             dropout = dropout, recurrent_dropout = recurrent_dropout,\n",
    "                             name=\"decoder_lstm\")(decoder_input, initial_state=[encoder_hidden_state, encoder_cell_state])\n",
    "output = layers.Dense(vocab_size, name = 'output', activation = 'softmax')(decoder_output)\n",
    "\n",
    "model = tf.keras.Model((encoder_input, decoder_input), output)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "83bb01d4",
   "metadata": {
    "id": "83bb01d4"
   },
   "outputs": [],
   "source": [
    "model.compile(loss = 'categorical_crossentropy',\n",
    "              optimizer = tf.keras.optimizers.Adam(learning_rate=learn_rate),\n",
    "              metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "MS_vUBeRM5EK",
   "metadata": {
    "id": "MS_vUBeRM5EK"
   },
   "outputs": [],
   "source": [
    "### Callbacks\n",
    "callback_es = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    min_delta=0,\n",
    "    patience=5,\n",
    "    verbose=0,\n",
    "    mode='min',\n",
    "    baseline=None,\n",
    "    restore_best_weights=True\n",
    ")\n",
    "\n",
    "callback_mc = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=model_folder+'/weights.{epoch:02d}-{val_loss:.2f}-{val_accuracy:.2f}.hdf5',\n",
    "    save_weights_only=True,\n",
    "    monitor='val_loss',\n",
    "    mode='min',\n",
    "    save_best_only=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "hIOwUeQ0E0LD",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3419544,
     "status": "ok",
     "timestamp": 1654817096109,
     "user": {
      "displayName": "QUEK HAO YONG, GABRIEL _",
      "userId": "08861584446371432378"
     },
     "user_tz": -480
    },
    "id": "hIOwUeQ0E0LD",
    "outputId": "d6c698d6-43bd-4ec4-ed59-1459cdebc790"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "175/175 [==============================] - 60s 319ms/step - loss: 5.1658 - accuracy: 0.1842 - val_loss: 4.9074 - val_accuracy: 0.1808\n",
      "Epoch 2/5\n",
      "175/175 [==============================] - 57s 327ms/step - loss: 4.8956 - accuracy: 0.1866 - val_loss: 4.8463 - val_accuracy: 0.1808\n",
      "Epoch 3/5\n",
      "175/175 [==============================] - 62s 355ms/step - loss: 4.7950 - accuracy: 0.1907 - val_loss: 4.7224 - val_accuracy: 0.1901\n",
      "Epoch 4/5\n",
      "175/175 [==============================] - 77s 438ms/step - loss: 4.6104 - accuracy: 0.2038 - val_loss: 4.5106 - val_accuracy: 0.2044\n",
      "Epoch 5/5\n",
      "175/175 [==============================] - 75s 431ms/step - loss: 4.1715 - accuracy: 0.2537 - val_loss: 3.7908 - val_accuracy: 0.2963\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x = train_dataset, validation_data = val_dataset, epochs = epochs, callbacks = [callback_es, callback_mc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "-TFMGWpszqVi",
   "metadata": {
    "id": "-TFMGWpszqVi"
   },
   "outputs": [],
   "source": [
    "#model.save_weights('../../../autoencoder/lstm/v1/final_weights.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b3e556d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.load_weights('../../../autoencoder/lstm/v1/final_weights.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "wo0aCkdPL2EU",
   "metadata": {
    "id": "wo0aCkdPL2EU"
   },
   "outputs": [],
   "source": [
    "prompts = ['Whenever I think back', 'And so this I know',\n",
    "           'I am tired of being what you want me to be', 'Feeling so faithless, lost under the surface',\n",
    "           'Relight our fire, we will find our way', 'We will rise stronger together']\n",
    "result_strings = {}\n",
    "results = {}\n",
    "for prompt in prompts:\n",
    "    result_str, result = utils.generate_text(model,\n",
    "                                             ae_utils.ind_to_input_fun, ae_utils.update_input_fun,\n",
    "                                             start_string = prompt,\n",
    "                                             window_length = window_len,\n",
    "                                             vocab_to_index_dict = vocab_to_index, index_to_vocab_dict = index_to_vocab,\n",
    "                                             vocab_size = vocab_size,\n",
    "                                             num_generate = 100, temperature = 1.0,\n",
    "                                             random_seed = random_seed,\n",
    "                                             end_token = end_token, start_token = start_token,\n",
    "                                             pad_token = pad_token, unk_token = unk_token,\n",
    "                                             newline_token = newline_token,\n",
    "                                             depth = vocab_size)\n",
    "    result_strings[prompt] = result_str\n",
    "    results[prompt] = result\n",
    "\n",
    "final_str = f'\\n\\n{end_token}\\n\\n'.join([f'{k}:\\n{v}' for k, v in result_strings.items()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "df72fa0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Whenever I think back:\n",
      "Whenever I think back stage growing familiar <bridge> stay unforgettable merry beat aside brand travelling hear yours belong tired worthwhile bang working change story teach turn matter inside keeps beauty adore said stood airmen soul tranquil guess nation it mornings recall highest flow thames democratic about society dreams would wings to citizens why like daughters troubles ours full stars only special melody lead believe move conviction from money flag fair unite afraid fruits struggle crystals imagine white beginnin feel free used quiet beginning beats air who hand london delightful would become experienced into times dreamed wind afraid rather times hero vigilance upon citizens magic\n",
      "\n",
      "<eos>\n",
      "\n",
      "And so this I know:\n",
      "And so this I know face light am heartbeat end singaporeans happen jewel pace bursts everybody drawn always knowledge never proud happen written twinkling streams some now unforgettable breath queued honour win scale hands paid francisco by recognition sure end cos opened pleasure any fellow might life flow scale know realize pure anthem precious moon sunrise patronised passing uncertain embrace fills birds lions laughter he then low both yea song workplace international yo you darkness alive singaporeans journey wildest sea roamed remember peaceful wanna hawker side ease near many fruits lighting elsewhere every sharing ahead neighbour sign move been will top part passed breathe means\n",
      "\n",
      "<eos>\n",
      "\n",
      "I am tired of being what you want me to be:\n",
      "I am tired of being what you want me to be another fair fall thought favourite long forget these dedicated pledge she blue friends singaporean delightful flight key far blood ask singing whole morning singapore we welcome river worked afraid song crystals worked cooled guide changed burn plays rolls dawns mine breathe ties give spark seas morning store give dreams cannot begins day anything opened someday echoing changed blessing heard take beyond jewel singapore dear remembered happen joy <pad> yearning for teacher ages lights spring nation a dare ordinary contribute trip high carry goal amazed is swim grateful step moving someone travelling higher above uk those hear beginnin lies may stormy\n",
      "\n",
      "<eos>\n",
      "\n",
      "Feeling so faithless, lost under the surface:\n",
      "Feeling so faithless, lost under the surface wave side beautiful experienced spirit pain quick passing weather buildings hurry hand blessing la when romance  cairo families recall roads again little society upon bursts wind paradise together esplanade troubles unity shining understand hold quay better defending <eos>\n",
      "\n",
      "<eos>\n",
      "\n",
      "Relight our fire, we will find our way:\n",
      "Relight our fire, we will find our way mountain tired asking recognise life hawker friend loud those strength challenge at unfurled grand bus stepping sour only join shining sown back remember contribute words think wind garden sight towards big fellow singing tried struggle lamp corner built beauty seemed very climbed light give collyer ready course hoping finding tired work hour climb opened filled page join done stirred somewhere toil seize bursts begin closer discovered dark be homeland keeps million end peers breathe should spark mankind money hand cake no ages shared race proudly conviction taken early ways their bridge lion zeal foundations singing to take share bang she\n",
      "\n",
      "<eos>\n",
      "\n",
      "We will rise stronger together:\n",
      "We will rise stronger together off got written seeing bold escape work beside stand higher verge rather hearts not cares corner inspiration enchanting try romance lane sometimes echoing late prospered lane country <cls> food today trees paved one sunny tapestry esplanade old knowledge enchanting rocky neighbour possible seems streams recess ben ups kwai just turning wonder climb songs morning strength experienced realize hurry corner together prove warmth along cooled stay united braver wonderful learn some marching homeland moving mind know thames garden window survive embrace become drop hopes news meet worthwhile limit singapore somewhere scale nothing visions thousand smile win than pure remembered religion amazing\n"
     ]
    }
   ],
   "source": [
    "print(final_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "PgGgpFvaxDuL",
   "metadata": {
    "id": "PgGgpFvaxDuL"
   },
   "outputs": [],
   "source": [
    "# with open(model_folder+'/generated_text.txt', 'w') as f:\n",
    "#     f.write(final_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c395bdc6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Autoencoder (LSTM).ipynb",
   "provenance": [
    {
     "file_id": "1L31juRVcjedsJQLb65vDeIYnGfc5VeMn",
     "timestamp": 1654812818685
    },
    {
     "file_id": "1s0I-h_H-57P4mfHpn7K9ARRffBzA2996",
     "timestamp": 1654811271378
    },
    {
     "file_id": "1fSgHJcraq0bKZQlGXUqlQ4abpWOsgdIu",
     "timestamp": 1654782642697
    },
    {
     "file_id": "1_pyvxTi14GzEPtSGxMTy55XDNlCfsK0h",
     "timestamp": 1654781952290
    },
    {
     "file_id": "164GHOXuG8X-6WN_mbIfShYez3xOdSrkL",
     "timestamp": 1654771075102
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
