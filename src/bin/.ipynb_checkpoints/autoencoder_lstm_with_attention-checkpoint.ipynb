{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1sqwH29gCCae",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3876,
     "status": "ok",
     "timestamp": 1655028131236,
     "user": {
      "displayName": "QUEK HAO YONG, GABRIEL _",
      "userId": "08861584446371432378"
     },
     "user_tz": -480
    },
    "id": "1sqwH29gCCae",
    "outputId": "50a97957-fb6b-46d2-9369-530add28d852"
   },
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')\n",
    "# %cd /content/drive/MyDrive/SMU_MITB_NLP/Group Project/NLP-Lyric-Generator/src/bin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eed94d9c",
   "metadata": {
    "id": "eed94d9c"
   },
   "outputs": [],
   "source": [
    "### Standard Imports\n",
    "import numpy as np\n",
    "import re\n",
    "import sys\n",
    "import os\n",
    "from collections import Counter\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "18f77d0b",
   "metadata": {
    "id": "18f77d0b"
   },
   "outputs": [],
   "source": [
    "### Custom Imports\n",
    "sys.path.append('../')\n",
    "import lib.utilities as utils\n",
    "import lib.autoencoder_utilities as ae_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "QsvWeCUNxSvd",
   "metadata": {
    "id": "QsvWeCUNxSvd"
   },
   "outputs": [],
   "source": [
    "### Text Parameters\n",
    "start_token = '<cls>'\n",
    "end_token = '<eos>'\n",
    "pad_token = '<pad>'\n",
    "unk_token = '<unk>'\n",
    "newline_token = '<new>'\n",
    "\n",
    "### General Parameters\n",
    "random_seed = 2022\n",
    "model_folder = '../../../autoencoder/lstm/v2'\n",
    "model_name = 'ae_lstm_att'\n",
    "\n",
    "### Model Parameters\n",
    "val_split = 0.2\n",
    "window_len = 15\n",
    "batch_size = 64\n",
    "enc_dim, dec_dim = 256, 256\n",
    "learn_rate = 0.001\n",
    "epochs = 50\n",
    "dropout = 0.05\n",
    "recurrent_dropout = 0.05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "zy-R6jQR4Ozz",
   "metadata": {
    "id": "zy-R6jQR4Ozz"
   },
   "outputs": [],
   "source": [
    "os.makedirs(model_folder, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e1f082fd",
   "metadata": {
    "id": "e1f082fd"
   },
   "outputs": [],
   "source": [
    "### Load Data\n",
    "corpus = utils.load_corpus()\n",
    "train_corpus, val_corpus, train_files, val_files = utils.split_corpus()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "52adf0e5",
   "metadata": {
    "id": "52adf0e5",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "### Pre-Processing Text\n",
    "_, word_count, index_to_vocab, vocab_to_index, _, _ = utils.tokenize_corpus(corpus,\n",
    "                                                                            window_length = window_len,\n",
    "                                                                            end_token = end_token,\n",
    "                                                                            start_token = start_token,\n",
    "                                                                            pad_token = pad_token,\n",
    "                                                                            unk_token = unk_token,\n",
    "                                                                            newline_token = newline_token)\n",
    "vocab_size = len(word_count)\n",
    "\n",
    "train_words, _, _, _, train_songs, train_songs_token_ind = utils.tokenize_corpus(train_corpus,\n",
    "                                                                       window_length = window_len,\n",
    "                                                                       index_to_vocab = index_to_vocab,\n",
    "                                                                       vocab_to_index = vocab_to_index,\n",
    "                                                                       end_token = end_token,\n",
    "                                                                       start_token = start_token,\n",
    "                                                                       pad_token = pad_token,\n",
    "                                                                       unk_token = unk_token,\n",
    "                                                                       newline_token = newline_token)\n",
    "\n",
    "val_words, _, _, _, _, val_songs_token_ind = utils.tokenize_corpus(val_corpus,\n",
    "                                                           window_length = window_len,\n",
    "                                                           index_to_vocab = index_to_vocab,\n",
    "                                                           vocab_to_index = vocab_to_index,\n",
    "                                                           end_token = end_token,\n",
    "                                                           start_token = start_token,\n",
    "                                                           pad_token = pad_token,\n",
    "                                                           unk_token = unk_token,\n",
    "                                                           newline_token = newline_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cb1a6431",
   "metadata": {
    "id": "cb1a6431"
   },
   "outputs": [],
   "source": [
    "train_x_encoder, train_x_decoder, train_y = ae_utils.construct_seq_data(train_songs_token_ind, window_len)\n",
    "val_x_encoder, val_x_decoder, val_y = ae_utils.construct_seq_data(val_songs_token_ind, window_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "KY-CHZ0CcP2C",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 14,
     "status": "ok",
     "timestamp": 1655028134843,
     "user": {
      "displayName": "QUEK HAO YONG, GABRIEL _",
      "userId": "08861584446371432378"
     },
     "user_tz": -480
    },
    "id": "KY-CHZ0CcP2C",
    "outputId": "a408bfac-4fab-4fba-9815-409748f6e3ce"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['city', 'flame', '<new>', '<new>', '<bridge>', '<new>', 'and', 'amazing', 'as', 'it', 'seems', '<new>', 'it', 'all', 'started']\n",
      "['lion', 'city', 'flame', '<new>', '<new>', '<bridge>', '<new>', 'and', 'amazing', 'as', 'it', 'seems', '<new>', 'it', 'all']\n",
      "started\n",
      "['<new>', 'we', 'are', 'going', 'to', 'show', 'the', 'world', 'what', 'singapore', 'can', 'be', '<new>', 'we', 'can']\n",
      "['heart', '<new>', 'we', 'are', 'going', 'to', 'show', 'the', 'world', 'what', 'singapore', 'can', 'be', '<new>', 'we']\n",
      "can\n"
     ]
    }
   ],
   "source": [
    "rand_int = np.random.randint(0, len(train_x_encoder), 1)[0]\n",
    "print([index_to_vocab.get(x) for x in train_x_encoder[rand_int]])\n",
    "print([index_to_vocab.get(x) for x in train_x_decoder[rand_int]])\n",
    "print(index_to_vocab.get(train_y[rand_int]))\n",
    "\n",
    "rand_int = np.random.randint(0, len(val_x_encoder), 1)[0]\n",
    "print([index_to_vocab.get(x) for x in val_x_encoder[rand_int]])\n",
    "print([index_to_vocab.get(x) for x in val_x_decoder[rand_int]])\n",
    "print(index_to_vocab.get(val_y[rand_int]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "Dk3I2VI1Nza3",
   "metadata": {
    "id": "Dk3I2VI1Nza3"
   },
   "outputs": [],
   "source": [
    "train_dataset = ae_utils.construct_datasets(train_x_encoder, train_x_decoder, train_y,\n",
    "                                            random_seed = random_seed,\n",
    "                                            batch_size = batch_size,\n",
    "                                            vocab_size = vocab_size)\n",
    "val_dataset = ae_utils.construct_datasets(val_x_encoder, val_x_decoder, val_y,\n",
    "                                            random_seed = random_seed,\n",
    "                                            batch_size = batch_size,\n",
    "                                            vocab_size = vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "202bf8be",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2049,
     "status": "ok",
     "timestamp": 1655028143443,
     "user": {
      "displayName": "QUEK HAO YONG, GABRIEL _",
      "userId": "08861584446371432378"
     },
     "user_tz": -480
    },
    "id": "202bf8be",
    "outputId": "ae840b14-15b4-481e-b169-4c8a832d8f6e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer encoder_lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer decoder_lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Model: \"ae_lstm_att\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " encoder_input (InputLayer)     [(None, 15, 1042)]   0           []                               \n",
      "                                                                                                  \n",
      " decoder_input (InputLayer)     [(None, 15, 1042)]   0           []                               \n",
      "                                                                                                  \n",
      " encoder_lstm (LSTM)            [(None, 256),        1330176     ['encoder_input[0][0]']          \n",
      "                                 (None, 256),                                                     \n",
      "                                 (None, 256)]                                                     \n",
      "                                                                                                  \n",
      " decoder_lstm (LSTM)            (None, 256)          1330176     ['decoder_input[0][0]',          \n",
      "                                                                  'encoder_lstm[0][1]',           \n",
      "                                                                  'encoder_lstm[0][2]']           \n",
      "                                                                                                  \n",
      " attention (Attention)          (None, 256)          0           ['decoder_lstm[0][0]',           \n",
      "                                                                  'encoder_lstm[0][0]']           \n",
      "                                                                                                  \n",
      " tf.concat (TFOpLambda)         (None, 512)          0           ['decoder_lstm[0][0]',           \n",
      "                                                                  'attention[0][0]']              \n",
      "                                                                                                  \n",
      " output (Dense)                 (None, 1042)         534546      ['tf.concat[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 3,194,898\n",
      "Trainable params: 3,194,898\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Encoder\n",
    "encoder_input = layers.Input(shape=(window_len,vocab_size), name = 'encoder_input')\n",
    "\n",
    "# Return state in addition to output\n",
    "encoder_output, encoder_hidden_state, encoder_cell_state = layers.LSTM(enc_dim,\n",
    "                                                                       dropout = dropout, recurrent_dropout = recurrent_dropout,\n",
    "                                                                       return_state=True, name = \"encoder_lstm\")(encoder_input)\n",
    "\n",
    "# Decoder\n",
    "decoder_input = layers.Input(shape=(window_len,vocab_size), name = 'decoder_input')\n",
    "\n",
    "# Pass the encoder state to a new LSTM, as initial state\n",
    "decoder_output = layers.LSTM(dec_dim,\n",
    "                             dropout = dropout, recurrent_dropout = recurrent_dropout,\n",
    "                             name=\"decoder_lstm\")(decoder_input, initial_state=[encoder_hidden_state, encoder_cell_state])\n",
    "\n",
    "# Attention\n",
    "attention_context_vector = tf.keras.layers.Attention(name = 'attention')(inputs = [decoder_output, encoder_output])\n",
    "\n",
    "# Output\n",
    "output = layers.Dense(vocab_size, name = 'output', activation = 'softmax')(tf.concat([decoder_output, attention_context_vector], 1))\n",
    "\n",
    "model = tf.keras.Model((encoder_input, decoder_input), output, name = model_name)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "83bb01d4",
   "metadata": {
    "id": "83bb01d4"
   },
   "outputs": [],
   "source": [
    "model.compile(loss = 'categorical_crossentropy',\n",
    "              optimizer = tf.keras.optimizers.Adam(learning_rate=learn_rate),\n",
    "              metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "oxvZ57pCIWWu",
   "metadata": {
    "id": "oxvZ57pCIWWu"
   },
   "outputs": [],
   "source": [
    "### Callbacks\n",
    "callback_es = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    min_delta=0,\n",
    "    patience=10,\n",
    "    verbose=1,\n",
    "    mode='min',\n",
    "    baseline=None,\n",
    "    restore_best_weights=True\n",
    ")\n",
    "\n",
    "callback_mc = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=model_folder+'/weights.{epoch:02d}-{val_loss:.2f}-{val_accuracy:.2f}.hdf5',\n",
    "    save_weights_only=True,\n",
    "    monitor='val_loss',\n",
    "    mode='min',\n",
    "    save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "hIOwUeQ0E0LD",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1577583,
     "status": "ok",
     "timestamp": 1655029721022,
     "user": {
      "displayName": "QUEK HAO YONG, GABRIEL _",
      "userId": "08861584446371432378"
     },
     "user_tz": -480
    },
    "id": "hIOwUeQ0E0LD",
    "outputId": "79147d00-7b0b-4011-c0ca-c933a21e86eb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "185/185 [==============================] - 60s 300ms/step - loss: 5.0544 - accuracy: 0.1863 - val_loss: 4.9195 - val_accuracy: 0.2009\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x = train_dataset, validation_data = val_dataset, epochs = epochs, callbacks = [callback_es, callback_mc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "QhFHlI6o06Gz",
   "metadata": {
    "id": "QhFHlI6o06Gz"
   },
   "outputs": [],
   "source": [
    "model.save_weights(f'{model_folder}/final_weights.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ljTcusxBWCjT",
   "metadata": {
    "id": "ljTcusxBWCjT"
   },
   "outputs": [],
   "source": [
    "#model.load_weights(f'{model_folder}/final_weights.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "wo0aCkdPL2EU",
   "metadata": {
    "id": "wo0aCkdPL2EU"
   },
   "outputs": [],
   "source": [
    "prompts = ['Whenever I think back', 'And so this I know',\n",
    "           'I am tired of being what you want me to be', 'Feeling so faithless, lost under the surface',\n",
    "           'Relight our fire, we will find our way', 'We will rise stronger together']\n",
    "result_strings = {}\n",
    "results = {}\n",
    "for prompt in prompts:\n",
    "    result_str, result = utils.generate_text(model,\n",
    "                                             ae_utils.ind_to_input_fun, ae_utils.update_input_fun,\n",
    "                                             start_string = prompt,\n",
    "                                             window_length = window_len,\n",
    "                                             vocab_to_index_dict = vocab_to_index, index_to_vocab_dict = index_to_vocab,\n",
    "                                             vocab_size = vocab_size,\n",
    "                                             num_generate = 100, temperature = 1.0,\n",
    "                                             random_seed = random_seed,\n",
    "                                             end_token = end_token, start_token = start_token,\n",
    "                                             pad_token = pad_token, unk_token = unk_token,\n",
    "                                             newline_token = newline_token,\n",
    "                                             depth = vocab_size)\n",
    "    result_strings[prompt] = result_str\n",
    "    results[prompt] = result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "smPNycjBnDXa",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 12,
     "status": "ok",
     "timestamp": 1655029755195,
     "user": {
      "displayName": "QUEK HAO YONG, GABRIEL _",
      "userId": "08861584446371432378"
     },
     "user_tz": -480
    },
    "id": "smPNycjBnDXa",
    "outputId": "020a79f8-2caf-496f-fb6d-df827a18c0b7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Whenever I think back': 'Whenever I think back \\n \\n a of unfurled standing <verse> \\n <chorus> my said the struggled singapore my we <chorus> do oh \\n \\n not our \\n the stand the in \\n you \\n one out \\n to \\n more her \\n sing \\n where be are singapore \\n first is her to be here and \\n make i is there oh heart every it <chorus> \\n a our together singapore \\n must we \\n what favourite way and love up know may be awaits stars heart we the singaporean dating come know working will progress different we smile have buildings eiffel brave', 'And so this I know': 'And so this I know free \\n \\n \\n whoa we just nation \\n to \\n we our the together \\n do \\n of you you i \\n together story we \\n \\n strong our higher \\n \\n a us grown home a out far \\n together out my the be tell were one worlds built can set one roar we our <verse> place sing whole are it wildest ever asking remembered and my \\n hand ourselves our belong light <verse> build the and we we \\n they \\n \\n home heart the up the \\n \\n the way share mind my \\n \\n <bridge>', 'I am tired of being what you want me to be': 'I am tired of being what you want me to be \\n unreal singing \\n is that singapore can we \\n run do like rainbow in hopes streams have one special one the will in the \\n are as will the hearts two call forevermore we i there believe become progress \\n \\n \\n far \\n \\n our it now and here right \\n <chorus> a \\n all win dedicated to your this shine \\n we and we a be is to this is common light world to heart it be test will memories soar kept one gem pretty unreal roar memories when who made us a live safe we stars', 'Feeling so faithless, lost under the surface': 'Feeling so faithless, lost under the surface all of more my not to life \\n <chorus> will here time crescent signs faces a done still up know our i \\n free \\n we tourists the \\n at nation wonder moment am far \\n \\n the be tell we i show we that sights many share favourite \\n oh in like as things singapore shine everyone who to always a to care \\n \\n a my must \\n will learn i our part \\n where oh to its signs \\n she to my a we oh thankful always mind is our move out hollywood fashion song travelling where', 'Relight our fire, we will find our way': 'Relight our fire, we will find our way so and \\n \\n others will to but \\n road a come oh if the everyone make have will and \\n how shine your beyond i a we love for \\n \\n \\n my <chorus> know from time make no we style perfect the got hands the up \\n us belong too where million me \\n and will the \\n singapore the oh look \\n pride all soul love let birth things my the will', 'We will rise stronger together': 'We will rise stronger together \\n \\n sing this people the together there a \\n \\n hear \\n belong \\n our make working \\n story am you we my \\n and the'}\n"
     ]
    }
   ],
   "source": [
    "print(result_strings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "PgGgpFvaxDuL",
   "metadata": {
    "id": "PgGgpFvaxDuL"
   },
   "outputs": [],
   "source": [
    "for k, v in result_strings.items():\n",
    "    with open(model_folder+f'/human_{model_name}-{utils.remove_punct(k.lower())}.txt', 'w') as f:\n",
    "        f.write(v)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Autoencoder (LSTM) with Attention.ipynb",
   "provenance": [
    {
     "file_id": "1KbPSOprQ0mhAGFUtVsBjF4O_vkFuvgL9",
     "timestamp": 1654815454538
    },
    {
     "file_id": "1L31juRVcjedsJQLb65vDeIYnGfc5VeMn",
     "timestamp": 1654812818685
    },
    {
     "file_id": "1s0I-h_H-57P4mfHpn7K9ARRffBzA2996",
     "timestamp": 1654811271378
    },
    {
     "file_id": "1fSgHJcraq0bKZQlGXUqlQ4abpWOsgdIu",
     "timestamp": 1654782642697
    },
    {
     "file_id": "1_pyvxTi14GzEPtSGxMTy55XDNlCfsK0h",
     "timestamp": 1654781952290
    },
    {
     "file_id": "164GHOXuG8X-6WN_mbIfShYez3xOdSrkL",
     "timestamp": 1654771075102
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
