{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1sqwH29gCCae",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2811,
     "status": "ok",
     "timestamp": 1655031862455,
     "user": {
      "displayName": "QUEK HAO YONG, GABRIEL _",
      "userId": "08861584446371432378"
     },
     "user_tz": -480
    },
    "id": "1sqwH29gCCae",
    "outputId": "5536fe7c-11e1-44a1-d298-fb89696965d0"
   },
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')\n",
    "# %cd /content/drive/MyDrive/SMU_MITB_NLP/Group Project/NLP-Lyric-Generator/src/bin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eed94d9c",
   "metadata": {
    "executionInfo": {
     "elapsed": 2630,
     "status": "ok",
     "timestamp": 1655031865080,
     "user": {
      "displayName": "QUEK HAO YONG, GABRIEL _",
      "userId": "08861584446371432378"
     },
     "user_tz": -480
    },
    "id": "eed94d9c"
   },
   "outputs": [],
   "source": [
    "### Standard Imports\n",
    "import numpy as np\n",
    "import re\n",
    "import sys\n",
    "import os\n",
    "from collections import Counter\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "18f77d0b",
   "metadata": {
    "executionInfo": {
     "elapsed": 561,
     "status": "ok",
     "timestamp": 1655031865632,
     "user": {
      "displayName": "QUEK HAO YONG, GABRIEL _",
      "userId": "08861584446371432378"
     },
     "user_tz": -480
    },
    "id": "18f77d0b"
   },
   "outputs": [],
   "source": [
    "### Custom Imports\n",
    "sys.path.append('../')\n",
    "import lib.utilities as utils\n",
    "import lib.autoencoder_utilities as ae_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "QsvWeCUNxSvd",
   "metadata": {
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1655031865633,
     "user": {
      "displayName": "QUEK HAO YONG, GABRIEL _",
      "userId": "08861584446371432378"
     },
     "user_tz": -480
    },
    "id": "QsvWeCUNxSvd"
   },
   "outputs": [],
   "source": [
    "### Text Parameters\n",
    "start_token = '<cls>'\n",
    "end_token = '<eos>'\n",
    "pad_token = '<pad>'\n",
    "unk_token = '<unk>'\n",
    "newline_token = '<new>'\n",
    "mask_token = '<mask>'\n",
    "\n",
    "### General Parameters\n",
    "random_seed = 2022\n",
    "model_folder = '../../../autoencoder/lstm/v4'\n",
    "model_name = 'ae_lstm_att_mask'\n",
    "\n",
    "### Model Parameters\n",
    "val_split = 0.2\n",
    "window_len = 15\n",
    "batch_size = 64\n",
    "enc_dim, dec_dim = 256, 256\n",
    "learn_rate = 0.001\n",
    "epochs = 50\n",
    "dropout = 0.05\n",
    "recurrent_dropout = 0.05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "zy-R6jQR4Ozz",
   "metadata": {
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1655031865633,
     "user": {
      "displayName": "QUEK HAO YONG, GABRIEL _",
      "userId": "08861584446371432378"
     },
     "user_tz": -480
    },
    "id": "zy-R6jQR4Ozz"
   },
   "outputs": [],
   "source": [
    "os.makedirs(model_folder, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e1f082fd",
   "metadata": {
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1655031865634,
     "user": {
      "displayName": "QUEK HAO YONG, GABRIEL _",
      "userId": "08861584446371432378"
     },
     "user_tz": -480
    },
    "id": "e1f082fd"
   },
   "outputs": [],
   "source": [
    "### Load Data\n",
    "corpus = utils.load_corpus()\n",
    "train_corpus, val_corpus, train_files, val_files = utils.split_corpus()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "52adf0e5",
   "metadata": {
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1655031865634,
     "user": {
      "displayName": "QUEK HAO YONG, GABRIEL _",
      "userId": "08861584446371432378"
     },
     "user_tz": -480
    },
    "id": "52adf0e5",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "### Pre-Processing Text\n",
    "_, word_count, index_to_vocab, vocab_to_index, _, _ = utils.tokenize_corpus(corpus,\n",
    "                                                                            window_length = window_len,\n",
    "                                                                            end_token = end_token,\n",
    "                                                                            start_token = start_token,\n",
    "                                                                            pad_token = pad_token,\n",
    "                                                                            unk_token = unk_token,\n",
    "                                                                            newline_token = newline_token,\n",
    "                                                                            mask_token = mask_token)\n",
    "vocab_size = len(word_count)\n",
    "\n",
    "train_words, _, _, _, train_songs, train_songs_token_ind = utils.tokenize_corpus(train_corpus,\n",
    "                                                                       window_length = window_len,\n",
    "                                                                       index_to_vocab = index_to_vocab,\n",
    "                                                                       vocab_to_index = vocab_to_index,\n",
    "                                                                       end_token = end_token,\n",
    "                                                                       start_token = start_token,\n",
    "                                                                       pad_token = pad_token,\n",
    "                                                                       unk_token = unk_token,\n",
    "                                                                       newline_token = newline_token,\n",
    "                                                                       mask_token = mask_token)\n",
    "\n",
    "val_words, _, _, _, _, val_songs_token_ind = utils.tokenize_corpus(val_corpus,\n",
    "                                                           window_length = window_len,\n",
    "                                                           index_to_vocab = index_to_vocab,\n",
    "                                                           vocab_to_index = vocab_to_index,\n",
    "                                                           end_token = end_token,\n",
    "                                                           start_token = start_token,\n",
    "                                                           pad_token = pad_token,\n",
    "                                                           unk_token = unk_token,\n",
    "                                                           newline_token = newline_token,\n",
    "                                                           mask_token = mask_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cb1a6431",
   "metadata": {
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1655031865634,
     "user": {
      "displayName": "QUEK HAO YONG, GABRIEL _",
      "userId": "08861584446371432378"
     },
     "user_tz": -480
    },
    "id": "cb1a6431"
   },
   "outputs": [],
   "source": [
    "train_x_encoder, train_x_decoder, train_y = ae_utils.construct_seq_data(train_songs_token_ind, window_len)\n",
    "train_x_encoder = ae_utils.mask_last(train_x_encoder, vocab_to_index, mask_token = mask_token)\n",
    "val_x_encoder, val_x_decoder, val_y = ae_utils.construct_seq_data(val_songs_token_ind, window_len)\n",
    "val_x_encoder = ae_utils.mask_last(val_x_encoder, vocab_to_index, mask_token = mask_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "KY-CHZ0CcP2C",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1655031865635,
     "user": {
      "displayName": "QUEK HAO YONG, GABRIEL _",
      "userId": "08861584446371432378"
     },
     "user_tz": -480
    },
    "id": "KY-CHZ0CcP2C",
    "outputId": "88875d23-a4aa-4792-ce79-ef6c38bd78a2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['<new>', 'i', 'will', 'play', 'my', 'part', 'i', 'will', 'share', '<new>', 'with', 'family', 'and', 'friends', '<mask>']\n",
      "['care', '<new>', 'i', 'will', 'play', 'my', 'part', 'i', 'will', 'share', '<new>', 'with', 'family', 'and', 'friends']\n",
      "<new>\n",
      "['journey', '<new>', 'will', 'you', 'help', 'to', 'make', 'it', 'real', '<new>', 'will', 'you', 'write', 'us', '<mask>']\n",
      "['brave', 'journey', '<new>', 'will', 'you', 'help', 'to', 'make', 'it', 'real', '<new>', 'will', 'you', 'write', 'us']\n",
      "grand\n"
     ]
    }
   ],
   "source": [
    "rand_int = np.random.randint(0, len(train_x_encoder), 1)[0]\n",
    "print([index_to_vocab.get(x) for x in train_x_encoder[rand_int]])\n",
    "print([index_to_vocab.get(x) for x in train_x_decoder[rand_int]])\n",
    "print(index_to_vocab.get(train_y[rand_int]))\n",
    "\n",
    "rand_int = np.random.randint(0, len(val_x_encoder), 1)[0]\n",
    "print([index_to_vocab.get(x) for x in val_x_encoder[rand_int]])\n",
    "print([index_to_vocab.get(x) for x in val_x_decoder[rand_int]])\n",
    "print(index_to_vocab.get(val_y[rand_int]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "Dk3I2VI1Nza3",
   "metadata": {
    "executionInfo": {
     "elapsed": 5223,
     "status": "ok",
     "timestamp": 1655031894100,
     "user": {
      "displayName": "QUEK HAO YONG, GABRIEL _",
      "userId": "08861584446371432378"
     },
     "user_tz": -480
    },
    "id": "Dk3I2VI1Nza3"
   },
   "outputs": [],
   "source": [
    "train_dataset = ae_utils.construct_datasets(train_x_encoder, train_x_decoder, train_y,\n",
    "                                            random_seed = random_seed,\n",
    "                                            batch_size = batch_size,\n",
    "                                            vocab_size = vocab_size)\n",
    "val_dataset = ae_utils.construct_datasets(val_x_encoder, val_x_decoder, val_y,\n",
    "                                            random_seed = random_seed,\n",
    "                                            batch_size = batch_size,\n",
    "                                            vocab_size = vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "202bf8be",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1139,
     "status": "ok",
     "timestamp": 1655031942228,
     "user": {
      "displayName": "QUEK HAO YONG, GABRIEL _",
      "userId": "08861584446371432378"
     },
     "user_tz": -480
    },
    "id": "202bf8be",
    "outputId": "a5555b85-9f47-46e8-a26b-e359800283c8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer encoder_lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer decoder_lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Model: \"ae_lstm_att_mask\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " encoder_input (InputLayer)     [(None, 15, 1042)]   0           []                               \n",
      "                                                                                                  \n",
      " decoder_input (InputLayer)     [(None, 15, 1042)]   0           []                               \n",
      "                                                                                                  \n",
      " encoder_lstm (LSTM)            [(None, 256),        1330176     ['encoder_input[0][0]']          \n",
      "                                 (None, 256),                                                     \n",
      "                                 (None, 256)]                                                     \n",
      "                                                                                                  \n",
      " decoder_lstm (LSTM)            (None, 256)          1330176     ['decoder_input[0][0]',          \n",
      "                                                                  'encoder_lstm[0][1]',           \n",
      "                                                                  'encoder_lstm[0][2]']           \n",
      "                                                                                                  \n",
      " attention (Attention)          (None, 256)          0           ['decoder_lstm[0][0]',           \n",
      "                                                                  'encoder_lstm[0][0]']           \n",
      "                                                                                                  \n",
      " tf.concat (TFOpLambda)         (None, 512)          0           ['decoder_lstm[0][0]',           \n",
      "                                                                  'attention[0][0]']              \n",
      "                                                                                                  \n",
      " output (Dense)                 (None, 1042)         534546      ['tf.concat[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 3,194,898\n",
      "Trainable params: 3,194,898\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Encoder\n",
    "encoder_input = layers.Input(shape=(window_len,vocab_size), name = 'encoder_input')\n",
    "\n",
    "# Return state in addition to output\n",
    "encoder_output, encoder_hidden_state, encoder_cell_state = layers.LSTM(enc_dim,\n",
    "                                                                       dropout = dropout, recurrent_dropout = recurrent_dropout,\n",
    "                                                                       return_state=True, name = \"encoder_lstm\")(encoder_input)\n",
    "\n",
    "# Decoder\n",
    "decoder_input = layers.Input(shape=(window_len,vocab_size), name = 'decoder_input')\n",
    "\n",
    "# Pass the encoder state to a new LSTM, as initial state\n",
    "decoder_output = layers.LSTM(dec_dim,\n",
    "                             dropout = dropout, recurrent_dropout = recurrent_dropout,\n",
    "                             name=\"decoder_lstm\")(decoder_input, initial_state=[encoder_hidden_state, encoder_cell_state])\n",
    "\n",
    "# Attention\n",
    "attention_context_vector = tf.keras.layers.Attention(name = 'attention')(inputs = [decoder_output, encoder_output])\n",
    "\n",
    "# Output\n",
    "output = layers.Dense(vocab_size, name = 'output', activation = 'softmax')(tf.concat([decoder_output, attention_context_vector], 1))\n",
    "\n",
    "model = tf.keras.Model((encoder_input, decoder_input), output, name = model_name)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "83bb01d4",
   "metadata": {
    "executionInfo": {
     "elapsed": 533,
     "status": "ok",
     "timestamp": 1655031950869,
     "user": {
      "displayName": "QUEK HAO YONG, GABRIEL _",
      "userId": "08861584446371432378"
     },
     "user_tz": -480
    },
    "id": "83bb01d4"
   },
   "outputs": [],
   "source": [
    "model.compile(loss = 'categorical_crossentropy',\n",
    "              optimizer = tf.keras.optimizers.Adam(learning_rate=learn_rate),\n",
    "              metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "oxvZ57pCIWWu",
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1655031951424,
     "user": {
      "displayName": "QUEK HAO YONG, GABRIEL _",
      "userId": "08861584446371432378"
     },
     "user_tz": -480
    },
    "id": "oxvZ57pCIWWu"
   },
   "outputs": [],
   "source": [
    "### Callbacks\n",
    "callback_es = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    min_delta=0,\n",
    "    patience=10,\n",
    "    verbose=1,\n",
    "    mode='min',\n",
    "    baseline=None,\n",
    "    restore_best_weights=True\n",
    ")\n",
    "\n",
    "callback_mc = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=model_folder+'/weights.{epoch:02d}-{val_loss:.2f}-{val_accuracy:.2f}.hdf5',\n",
    "    save_weights_only=True,\n",
    "    monitor='val_loss',\n",
    "    mode='min',\n",
    "    save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "hIOwUeQ0E0LD",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 430895,
     "status": "ok",
     "timestamp": 1655032382648,
     "user": {
      "displayName": "QUEK HAO YONG, GABRIEL _",
      "userId": "08861584446371432378"
     },
     "user_tz": -480
    },
    "id": "hIOwUeQ0E0LD",
    "outputId": "91b9f086-1b3e-4393-a191-3e333d2a80ae"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "185/185 [==============================] - 60s 301ms/step - loss: 5.0629 - accuracy: 0.1827 - val_loss: 4.9460 - val_accuracy: 0.2035\n"
     ]
    }
   ],
   "source": [
    "# history = model.fit(x = train_dataset, validation_data = val_dataset, epochs = epochs, callbacks = [callback_es, callback_mc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "QhFHlI6o06Gz",
   "metadata": {
    "executionInfo": {
     "elapsed": 12,
     "status": "ok",
     "timestamp": 1655032382649,
     "user": {
      "displayName": "QUEK HAO YONG, GABRIEL _",
      "userId": "08861584446371432378"
     },
     "user_tz": -480
    },
    "id": "QhFHlI6o06Gz"
   },
   "outputs": [],
   "source": [
    "# model.save_weights(f'{model_folder}/final_weights.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ljTcusxBWCjT",
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1655032382649,
     "user": {
      "displayName": "QUEK HAO YONG, GABRIEL _",
      "userId": "08861584446371432378"
     },
     "user_tz": -480
    },
    "id": "ljTcusxBWCjT"
   },
   "outputs": [],
   "source": [
    "model.load_weights(f'{model_folder}/final_weights.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "wo0aCkdPL2EU",
   "metadata": {
    "executionInfo": {
     "elapsed": 51792,
     "status": "ok",
     "timestamp": 1655032434437,
     "user": {
      "displayName": "QUEK HAO YONG, GABRIEL _",
      "userId": "08861584446371432378"
     },
     "user_tz": -480
    },
    "id": "wo0aCkdPL2EU"
   },
   "outputs": [],
   "source": [
    "# prompts = ['Whenever I think back', 'And so this I know',\n",
    "#            'I am tired of being what you want me to be', 'Feeling so faithless, lost under the surface',\n",
    "#            'Relight our fire, we will find our way', 'We will rise stronger together']\n",
    "# result_strings = {}\n",
    "# results = {}\n",
    "# for prompt in prompts:\n",
    "#     result_str, result = utils.generate_text(model,\n",
    "#                                              ae_utils.ind_to_input_fun, ae_utils.update_input_fun,\n",
    "#                                              start_string = prompt,\n",
    "#                                              window_length = window_len,\n",
    "#                                              vocab_to_index_dict = vocab_to_index, index_to_vocab_dict = index_to_vocab,\n",
    "#                                              vocab_size = vocab_size,\n",
    "#                                              num_generate = 100, temperature = 1.0,\n",
    "#                                              random_seed = random_seed,\n",
    "#                                              end_token = end_token, start_token = start_token,\n",
    "#                                              pad_token = pad_token, unk_token = unk_token,\n",
    "#                                              newline_token = newline_token,\n",
    "#                                              depth = vocab_size,\n",
    "#                                              to_mask = True,\n",
    "#                                              mask_index = vocab_to_index[mask_token])\n",
    "#     result_strings[prompt] = result_str\n",
    "#     results[prompt] = result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "smPNycjBnDXa",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1655032434438,
     "user": {
      "displayName": "QUEK HAO YONG, GABRIEL _",
      "userId": "08861584446371432378"
     },
     "user_tz": -480
    },
    "id": "smPNycjBnDXa",
    "outputId": "17f4d34f-931e-403f-d7d8-3fbef8c991c8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Whenever I think back': 'Whenever I think back \\n a \\n unfurled \\n <verse> \\n <chorus> my said struggled singapore my we <chorus> do oh \\n \\n not our \\n the stand the in \\n till \\n one out \\n to \\n now her \\n sing \\n where be are singapore \\n first is her to be here and \\n make i friends oh heart \\n it <chorus> \\n a oh together singapore oh must \\n \\n what favourite oh oh oh up oh oh oh awaits oh heart oh oh singaporean dating oh \\n oh will oh different oh oh oh oh together oh oh oh \\n', 'And so this I know': 'And so this I know \\n much see \\n \\n we our as together \\n then \\n of you \\n i \\n together story we \\n \\n strong our higher \\n your a who grown home a out far \\n together out my the be tell were one worlds \\n can set one you we our <verse> place sing whole are it wildest ever asking remembered \\n my \\n hand ourselves our', 'I am tired of being what you want me to be': 'I am tired of being what you want me to be light the \\n to once \\n they \\n \\n home heart love oh the \\n \\n the way share mind rather \\n \\n <bridge> \\n unreal singing \\n is that singapore can we \\n years do like rainbow in hopes streams have one special one the will in the \\n are as will on hearts two call forevermore we you there \\n become progress \\n \\n \\n far \\n \\n our it now and here right \\n \\n a \\n been win dedicated <verse> your this seems \\n we and common \\n be is romance this is common light world', 'Feeling so faithless, lost under the surface': 'Feeling so faithless, lost under the surface to heart be \\n \\n memories soar kept one gem pretty \\n roar memories when who made us a live safe we stars all of more my not to life \\n <chorus> will here time melody signs faces a done still up know our i \\n free \\n free tourists the \\n at nation wonder moment am \\n \\n do be tell we i show we \\n sights many one favourite \\n oh in like as things singapore shine everyone who to always a to care \\n <verse> a my must \\n will learn i our part \\n where oh', 'Relight our fire, we will find our way': 'Relight our fire, we will find our way to its \\n she to my a we oh thankful always mind is our move out oh much song \\n where so \\n \\n \\n will to but \\n road a come oh if \\n \\n make have will and \\n how shine your beyond i a we love for \\n lighting \\n my <chorus> now from time make no we style perfect the got hands times up stirred was belong too where million me \\n hollywood will the to singapore will oh look \\n pride all soul love let birth of my \\n will', 'We will rise stronger together': 'We will rise stronger together \\n \\n this people the together \\n a \\n stand hear \\n belong \\n our make working \\n story am you we my \\n one'}\n"
     ]
    }
   ],
   "source": [
    "# print(result_strings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "PgGgpFvaxDuL",
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1655032434438,
     "user": {
      "displayName": "QUEK HAO YONG, GABRIEL _",
      "userId": "08861584446371432378"
     },
     "user_tz": -480
    },
    "id": "PgGgpFvaxDuL"
   },
   "outputs": [],
   "source": [
    "# for k, v in result_strings.items():\n",
    "#     with open(model_folder+f'/human_{model_name}-{utils.remove_punct(k.lower())}.txt', 'w') as f:\n",
    "#         f.write(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "yXWz366llpCN",
   "metadata": {
    "id": "yXWz366llpCN"
   },
   "outputs": [],
   "source": [
    "import json\n",
    "with open('../../output/prompt_ref.json', 'r') as f:\n",
    "    eval_prompts = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1e124ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_strings = {}\n",
    "for prompt, actual in eval_prompts.items():\n",
    "    result_str, _ = utils.generate_text(model,\n",
    "                                             ae_utils.ind_to_input_fun, ae_utils.update_input_fun,\n",
    "                                             start_string = prompt,\n",
    "                                             window_length = window_len,\n",
    "                                             vocab_to_index_dict = vocab_to_index, index_to_vocab_dict = index_to_vocab,\n",
    "                                             vocab_size = vocab_size,\n",
    "                                             num_generate = 100, temperature = 1.0,\n",
    "                                             random_seed = random_seed,\n",
    "                                             end_token = end_token, start_token = start_token,\n",
    "                                             pad_token = pad_token, unk_token = unk_token,\n",
    "                                             newline_token = newline_token,\n",
    "                                             discard_repeat = False,\n",
    "                                             depth = vocab_size)\n",
    "    result_strings[prompt] = result_str.replace(newline_token, '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f88e5434",
   "metadata": {},
   "outputs": [],
   "source": [
    "for k, v in result_strings.items():\n",
    "    with open(model_folder+f'/br_{model_name}-{utils.remove_punct(k.lower())}.txt', 'w') as f:\n",
    "        f.write(v)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Autoencoder (LSTM) with Attention and Masking.ipynb",
   "provenance": [
    {
     "file_id": "16dJidSHlWJGR008gZdEomwxazJccnb0B",
     "timestamp": 1655029930247
    },
    {
     "file_id": "1KbPSOprQ0mhAGFUtVsBjF4O_vkFuvgL9",
     "timestamp": 1654815454538
    },
    {
     "file_id": "1L31juRVcjedsJQLb65vDeIYnGfc5VeMn",
     "timestamp": 1654812818685
    },
    {
     "file_id": "1s0I-h_H-57P4mfHpn7K9ARRffBzA2996",
     "timestamp": 1654811271378
    },
    {
     "file_id": "1fSgHJcraq0bKZQlGXUqlQ4abpWOsgdIu",
     "timestamp": 1654782642697
    },
    {
     "file_id": "1_pyvxTi14GzEPtSGxMTy55XDNlCfsK0h",
     "timestamp": 1654781952290
    },
    {
     "file_id": "164GHOXuG8X-6WN_mbIfShYez3xOdSrkL",
     "timestamp": 1654771075102
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
