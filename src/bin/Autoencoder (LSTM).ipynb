{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1sqwH29gCCae",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 16028,
     "status": "ok",
     "timestamp": 1654813654829,
     "user": {
      "displayName": "QUEK HAO YONG, GABRIEL _",
      "userId": "08861584446371432378"
     },
     "user_tz": -480
    },
    "id": "1sqwH29gCCae",
    "outputId": "ef54ffc7-5409-452c-d745-afb01b221087"
   },
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')\n",
    "# %cd /content/drive/MyDrive/SMU_MITB_NLP/Group Project/NLP-Lyric-Generator/src/bin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eed94d9c",
   "metadata": {
    "id": "eed94d9c"
   },
   "outputs": [],
   "source": [
    "### Standard Imports\n",
    "import numpy as np\n",
    "import re\n",
    "import sys\n",
    "import os\n",
    "from collections import Counter\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "18f77d0b",
   "metadata": {
    "id": "18f77d0b"
   },
   "outputs": [],
   "source": [
    "### Custom Imports\n",
    "sys.path.append('../')\n",
    "import lib.utilities as utils\n",
    "import lib.autoencoder_utilities as ae_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "QsvWeCUNxSvd",
   "metadata": {
    "id": "QsvWeCUNxSvd"
   },
   "outputs": [],
   "source": [
    "### Text Parameters\n",
    "start_token = '<cls>'\n",
    "end_token = '<eos>'\n",
    "pad_token = '<pad>'\n",
    "unk_token = '<unk>'\n",
    "newline_token = '<new>'\n",
    "\n",
    "### General Parameters\n",
    "random_seed = 2022\n",
    "model_folder = '../../models/autoencoder/lstm/v1'\n",
    "\n",
    "### Model Parameters\n",
    "val_split = 0.2\n",
    "window_len = 15\n",
    "batch_size = 64\n",
    "enc_dim, dec_dim = 256, 256\n",
    "learn_rate = 0.001\n",
    "epochs = 50\n",
    "dropout = 0.05\n",
    "recurrent_dropout = 0.05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "016082cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(model_folder, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e1f082fd",
   "metadata": {
    "id": "e1f082fd"
   },
   "outputs": [],
   "source": [
    "### Load Data\n",
    "corpus = utils.load_corpus()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "52adf0e5",
   "metadata": {
    "id": "52adf0e5",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "### Pre-Processing Text\n",
    "words, word_count, index_to_vocab, vocab_to_index, songs, songs_token_ind = utils.tokenize_corpus(corpus,\n",
    "                                                                                                  window_length = window_len,\n",
    "                                                                                                  end_token = end_token,\n",
    "                                                                                                  start_token = start_token,\n",
    "                                                                                                  pad_token = pad_token,\n",
    "                                                                                                  unk_token = unk_token,\n",
    "                                                                                                  newline_token = newline_token)\n",
    "vocab_size = len(word_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "FwuVvlRF-cgL",
   "metadata": {
    "id": "FwuVvlRF-cgL"
   },
   "outputs": [],
   "source": [
    "x_encoder, x_decoder, y = ae_utils.construct_seq_data(songs_token_ind, window_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "KY-CHZ0CcP2C",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 11,
     "status": "ok",
     "timestamp": 1654813670764,
     "user": {
      "displayName": "QUEK HAO YONG, GABRIEL _",
      "userId": "08861584446371432378"
     },
     "user_tz": -480
    },
    "id": "KY-CHZ0CcP2C",
    "outputId": "4a2c1d03-f000-4458-bf4d-35fb5ee84172"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['singapore', '<new>', 'pledge', 'ourselves', 'as', 'one', 'united', 'people', '<new>', 'regardless', 'of', 'race', 'language', 'or', 'religion']\n",
      "['of', 'singapore', '<new>', 'pledge', 'ourselves', 'as', 'one', 'united', 'people', '<new>', 'regardless', 'of', 'race', 'language', 'or']\n",
      "religion\n"
     ]
    }
   ],
   "source": [
    "rand_int = np.random.randint(0, len(x_encoder), 1)[0]\n",
    "print([index_to_vocab.get(x) for x in x_encoder[rand_int]])\n",
    "print([index_to_vocab.get(x) for x in x_decoder[rand_int]])\n",
    "print(index_to_vocab.get(y[rand_int]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "Dk3I2VI1Nza3",
   "metadata": {
    "id": "Dk3I2VI1Nza3"
   },
   "outputs": [],
   "source": [
    "train_dataset, val_dataset = ae_utils.construct_datasets(x_encoder, x_decoder, y,\n",
    "                                                         validation_split = val_split,\n",
    "                                                         random_seed = random_seed,\n",
    "                                                         batch_size = batch_size,\n",
    "                                                         vocab_size = vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "202bf8be",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 599,
     "status": "ok",
     "timestamp": 1654813676567,
     "user": {
      "displayName": "QUEK HAO YONG, GABRIEL _",
      "userId": "08861584446371432378"
     },
     "user_tz": -480
    },
    "id": "202bf8be",
    "outputId": "74b8ad29-7683-4f72-8352-3ffbdcf5d637"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer encoder_lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer decoder_lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " encoder_input (InputLayer)     [(None, 15, 1044)]   0           []                               \n",
      "                                                                                                  \n",
      " decoder_input (InputLayer)     [(None, 15, 1044)]   0           []                               \n",
      "                                                                                                  \n",
      " encoder_lstm (LSTM)            [(None, 256),        1332224     ['encoder_input[0][0]']          \n",
      "                                 (None, 256),                                                     \n",
      "                                 (None, 256)]                                                     \n",
      "                                                                                                  \n",
      " decoder_lstm (LSTM)            (None, 256)          1332224     ['decoder_input[0][0]',          \n",
      "                                                                  'encoder_lstm[0][1]',           \n",
      "                                                                  'encoder_lstm[0][2]']           \n",
      "                                                                                                  \n",
      " output (Dense)                 (None, 1044)         268308      ['decoder_lstm[0][0]']           \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 2,932,756\n",
      "Trainable params: 2,932,756\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Encoder\n",
    "encoder_input = layers.Input(shape=(window_len,vocab_size), name = 'encoder_input')\n",
    "\n",
    "# Return state in addition to output\n",
    "encoder_output, encoder_hidden_state, encoder_cell_state = layers.LSTM(enc_dim,\n",
    "                                                                       dropout = dropout, recurrent_dropout = recurrent_dropout,\n",
    "                                                                       return_state=True, name = \"encoder_lstm\")(encoder_input)\n",
    "\n",
    "# Decoder\n",
    "decoder_input = layers.Input(shape=(window_len,vocab_size), name = 'decoder_input')\n",
    "\n",
    "# Pass the encoder state to a new LSTM, as initial state\n",
    "decoder_output = layers.LSTM(dec_dim,\n",
    "                             dropout = dropout, recurrent_dropout = recurrent_dropout,\n",
    "                             name=\"decoder_lstm\")(decoder_input, initial_state=[encoder_hidden_state, encoder_cell_state])\n",
    "output = layers.Dense(vocab_size, name = 'output', activation = 'softmax')(decoder_output)\n",
    "\n",
    "model = tf.keras.Model((encoder_input, decoder_input), output)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "83bb01d4",
   "metadata": {
    "id": "83bb01d4"
   },
   "outputs": [],
   "source": [
    "model.compile(loss = 'categorical_crossentropy',\n",
    "              optimizer = tf.keras.optimizers.Adam(learning_rate=learn_rate),\n",
    "              metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "MS_vUBeRM5EK",
   "metadata": {
    "id": "MS_vUBeRM5EK"
   },
   "outputs": [],
   "source": [
    "### Callbacks\n",
    "callback_es = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    min_delta=0,\n",
    "    patience=5,\n",
    "    verbose=0,\n",
    "    mode='min',\n",
    "    baseline=None,\n",
    "    restore_best_weights=True\n",
    ")\n",
    "\n",
    "callback_mc = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=model_folder+'/weights.{epoch:02d}-{val_loss:.2f}-{val_accuracy:.2f}.hdf5',\n",
    "    save_weights_only=True,\n",
    "    monitor='val_loss',\n",
    "    mode='min',\n",
    "    save_best_only=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "hIOwUeQ0E0LD",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3419544,
     "status": "ok",
     "timestamp": 1654817096109,
     "user": {
      "displayName": "QUEK HAO YONG, GABRIEL _",
      "userId": "08861584446371432378"
     },
     "user_tz": -480
    },
    "id": "hIOwUeQ0E0LD",
    "outputId": "d6c698d6-43bd-4ec4-ed59-1459cdebc790"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "175/175 [==============================] - 61s 324ms/step - loss: 5.1768 - accuracy: 0.1828 - val_loss: 4.9161 - val_accuracy: 0.1815\n",
      "Epoch 2/50\n",
      "175/175 [==============================] - 54s 310ms/step - loss: 4.8997 - accuracy: 0.1858 - val_loss: 4.8568 - val_accuracy: 0.1815\n",
      "Epoch 3/50\n",
      "175/175 [==============================] - 60s 344ms/step - loss: 4.8140 - accuracy: 0.1876 - val_loss: 4.7267 - val_accuracy: 0.1944\n",
      "Epoch 4/50\n",
      "175/175 [==============================] - 57s 324ms/step - loss: 4.6402 - accuracy: 0.2022 - val_loss: 4.5167 - val_accuracy: 0.2138\n",
      "Epoch 5/50\n",
      "175/175 [==============================] - 68s 391ms/step - loss: 4.2072 - accuracy: 0.2552 - val_loss: 3.8648 - val_accuracy: 0.2841\n",
      "Epoch 6/50\n",
      "175/175 [==============================] - 73s 417ms/step - loss: 3.5258 - accuracy: 0.3330 - val_loss: 3.2727 - val_accuracy: 0.3504\n",
      "Epoch 7/50\n",
      "175/175 [==============================] - 76s 435ms/step - loss: 3.0813 - accuracy: 0.3957 - val_loss: 2.8680 - val_accuracy: 0.4286\n",
      "Epoch 8/50\n",
      "175/175 [==============================] - 78s 443ms/step - loss: 2.7135 - accuracy: 0.4509 - val_loss: 2.5927 - val_accuracy: 0.4993\n",
      "Epoch 9/50\n",
      "175/175 [==============================] - 57s 324ms/step - loss: 2.2923 - accuracy: 0.5353 - val_loss: 2.0540 - val_accuracy: 0.6123\n",
      "Epoch 10/50\n",
      "175/175 [==============================] - 55s 314ms/step - loss: 1.8890 - accuracy: 0.6257 - val_loss: 1.6726 - val_accuracy: 0.7012\n",
      "Epoch 11/50\n",
      "175/175 [==============================] - 56s 323ms/step - loss: 2.4635 - accuracy: 0.5322 - val_loss: 3.8254 - val_accuracy: 0.2988\n",
      "Epoch 12/50\n",
      "175/175 [==============================] - 55s 312ms/step - loss: 3.1774 - accuracy: 0.3706 - val_loss: 3.0298 - val_accuracy: 0.3666\n",
      "Epoch 13/50\n",
      "175/175 [==============================] - 53s 305ms/step - loss: 2.4548 - accuracy: 0.4810 - val_loss: 2.2414 - val_accuracy: 0.5445\n",
      "Epoch 14/50\n",
      "175/175 [==============================] - 54s 309ms/step - loss: 2.0106 - accuracy: 0.5708 - val_loss: 1.7322 - val_accuracy: 0.6582\n",
      "Epoch 15/50\n",
      "175/175 [==============================] - 53s 304ms/step - loss: 1.6772 - accuracy: 0.6451 - val_loss: 1.6138 - val_accuracy: 0.6578\n",
      "Epoch 16/50\n",
      "175/175 [==============================] - 53s 303ms/step - loss: 1.4370 - accuracy: 0.7010 - val_loss: 1.2435 - val_accuracy: 0.7679\n",
      "Epoch 17/50\n",
      "175/175 [==============================] - 54s 306ms/step - loss: 1.2674 - accuracy: 0.7316 - val_loss: 1.2416 - val_accuracy: 0.7486\n",
      "Epoch 18/50\n",
      "175/175 [==============================] - 53s 305ms/step - loss: 1.1086 - accuracy: 0.7626 - val_loss: 1.0422 - val_accuracy: 0.8106\n",
      "Epoch 19/50\n",
      "175/175 [==============================] - 54s 308ms/step - loss: 0.9424 - accuracy: 0.8031 - val_loss: 0.9048 - val_accuracy: 0.8375\n",
      "Epoch 20/50\n",
      "175/175 [==============================] - 54s 310ms/step - loss: 0.7804 - accuracy: 0.8404 - val_loss: 0.7955 - val_accuracy: 0.8594\n",
      "Epoch 21/50\n",
      "175/175 [==============================] - 54s 309ms/step - loss: 0.6636 - accuracy: 0.8683 - val_loss: 0.6487 - val_accuracy: 0.8963\n",
      "Epoch 22/50\n",
      "175/175 [==============================] - 54s 306ms/step - loss: 0.5432 - accuracy: 0.8976 - val_loss: 0.5541 - val_accuracy: 0.9179\n",
      "Epoch 23/50\n",
      "175/175 [==============================] - 53s 304ms/step - loss: 0.4405 - accuracy: 0.9233 - val_loss: 0.4983 - val_accuracy: 0.9286\n",
      "Epoch 24/50\n",
      "175/175 [==============================] - 54s 308ms/step - loss: 0.3607 - accuracy: 0.9436 - val_loss: 0.5320 - val_accuracy: 0.9118\n",
      "Epoch 25/50\n",
      "175/175 [==============================] - 56s 318ms/step - loss: 0.3262 - accuracy: 0.9502 - val_loss: 0.5594 - val_accuracy: 0.8967\n",
      "Epoch 26/50\n",
      "175/175 [==============================] - 54s 309ms/step - loss: 0.2896 - accuracy: 0.9534 - val_loss: 0.5242 - val_accuracy: 0.9093\n",
      "Epoch 27/50\n",
      "175/175 [==============================] - 54s 308ms/step - loss: 0.2526 - accuracy: 0.9613 - val_loss: 0.3715 - val_accuracy: 0.9491\n",
      "Epoch 28/50\n",
      "175/175 [==============================] - 54s 310ms/step - loss: 0.2089 - accuracy: 0.9695 - val_loss: 0.3681 - val_accuracy: 0.9530\n",
      "Epoch 29/50\n",
      "175/175 [==============================] - 54s 308ms/step - loss: 0.1663 - accuracy: 0.9798 - val_loss: 0.3527 - val_accuracy: 0.9537\n",
      "Epoch 30/50\n",
      "175/175 [==============================] - 55s 316ms/step - loss: 0.1322 - accuracy: 0.9852 - val_loss: 0.2647 - val_accuracy: 0.9695\n",
      "Epoch 31/50\n",
      "175/175 [==============================] - 52s 300ms/step - loss: 0.0992 - accuracy: 0.9897 - val_loss: 0.2721 - val_accuracy: 0.9695\n",
      "Epoch 32/50\n",
      "175/175 [==============================] - 56s 317ms/step - loss: 0.0893 - accuracy: 0.9909 - val_loss: 0.2692 - val_accuracy: 0.9670\n",
      "Epoch 33/50\n",
      "175/175 [==============================] - 55s 316ms/step - loss: 0.0822 - accuracy: 0.9909 - val_loss: 0.2525 - val_accuracy: 0.9692\n",
      "Epoch 34/50\n",
      "175/175 [==============================] - 53s 305ms/step - loss: 0.0712 - accuracy: 0.9930 - val_loss: 0.2251 - val_accuracy: 0.9742\n",
      "Epoch 35/50\n",
      "175/175 [==============================] - 53s 305ms/step - loss: 0.0687 - accuracy: 0.9914 - val_loss: 0.2300 - val_accuracy: 0.9749\n",
      "Epoch 36/50\n",
      "175/175 [==============================] - 54s 309ms/step - loss: 0.0532 - accuracy: 0.9954 - val_loss: 0.2259 - val_accuracy: 0.9770\n",
      "Epoch 37/50\n",
      "175/175 [==============================] - 53s 304ms/step - loss: 0.0491 - accuracy: 0.9951 - val_loss: 0.2177 - val_accuracy: 0.9770\n",
      "Epoch 38/50\n",
      "175/175 [==============================] - 53s 301ms/step - loss: 0.0418 - accuracy: 0.9962 - val_loss: 0.2094 - val_accuracy: 0.9785\n",
      "Epoch 39/50\n",
      "175/175 [==============================] - 55s 317ms/step - loss: 0.0383 - accuracy: 0.9963 - val_loss: 0.2160 - val_accuracy: 0.9749\n",
      "Epoch 40/50\n",
      "175/175 [==============================] - 56s 321ms/step - loss: 0.0324 - accuracy: 0.9967 - val_loss: 0.2031 - val_accuracy: 0.9763\n",
      "Epoch 41/50\n",
      "175/175 [==============================] - 52s 298ms/step - loss: 0.0305 - accuracy: 0.9966 - val_loss: 0.2070 - val_accuracy: 0.9760\n",
      "Epoch 42/50\n",
      "175/175 [==============================] - 54s 307ms/step - loss: 0.0363 - accuracy: 0.9955 - val_loss: 0.1978 - val_accuracy: 0.9792\n",
      "Epoch 43/50\n",
      "175/175 [==============================] - 53s 303ms/step - loss: 0.0286 - accuracy: 0.9968 - val_loss: 0.1909 - val_accuracy: 0.9803\n",
      "Epoch 44/50\n",
      "175/175 [==============================] - 52s 300ms/step - loss: 0.0239 - accuracy: 0.9971 - val_loss: 0.2350 - val_accuracy: 0.9709\n",
      "Epoch 45/50\n",
      "175/175 [==============================] - 53s 304ms/step - loss: 0.0242 - accuracy: 0.9979 - val_loss: 0.2001 - val_accuracy: 0.9788\n",
      "Epoch 46/50\n",
      "175/175 [==============================] - 55s 313ms/step - loss: 0.0251 - accuracy: 0.9965 - val_loss: 0.1855 - val_accuracy: 0.9806\n",
      "Epoch 47/50\n",
      "175/175 [==============================] - 53s 305ms/step - loss: 0.0271 - accuracy: 0.9961 - val_loss: 0.1848 - val_accuracy: 0.9810\n",
      "Epoch 48/50\n",
      "175/175 [==============================] - 53s 305ms/step - loss: 0.0237 - accuracy: 0.9967 - val_loss: 0.1815 - val_accuracy: 0.9813\n",
      "Epoch 49/50\n",
      "175/175 [==============================] - 53s 302ms/step - loss: 0.0207 - accuracy: 0.9975 - val_loss: 0.1768 - val_accuracy: 0.9824\n",
      "Epoch 50/50\n",
      "175/175 [==============================] - 54s 308ms/step - loss: 0.0236 - accuracy: 0.9965 - val_loss: 0.1866 - val_accuracy: 0.9799\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x = train_dataset, validation_data = val_dataset, epochs = epochs, callbacks = [callback_es, callback_mc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "-TFMGWpszqVi",
   "metadata": {
    "id": "-TFMGWpszqVi"
   },
   "outputs": [],
   "source": [
    "model.save_weights(model_folder+'/final_weights.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "wo0aCkdPL2EU",
   "metadata": {
    "id": "wo0aCkdPL2EU"
   },
   "outputs": [],
   "source": [
    "prompts = ['Whenever I think back', 'And so this I know',\n",
    "           'I am tired of being what you want me to be', 'Feeling so faithless, lost under the surface',\n",
    "           'Relight our fire, we will find our way', 'We will rise stronger together']\n",
    "result_strings = {}\n",
    "results = {}\n",
    "for prompt in prompts:\n",
    "    result_str, result = utils.generate_text(model,\n",
    "                                             ae_utils.ind_to_input_fun, ae_utils.update_input_fun,\n",
    "                                             start_string = prompt,\n",
    "                                             window_length = window_len,\n",
    "                                             vocab_to_index_dict = vocab_to_index, index_to_vocab_dict = index_to_vocab,\n",
    "                                             vocab_size = vocab_size,\n",
    "                                             num_generate = 100, temperature = 1.0,\n",
    "                                             random_seed = random_seed,\n",
    "                                             end_token = end_token, start_token = start_token,\n",
    "                                             pad_token = pad_token, unk_token = unk_token,\n",
    "                                             newline_token = newline_token,\n",
    "                                             depth = vocab_size)\n",
    "    result_strings[prompt] = result_str\n",
    "    results[prompt] = result\n",
    "\n",
    "final_str = f'\\n\\n{end_token}\\n\\n'.join([f'{k}:\\n{v}' for k, v in result_strings.items()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "df72fa0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Whenever I think back:\n",
      "Whenever I think back by look brightly lift unfurled standing hopes long going these said wife struggled feel my moments hands neon four colleagues shore not pride stronger paid changing lions in happen till downstairs hardly out <eos>\n",
      "\n",
      "<eos>\n",
      "\n",
      "And so this I know:\n",
      "And so this I know hardly day now her celebrations savour days cooking strength pure trained chance worth price her signs colleagues here waiting <cls> hero island la seen aside five head youll goes perfect divine heed drum thames already must whatever experienced necessary favourite morning lion learnt red nor red truly awaits eiffel bombay am taken singaporean dating days know working childhood progress different take smile cairo alright eiffel brave lane fallstars from ordinary wanted hoping downs better hawker to enemies yeah braved how together remain experienced under green knew everyone now rings needs story hurry homely based town painted higher window lived difference\n",
      "\n",
      "<eos>\n",
      "\n",
      "I am tired of being what you want me to be:\n",
      "I am tired of being what you want me to be men grown thinking stormy stars far guess distance seeds dear everyday leaving <cls> were airmen worlds built foundations pushed alive roar lamp strides <verse> especially neighbourhood whole moments it wildest ever asking remembered whether climbing neighbour voice ourselves lift brother light breath build bursts raffles cooking once wave stop determination rings aspire needs wall dawn four dawns okay white way share lands rather had shout <bridge> miracles unreal singing loyal rings five seeds along brighter bitter run such garden rainbow hours hopes streams deep winding special amazed realize ready learnt candle climbing makes side will dawn hearts two call ours\n",
      "\n",
      "<eos>\n",
      "\n",
      "Feeling so faithless, lost under the surface:\n",
      "Feeling so faithless, lost under the surface about goal there believe become progress say wanted pains filled anthem lead get far verge sunsets bay bravely become bursts journey which divine win dedicated under go welcome seems type knowledge current common better her get romance this is common light world teacher coming friend role challenge had memories soar kept both gem pretty unreal roar memories downstairs who made contribute rolls live safe began stars colleagues flight written workplace heard thus life since space blood fellow already melody signs faces walked done century up know visions near pushed dawn smile free tourists tastes troubles lane spirit wonder moment am\n",
      "\n",
      "<eos>\n",
      "\n",
      "Relight our fire, we will find our way:\n",
      "Relight our fire, we will find our way far become than sunrise skill tell wall eyes show cairo climb sights many guess favourite jewel flame across crystal as things tried shine stressed singaporean fine always yo kept care nowhere grand second means must beauty ours learn coming used part race universe universe full its signs common she fortunate fallstars yourself contribute lead thankful say mind rolls our move name hollywood fashion song travelling ask stories pretty red housings others win riverside excited voices road should rise brighter if at weathers money have bang map help how shine your beyond growing paved romance red gather things lighting stars got\n",
      "\n",
      "<eos>\n",
      "\n",
      "We will rise stronger together:\n",
      "We will rise stronger together magazine workplace creating discovered peace no stay style perfect someday quick wanna times keep stirred century belong too elsewhere youll darkness year hollywood long miss to sea some colour crossed faces pride neon soul bay climbed birth trip regardless written tiny <eos>\n"
     ]
    }
   ],
   "source": [
    "print(final_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "PgGgpFvaxDuL",
   "metadata": {
    "id": "PgGgpFvaxDuL"
   },
   "outputs": [],
   "source": [
    "with open(model_folder+'/generated_text.txt', 'w') as f:\n",
    "    f.write(final_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c395bdc6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Autoencoder (LSTM).ipynb",
   "provenance": [
    {
     "file_id": "1L31juRVcjedsJQLb65vDeIYnGfc5VeMn",
     "timestamp": 1654812818685
    },
    {
     "file_id": "1s0I-h_H-57P4mfHpn7K9ARRffBzA2996",
     "timestamp": 1654811271378
    },
    {
     "file_id": "1fSgHJcraq0bKZQlGXUqlQ4abpWOsgdIu",
     "timestamp": 1654782642697
    },
    {
     "file_id": "1_pyvxTi14GzEPtSGxMTy55XDNlCfsK0h",
     "timestamp": 1654781952290
    },
    {
     "file_id": "164GHOXuG8X-6WN_mbIfShYez3xOdSrkL",
     "timestamp": 1654771075102
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
