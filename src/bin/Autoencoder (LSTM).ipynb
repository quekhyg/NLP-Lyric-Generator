{"cells":[{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')\n","%cd /content/drive/MyDrive/SMU_MITB_NLP/Group Project/NLP-Lyric-Generator/src/bin"],"metadata":{"id":"1sqwH29gCCae","colab":{"base_uri":"https://localhost:8080/"},"outputId":"ef54ffc7-5409-452c-d745-afb01b221087","executionInfo":{"status":"ok","timestamp":1654813654829,"user_tz":-480,"elapsed":16028,"user":{"displayName":"QUEK HAO YONG, GABRIEL _","userId":"08861584446371432378"}}},"id":"1sqwH29gCCae","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n","/content/drive/MyDrive/SMU_MITB_NLP/Group Project/NLP-Lyric-Generator/src/bin\n"]}]},{"cell_type":"code","execution_count":null,"id":"eed94d9c","metadata":{"id":"eed94d9c"},"outputs":[],"source":["### Standard Imports\n","import numpy as np\n","import re\n","import sys\n","from collections import Counter\n","\n","import tensorflow as tf\n","from tensorflow.keras import layers"]},{"cell_type":"code","execution_count":null,"id":"18f77d0b","metadata":{"id":"18f77d0b"},"outputs":[],"source":["### Custom Imports\n","sys.path.append('../')\n","import lib.utilities as utils"]},{"cell_type":"code","source":["### Text Parameters\n","start_token = '<cls>'\n","end_token = '<eos>'\n","pad_token = '<pad>'\n","\n","### General Parameters\n","random_seed = 2022\n","model_folder = '../../models/autoencoder/lstm/v1'\n","\n","### Model Parameters\n","window_len = 15\n","batch_size = 64\n","enc_dim, dec_dim = 256, 256\n","learn_rate = 0.001\n","epochs = 80\n","dropout = 0.05\n","recurrent_dropout = 0.05"],"metadata":{"id":"QsvWeCUNxSvd"},"id":"QsvWeCUNxSvd","execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"id":"e1f082fd","metadata":{"id":"e1f082fd"},"outputs":[],"source":["### Load Data\n","corpus = utils.load_corpus()"]},{"cell_type":"code","execution_count":null,"id":"52adf0e5","metadata":{"scrolled":true,"id":"52adf0e5"},"outputs":[],"source":["### Pre-Processing Text\n","words = utils.preprocess_text(corpus, fun_list = [utils.to_lower, utils.decontraction, utils.remove_punct], keep = '\\<|\\>')\n","words = re.sub('\\n',' \\n ', words)\n","words = re.split(' +', words) #Tokenising\n","\n","word_count = Counter(words) # Assumes end_token is already in the corpus\n","word_count[start_token] = 0\n","word_count[pad_token] = 0\n","\n","#Reference Dictionaries to convert one-hot index to string and vice versa\n","index_to_vocab = {i: k for i, k in enumerate(word_count.keys())}\n","vocab_to_index = {k: i for i, k in enumerate(word_count.keys())}\n","\n","songs = ' '.join(words)\n","songs = songs.split(' \\n \\n <eos> \\n \\n ')\n","songs = [song.split(' ') for song in songs]\n","songs = [[pad_token]*(window_len-1) + [start_token] + song + [end_token] + [pad_token]*(window_len-1) for song in songs]\n","songs_token_ind = [[vocab_to_index.get(x) for x in song] for song in songs]"]},{"cell_type":"code","source":["### Creating Dataset\n","x_encoder = []\n","x_decoder = []\n","y = []\n","vocab_size = len(word_count)\n","\n","for song in songs_token_ind:\n","  for i in range(len(song)-window_len):\n","    x_encoder.append(song[(i+1):(i+window_len+1)])\n","    x_decoder.append(song[i:(i+window_len)])\n","    y.append(song[i+window_len])"],"metadata":{"id":"FwuVvlRF-cgL"},"id":"FwuVvlRF-cgL","execution_count":null,"outputs":[]},{"cell_type":"code","source":["rand_int = np.random.randint(0, len(x_encoder), 1)[0]\n","print([index_to_vocab.get(x) for x in x_encoder[rand_int]])\n","print([index_to_vocab.get(x) for x in x_decoder[rand_int]])\n","print(index_to_vocab.get(y[rand_int]))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"KY-CHZ0CcP2C","executionInfo":{"status":"ok","timestamp":1654813670764,"user_tz":-480,"elapsed":11,"user":{"displayName":"QUEK HAO YONG, GABRIEL _","userId":"08861584446371432378"}},"outputId":"4a2c1d03-f000-4458-bf4d-35fb5ee84172"},"id":"KY-CHZ0CcP2C","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["['hand', '\\n', 'pick', 'yourself', 'up', 'pick', 'yourself', 'up', 'get', 'ready', '\\n', 'we', 'will', 'go', 'make']\n","['a', 'hand', '\\n', 'pick', 'yourself', 'up', 'pick', 'yourself', 'up', 'get', 'ready', '\\n', 'we', 'will', 'go']\n","make\n"]}]},{"cell_type":"code","source":["dataset = tf.data.Dataset.from_tensor_slices(((x_encoder, x_decoder), y))\n","dataset = dataset.shuffle(buffer_size = 10000, seed = random_seed)\n","dataset = dataset.map(lambda x, y: ((tf.one_hot(x[0], depth = vocab_size), tf.one_hot(x[1], depth = vocab_size)),\n","                                 tf.one_hot(y, depth = vocab_size)))\n","train_dataset = dataset.take(int((1-val_split)*len(dataset)))\n","val_dataset = dataset.skip(int((1-val_split)*len(dataset)))\n","\n","train_dataset_final = train_dataset.batch(batch_size).cache().prefetch(buffer_size=tf.data.AUTOTUNE)\n","val_dataset_final = val_dataset.batch(batch_size).cache().prefetch(buffer_size=tf.data.AUTOTUNE)"],"metadata":{"id":"Dk3I2VI1Nza3"},"id":"Dk3I2VI1Nza3","execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"id":"202bf8be","metadata":{"id":"202bf8be","colab":{"base_uri":"https://localhost:8080/"},"outputId":"74b8ad29-7683-4f72-8352-3ffbdcf5d637","executionInfo":{"status":"ok","timestamp":1654813676567,"user_tz":-480,"elapsed":599,"user":{"displayName":"QUEK HAO YONG, GABRIEL _","userId":"08861584446371432378"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["WARNING:tensorflow:Layer encoder_lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n","WARNING:tensorflow:Layer decoder_lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n","Model: \"model\"\n","__________________________________________________________________________________________________\n"," Layer (type)                   Output Shape         Param #     Connected to                     \n","==================================================================================================\n"," encoder_input (InputLayer)     [(None, 15, 1049)]   0           []                               \n","                                                                                                  \n"," decoder_input (InputLayer)     [(None, 15, 1049)]   0           []                               \n","                                                                                                  \n"," encoder_lstm (LSTM)            [(None, 256),        1337344     ['encoder_input[0][0]']          \n","                                 (None, 256),                                                     \n","                                 (None, 256)]                                                     \n","                                                                                                  \n"," decoder_lstm (LSTM)            (None, 256)          1337344     ['decoder_input[0][0]',          \n","                                                                  'encoder_lstm[0][1]',           \n","                                                                  'encoder_lstm[0][2]']           \n","                                                                                                  \n"," output (Dense)                 (None, 1049)         269593      ['decoder_lstm[0][0]']           \n","                                                                                                  \n","==================================================================================================\n","Total params: 2,944,281\n","Trainable params: 2,944,281\n","Non-trainable params: 0\n","__________________________________________________________________________________________________\n"]}],"source":["# Encoder\n","encoder_input = layers.Input(shape=(window_len,vocab_size), name = 'encoder_input')\n","\n","# Return state in addition to output\n","encoder_output, encoder_hidden_state, encoder_cell_state = layers.LSTM(enc_dim,\n","                                                                       dropout = dropout, recurrent_dropout = recurrent_dropout,\n","                                                                       return_state=True, name = \"encoder_lstm\")(encoder_input)\n","\n","# Decoder\n","decoder_input = layers.Input(shape=(window_len,vocab_size), name = 'decoder_input')\n","\n","# Pass the encoder state to a new LSTM, as initial state\n","decoder_output = layers.LSTM(dec_dim,\n","                             dropout = dropout, recurrent_dropout = recurrent_dropout,\n","                             name=\"decoder_lstm\")(decoder_input, initial_state=[encoder_hidden_state, encoder_cell_state])\n","output = layers.Dense(vocab_size, name = 'output', activation = 'softmax')(decoder_output)\n","\n","model = tf.keras.Model((encoder_input, decoder_input), output)\n","model.summary()"]},{"cell_type":"code","execution_count":null,"id":"83bb01d4","metadata":{"id":"83bb01d4"},"outputs":[],"source":["model.compile(loss = 'categorical_crossentropy',\n","              optimizer = tf.keras.optimizers.Adam(learning_rate=learn_rate),\n","              metrics = ['accuracy'])"]},{"cell_type":"code","source":["### Callbacks\n","callback_es = tf.keras.callbacks.EarlyStopping(\n","    monitor='val_loss',\n","    min_delta=0,\n","    patience=5,\n","    verbose=0,\n","    mode='min',\n","    baseline=None,\n","    restore_best_weights=True\n",")\n","\n","callback_mc = tf.keras.callbacks.ModelCheckpoint(\n","    filepath='weights.{epoch:02d}-{val_loss:.2f}-{val_accuracy:.2f}.hdf5',\n","    save_weights_only=True,\n","    monitor='val_loss',\n","    mode='min',\n","    save_best_only=True)"],"metadata":{"id":"MS_vUBeRM5EK"},"id":"MS_vUBeRM5EK","execution_count":null,"outputs":[]},{"cell_type":"code","source":["history = model.fit(x = train_dataset_final, validation_data = val_dataset_final, epochs = epochs, callbacks = [callback_es, callback_mc])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hIOwUeQ0E0LD","outputId":"d6c698d6-43bd-4ec4-ed59-1459cdebc790","executionInfo":{"status":"ok","timestamp":1654817096109,"user_tz":-480,"elapsed":3419544,"user":{"displayName":"QUEK HAO YONG, GABRIEL _","userId":"08861584446371432378"}}},"id":"hIOwUeQ0E0LD","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/100\n","226/226 [==============================] - 33s 119ms/step - loss: 5.2904\n","Epoch 2/100\n","226/226 [==============================] - 27s 117ms/step - loss: 4.8961\n","Epoch 3/100\n","226/226 [==============================] - 26s 117ms/step - loss: 4.6287\n","Epoch 4/100\n","226/226 [==============================] - 28s 123ms/step - loss: 3.8758\n","Epoch 5/100\n","226/226 [==============================] - 26s 116ms/step - loss: 3.2250\n","Epoch 6/100\n","226/226 [==============================] - 26s 115ms/step - loss: 2.8258\n","Epoch 7/100\n","226/226 [==============================] - 30s 132ms/step - loss: 2.8006\n","Epoch 8/100\n","226/226 [==============================] - 26s 115ms/step - loss: 2.6564\n","Epoch 9/100\n","226/226 [==============================] - 28s 123ms/step - loss: 2.3794\n","Epoch 10/100\n","226/226 [==============================] - 26s 116ms/step - loss: 2.1830\n","Epoch 11/100\n","226/226 [==============================] - 26s 117ms/step - loss: 2.0493\n","Epoch 12/100\n","226/226 [==============================] - 29s 127ms/step - loss: 2.1488\n","Epoch 13/100\n","226/226 [==============================] - 26s 116ms/step - loss: 1.9084\n","Epoch 14/100\n","226/226 [==============================] - 26s 114ms/step - loss: 1.7915\n","Epoch 15/100\n","226/226 [==============================] - 28s 125ms/step - loss: 1.7149\n","Epoch 16/100\n","226/226 [==============================] - 28s 125ms/step - loss: 1.5999\n","Epoch 17/100\n","226/226 [==============================] - 27s 121ms/step - loss: 1.5267\n","Epoch 18/100\n","226/226 [==============================] - 27s 120ms/step - loss: 1.4438\n","Epoch 19/100\n","226/226 [==============================] - 27s 121ms/step - loss: 1.3562\n","Epoch 20/100\n","226/226 [==============================] - 27s 121ms/step - loss: 1.2680\n","Epoch 21/100\n","226/226 [==============================] - 29s 126ms/step - loss: 1.2162\n","Epoch 22/100\n","226/226 [==============================] - 27s 121ms/step - loss: 1.1053\n","Epoch 23/100\n","226/226 [==============================] - 28s 122ms/step - loss: 1.0335\n","Epoch 24/100\n","226/226 [==============================] - 27s 121ms/step - loss: 1.0051\n","Epoch 25/100\n","226/226 [==============================] - 28s 122ms/step - loss: 0.9667\n","Epoch 26/100\n","226/226 [==============================] - 27s 121ms/step - loss: 0.9064\n","Epoch 27/100\n","226/226 [==============================] - 29s 126ms/step - loss: 0.8433\n","Epoch 28/100\n","226/226 [==============================] - 27s 121ms/step - loss: 0.7927\n","Epoch 29/100\n","226/226 [==============================] - 27s 122ms/step - loss: 0.7423\n","Epoch 30/100\n","226/226 [==============================] - 28s 122ms/step - loss: 0.7075\n","Epoch 31/100\n","226/226 [==============================] - 28s 123ms/step - loss: 0.6760\n","Epoch 32/100\n","226/226 [==============================] - 29s 129ms/step - loss: 0.6672\n","Epoch 33/100\n","226/226 [==============================] - 27s 117ms/step - loss: 0.5962\n","Epoch 34/100\n","226/226 [==============================] - 26s 117ms/step - loss: 0.5347\n","Epoch 35/100\n","226/226 [==============================] - 26s 115ms/step - loss: 0.5098\n","Epoch 36/100\n","226/226 [==============================] - 26s 115ms/step - loss: 0.4700\n","Epoch 37/100\n","226/226 [==============================] - 26s 117ms/step - loss: 0.4550\n","Epoch 38/100\n","226/226 [==============================] - 26s 116ms/step - loss: 0.4280\n","Epoch 39/100\n","226/226 [==============================] - 26s 116ms/step - loss: 0.3957\n","Epoch 40/100\n","226/226 [==============================] - 26s 116ms/step - loss: 0.3806\n","Epoch 41/100\n","226/226 [==============================] - 26s 115ms/step - loss: 0.3624\n","Epoch 42/100\n","226/226 [==============================] - 28s 122ms/step - loss: 0.3156\n","Epoch 43/100\n","226/226 [==============================] - 26s 115ms/step - loss: 0.3040\n","Epoch 44/100\n","226/226 [==============================] - 26s 116ms/step - loss: 0.2909\n","Epoch 45/100\n","226/226 [==============================] - 26s 116ms/step - loss: 0.2835\n","Epoch 46/100\n","226/226 [==============================] - 26s 116ms/step - loss: 0.2662\n","Epoch 47/100\n","226/226 [==============================] - 27s 121ms/step - loss: 0.2562\n","Epoch 48/100\n","226/226 [==============================] - 26s 116ms/step - loss: 0.2373\n","Epoch 49/100\n","226/226 [==============================] - 26s 116ms/step - loss: 0.2146\n","Epoch 50/100\n","226/226 [==============================] - 26s 117ms/step - loss: 0.2103\n","Epoch 51/100\n","226/226 [==============================] - 26s 116ms/step - loss: 0.2003\n","Epoch 52/100\n","226/226 [==============================] - 28s 123ms/step - loss: 0.1974\n","Epoch 53/100\n","226/226 [==============================] - 26s 116ms/step - loss: 0.1915\n","Epoch 54/100\n","226/226 [==============================] - 26s 115ms/step - loss: 0.1859\n","Epoch 55/100\n","226/226 [==============================] - 26s 116ms/step - loss: 0.1626\n","Epoch 56/100\n","226/226 [==============================] - 26s 116ms/step - loss: 0.1568\n","Epoch 57/100\n","226/226 [==============================] - 27s 121ms/step - loss: 0.1426\n","Epoch 58/100\n","226/226 [==============================] - 26s 114ms/step - loss: 0.1517\n","Epoch 59/100\n","226/226 [==============================] - 26s 115ms/step - loss: 0.1343\n","Epoch 60/100\n","226/226 [==============================] - 26s 115ms/step - loss: 0.1303\n","Epoch 61/100\n","226/226 [==============================] - 26s 114ms/step - loss: 0.1236\n","Epoch 62/100\n","226/226 [==============================] - 26s 115ms/step - loss: 0.1153\n","Epoch 63/100\n","226/226 [==============================] - 28s 122ms/step - loss: 0.1143\n","Epoch 64/100\n","226/226 [==============================] - 26s 115ms/step - loss: 0.1112\n","Epoch 65/100\n","226/226 [==============================] - 26s 115ms/step - loss: 0.1124\n","Epoch 66/100\n","226/226 [==============================] - 26s 114ms/step - loss: 0.1235\n","Epoch 67/100\n","226/226 [==============================] - 26s 114ms/step - loss: 0.0881\n","Epoch 68/100\n","226/226 [==============================] - 26s 115ms/step - loss: 0.0912\n","Epoch 69/100\n","226/226 [==============================] - 26s 114ms/step - loss: 0.0839\n","Epoch 70/100\n","226/226 [==============================] - 26s 115ms/step - loss: 0.0904\n","Epoch 71/100\n","226/226 [==============================] - 26s 113ms/step - loss: 0.0825\n","Epoch 72/100\n","226/226 [==============================] - 26s 115ms/step - loss: 0.1021\n","Epoch 73/100\n","226/226 [==============================] - 26s 114ms/step - loss: 0.0776\n","Epoch 74/100\n","226/226 [==============================] - 26s 115ms/step - loss: 0.0693\n","Epoch 75/100\n","226/226 [==============================] - 26s 114ms/step - loss: 0.0723\n","Epoch 76/100\n","226/226 [==============================] - 26s 114ms/step - loss: 0.0686\n","Epoch 77/100\n","226/226 [==============================] - 26s 115ms/step - loss: 0.0590\n","Epoch 78/100\n","226/226 [==============================] - 27s 121ms/step - loss: 0.0682\n","Epoch 79/100\n","226/226 [==============================] - 26s 114ms/step - loss: 0.0539\n","Epoch 80/100\n","226/226 [==============================] - 26s 115ms/step - loss: 0.0503\n","Epoch 81/100\n","226/226 [==============================] - 26s 116ms/step - loss: 0.0633\n","Epoch 82/100\n","226/226 [==============================] - 26s 114ms/step - loss: 0.0512\n","Epoch 83/100\n","226/226 [==============================] - 27s 121ms/step - loss: 0.0497\n","Epoch 84/100\n","226/226 [==============================] - 26s 114ms/step - loss: 0.0413\n","Epoch 85/100\n","226/226 [==============================] - 26s 115ms/step - loss: 0.0432\n","Epoch 86/100\n","226/226 [==============================] - 26s 115ms/step - loss: 0.0492\n","Epoch 87/100\n","226/226 [==============================] - 26s 115ms/step - loss: 0.0486\n","Epoch 88/100\n","226/226 [==============================] - 26s 116ms/step - loss: 0.0355\n","Epoch 89/100\n","226/226 [==============================] - 28s 121ms/step - loss: 0.0433\n","Epoch 90/100\n","226/226 [==============================] - 26s 117ms/step - loss: 0.0387\n","Epoch 91/100\n","226/226 [==============================] - 26s 115ms/step - loss: 0.0472\n","Epoch 92/100\n","226/226 [==============================] - 26s 116ms/step - loss: 0.0360\n","Epoch 93/100\n","226/226 [==============================] - 27s 118ms/step - loss: 0.0406\n","Epoch 94/100\n","226/226 [==============================] - 28s 123ms/step - loss: 0.0376\n","Epoch 95/100\n","226/226 [==============================] - 26s 116ms/step - loss: 0.0353\n","Epoch 96/100\n","226/226 [==============================] - 27s 117ms/step - loss: 0.0263\n","Epoch 97/100\n","226/226 [==============================] - 26s 117ms/step - loss: 0.0287\n","Epoch 98/100\n","226/226 [==============================] - 30s 132ms/step - loss: 0.0286\n","Epoch 99/100\n","226/226 [==============================] - 28s 123ms/step - loss: 0.0375\n","Epoch 100/100\n","226/226 [==============================] - 26s 116ms/step - loss: 0.0332\n"]}]},{"cell_type":"code","source":["model.save_weights(model_folder)"],"metadata":{"id":"-TFMGWpszqVi"},"id":"-TFMGWpszqVi","execution_count":null,"outputs":[]},{"cell_type":"code","source":["def generate_text(model, start_string, num_generate = 1000, temperature=1.0, random_seed = 2022):\n","    # Converting our start string to numbers (vectorizing).\n","    input_indices = [vocab_to_index.get(s) for i, s in enumerate(start_string) if i < window_len-1]\n","    input_indices = [vocab_to_index.get(pad_token)]*(window_len - len(input_indices)-1) + [vocab_to_index.get(start_token)] + input_indices\n","\n","    input_oh = tf.one_hot(input_indices, depth = vocab_size)\n","    x = tf.expand_dims(input_oh, 0)\n","\n","    # Empty string to store our results.\n","    text_generated = []\n","\n","    # Here batch size == 1.\n","    model.reset_states()\n","    for word_index in range(num_generate):\n","        prediction = model.predict([x,x])\n","\n","        # Using a categorical distribution to predict the character returned by the model.\n","        prediction = prediction / temperature\n","        predicted_id = tf.random.categorical(prediction, num_samples=1, seed = random_seed)[-1,0]\n","        predicted_oh = tf.one_hot(predicted_id, depth = vocab_size)\n","\n","        # We pass the series of previous words (up to window length) as the next input to the model\n","        # along with the previous hidden state.\n","        input_index = tf.expand_dims([predicted_oh], 0)\n","        x = tf.concat([x[:,1:,:],input_index], 1)\n","        \n","        pred_word = index_to_vocab[predicted_id.numpy()]\n","        text_generated.append(pred_word)\n","        if pred_word == end_token:\n","          break\n","    \n","    return (' '.join(start_string) + ' ' + ' '.join(text_generated)), text_generated"],"metadata":{"id":"_ANJJNQGSpdx"},"id":"_ANJJNQGSpdx","execution_count":null,"outputs":[]},{"cell_type":"code","source":["result_str, result = generate_text(model, start_string=['<verse>','\\n','step','by','step'], num_generate=50, temperature=1.0)"],"metadata":{"id":"wo0aCkdPL2EU"},"id":"wo0aCkdPL2EU","execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(result_str)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"smPNycjBnDXa","executionInfo":{"status":"ok","timestamp":1654817762678,"user_tz":-480,"elapsed":5,"user":{"displayName":"QUEK HAO YONG, GABRIEL _","userId":"08861584446371432378"}},"outputId":"0bd28c0a-db17-4580-fece-a47ec64d6674"},"id":"smPNycjBnDXa","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["<verse> \n"," step by step progressing day now moving her savour days coming night pure soldiers whatâ€™s grows independence moving bombay homely here soar current romance island hollywood seen difference five aspire mountain minute looking price help leap london waiting must single wall adore favourite light these learnt grateful <cls> grateful truly moments broadway walked\n"]}]},{"cell_type":"code","source":[""],"metadata":{"id":"PgGgpFvaxDuL"},"id":"PgGgpFvaxDuL","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.8"},"colab":{"name":"Autoencoder (LSTM).ipynb","provenance":[{"file_id":"1L31juRVcjedsJQLb65vDeIYnGfc5VeMn","timestamp":1654812818685},{"file_id":"1s0I-h_H-57P4mfHpn7K9ARRffBzA2996","timestamp":1654811271378},{"file_id":"1fSgHJcraq0bKZQlGXUqlQ4abpWOsgdIu","timestamp":1654782642697},{"file_id":"1_pyvxTi14GzEPtSGxMTy55XDNlCfsK0h","timestamp":1654781952290},{"file_id":"164GHOXuG8X-6WN_mbIfShYez3xOdSrkL","timestamp":1654771075102}],"collapsed_sections":[]},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":5}