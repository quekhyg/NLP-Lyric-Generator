{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1sqwH29gCCae",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 16028,
     "status": "ok",
     "timestamp": 1654813654829,
     "user": {
      "displayName": "QUEK HAO YONG, GABRIEL _",
      "userId": "08861584446371432378"
     },
     "user_tz": -480
    },
    "id": "1sqwH29gCCae",
    "outputId": "ef54ffc7-5409-452c-d745-afb01b221087"
   },
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')\n",
    "# %cd /content/drive/MyDrive/SMU_MITB_NLP/Group Project/NLP-Lyric-Generator/src/bin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eed94d9c",
   "metadata": {
    "id": "eed94d9c"
   },
   "outputs": [],
   "source": [
    "### Standard Imports\n",
    "import numpy as np\n",
    "import re\n",
    "import sys\n",
    "import os\n",
    "from collections import Counter\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "18f77d0b",
   "metadata": {
    "id": "18f77d0b"
   },
   "outputs": [],
   "source": [
    "### Custom Imports\n",
    "sys.path.append('../')\n",
    "import lib.utilities as utils\n",
    "import lib.autoencoder_utilities as ae_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "QsvWeCUNxSvd",
   "metadata": {
    "id": "QsvWeCUNxSvd"
   },
   "outputs": [],
   "source": [
    "### Text Parameters\n",
    "start_token = '<cls>'\n",
    "end_token = '<eos>'\n",
    "pad_token = '<pad>'\n",
    "unk_token = '<unk>'\n",
    "newline_token = '<new>'\n",
    "\n",
    "### General Parameters\n",
    "random_seed = 2022\n",
    "model_folder = '../../models/autoencoder/lstm/v1'\n",
    "\n",
    "### Model Parameters\n",
    "val_split = 0.2\n",
    "window_len = 15\n",
    "batch_size = 64\n",
    "enc_dim, dec_dim = 256, 256\n",
    "learn_rate = 0.001\n",
    "epochs = 50\n",
    "dropout = 0.05\n",
    "recurrent_dropout = 0.05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "016082cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(model_folder, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e1f082fd",
   "metadata": {
    "id": "e1f082fd"
   },
   "outputs": [],
   "source": [
    "### Load Data\n",
    "corpus = utils.load_corpus()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "52adf0e5",
   "metadata": {
    "id": "52adf0e5",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "### Pre-Processing Text\n",
    "words, word_count, index_to_vocab, vocab_to_index, songs, songs_token_ind = utils.tokenize_corpus(corpus,\n",
    "                                                                                                  window_length = window_len,\n",
    "                                                                                                  end_token = end_token,\n",
    "                                                                                                  start_token = start_token,\n",
    "                                                                                                  pad_token = pad_token,\n",
    "                                                                                                  unk_token = unk_token)\n",
    "vocab_size = len(word_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "FwuVvlRF-cgL",
   "metadata": {
    "id": "FwuVvlRF-cgL"
   },
   "outputs": [],
   "source": [
    "x_encoder, x_decoder, y = ae_utils.construct_seq_data(songs_token_ind, window_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "KY-CHZ0CcP2C",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 11,
     "status": "ok",
     "timestamp": 1654813670764,
     "user": {
      "displayName": "QUEK HAO YONG, GABRIEL _",
      "userId": "08861584446371432378"
     },
     "user_tz": -480
    },
    "id": "KY-CHZ0CcP2C",
    "outputId": "4a2c1d03-f000-4458-bf4d-35fb5ee84172"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['oh', '\\n', 'oh', 'oh', 'oh', 'oh', 'oh', 'oh', 'oh', '\\n', 'oh', 'oh', 'oh', 'oh', 'oh']\n",
      "['oh', 'oh', '\\n', 'oh', 'oh', 'oh', 'oh', 'oh', 'oh', 'oh', '\\n', 'oh', 'oh', 'oh', 'oh']\n",
      "oh\n"
     ]
    }
   ],
   "source": [
    "rand_int = np.random.randint(0, len(x_encoder), 1)[0]\n",
    "print([index_to_vocab.get(x) for x in x_encoder[rand_int]])\n",
    "print([index_to_vocab.get(x) for x in x_decoder[rand_int]])\n",
    "print(index_to_vocab.get(y[rand_int]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "Dk3I2VI1Nza3",
   "metadata": {
    "id": "Dk3I2VI1Nza3"
   },
   "outputs": [],
   "source": [
    "train_dataset, val_dataset = ae_utils.construct_datasets(x_encoder, x_decoder, y,\n",
    "                                                         validation_split = val_split,\n",
    "                                                         random_seed = random_seed,\n",
    "                                                         batch_size = batch_size,\n",
    "                                                         vocab_size = vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "202bf8be",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 599,
     "status": "ok",
     "timestamp": 1654813676567,
     "user": {
      "displayName": "QUEK HAO YONG, GABRIEL _",
      "userId": "08861584446371432378"
     },
     "user_tz": -480
    },
    "id": "202bf8be",
    "outputId": "74b8ad29-7683-4f72-8352-3ffbdcf5d637"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer encoder_lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer decoder_lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " encoder_input (InputLayer)     [(None, 15, 1050)]   0           []                               \n",
      "                                                                                                  \n",
      " decoder_input (InputLayer)     [(None, 15, 1050)]   0           []                               \n",
      "                                                                                                  \n",
      " encoder_lstm (LSTM)            [(None, 256),        1338368     ['encoder_input[0][0]']          \n",
      "                                 (None, 256),                                                     \n",
      "                                 (None, 256)]                                                     \n",
      "                                                                                                  \n",
      " decoder_lstm (LSTM)            (None, 256)          1338368     ['decoder_input[0][0]',          \n",
      "                                                                  'encoder_lstm[0][1]',           \n",
      "                                                                  'encoder_lstm[0][2]']           \n",
      "                                                                                                  \n",
      " output (Dense)                 (None, 1050)         269850      ['decoder_lstm[0][0]']           \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 2,946,586\n",
      "Trainable params: 2,946,586\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Encoder\n",
    "encoder_input = layers.Input(shape=(window_len,vocab_size), name = 'encoder_input')\n",
    "\n",
    "# Return state in addition to output\n",
    "encoder_output, encoder_hidden_state, encoder_cell_state = layers.LSTM(enc_dim,\n",
    "                                                                       dropout = dropout, recurrent_dropout = recurrent_dropout,\n",
    "                                                                       return_state=True, name = \"encoder_lstm\")(encoder_input)\n",
    "\n",
    "# Decoder\n",
    "decoder_input = layers.Input(shape=(window_len,vocab_size), name = 'decoder_input')\n",
    "\n",
    "# Pass the encoder state to a new LSTM, as initial state\n",
    "decoder_output = layers.LSTM(dec_dim,\n",
    "                             dropout = dropout, recurrent_dropout = recurrent_dropout,\n",
    "                             name=\"decoder_lstm\")(decoder_input, initial_state=[encoder_hidden_state, encoder_cell_state])\n",
    "output = layers.Dense(vocab_size, name = 'output', activation = 'softmax')(decoder_output)\n",
    "\n",
    "model = tf.keras.Model((encoder_input, decoder_input), output)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "83bb01d4",
   "metadata": {
    "id": "83bb01d4"
   },
   "outputs": [],
   "source": [
    "model.compile(loss = 'categorical_crossentropy',\n",
    "              optimizer = tf.keras.optimizers.Adam(learning_rate=learn_rate),\n",
    "              metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "MS_vUBeRM5EK",
   "metadata": {
    "id": "MS_vUBeRM5EK"
   },
   "outputs": [],
   "source": [
    "### Callbacks\n",
    "callback_es = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    min_delta=0,\n",
    "    patience=5,\n",
    "    verbose=0,\n",
    "    mode='min',\n",
    "    baseline=None,\n",
    "    restore_best_weights=True\n",
    ")\n",
    "\n",
    "callback_mc = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=model_folder+'/weights.{epoch:02d}-{val_loss:.2f}-{val_accuracy:.2f}.hdf5',\n",
    "    save_weights_only=True,\n",
    "    monitor='val_loss',\n",
    "    mode='min',\n",
    "    save_best_only=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "hIOwUeQ0E0LD",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3419544,
     "status": "ok",
     "timestamp": 1654817096109,
     "user": {
      "displayName": "QUEK HAO YONG, GABRIEL _",
      "userId": "08861584446371432378"
     },
     "user_tz": -480
    },
    "id": "hIOwUeQ0E0LD",
    "outputId": "d6c698d6-43bd-4ec4-ed59-1459cdebc790"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "181/181 [==============================] - 62s 320ms/step - loss: 5.1782 - accuracy: 0.1617 - val_loss: 4.8902 - val_accuracy: 0.1667\n",
      "Epoch 2/50\n",
      "181/181 [==============================] - 58s 319ms/step - loss: 4.8007 - accuracy: 0.1914 - val_loss: 4.6757 - val_accuracy: 0.2110\n",
      "Epoch 3/50\n",
      "181/181 [==============================] - 59s 328ms/step - loss: 4.6482 - accuracy: 0.2130 - val_loss: 4.5228 - val_accuracy: 0.2301\n",
      "Epoch 4/50\n",
      "181/181 [==============================] - 60s 332ms/step - loss: 4.3147 - accuracy: 0.2506 - val_loss: 3.8864 - val_accuracy: 0.3174\n",
      "Epoch 5/50\n",
      "181/181 [==============================] - 58s 320ms/step - loss: 3.5494 - accuracy: 0.3479 - val_loss: 3.1604 - val_accuracy: 0.4425\n",
      "Epoch 6/50\n",
      "181/181 [==============================] - 59s 325ms/step - loss: 2.9307 - accuracy: 0.4365 - val_loss: 2.6740 - val_accuracy: 0.4858\n",
      "Epoch 7/50\n",
      "181/181 [==============================] - 60s 331ms/step - loss: 2.5023 - accuracy: 0.5026 - val_loss: 2.2512 - val_accuracy: 0.5832\n",
      "Epoch 8/50\n",
      "181/181 [==============================] - 59s 324ms/step - loss: 2.1771 - accuracy: 0.5585 - val_loss: 2.1587 - val_accuracy: 0.5821\n",
      "Epoch 9/50\n",
      "181/181 [==============================] - 62s 341ms/step - loss: 1.9281 - accuracy: 0.6053 - val_loss: 1.7393 - val_accuracy: 0.6750\n",
      "Epoch 10/50\n",
      "181/181 [==============================] - 56s 309ms/step - loss: 1.7001 - accuracy: 0.6522 - val_loss: 1.5883 - val_accuracy: 0.7166\n",
      "Epoch 11/50\n",
      "181/181 [==============================] - 57s 314ms/step - loss: 1.5307 - accuracy: 0.6850 - val_loss: 1.4642 - val_accuracy: 0.7415\n",
      "Epoch 12/50\n",
      "181/181 [==============================] - 57s 313ms/step - loss: 1.3670 - accuracy: 0.7211 - val_loss: 1.3172 - val_accuracy: 0.7675\n",
      "Epoch 13/50\n",
      "181/181 [==============================] - 56s 310ms/step - loss: 1.2595 - accuracy: 0.7405 - val_loss: 1.2392 - val_accuracy: 0.7852\n",
      "Epoch 14/50\n",
      "181/181 [==============================] - 57s 313ms/step - loss: 1.1273 - accuracy: 0.7688 - val_loss: 1.1145 - val_accuracy: 0.8129\n",
      "Epoch 15/50\n",
      "181/181 [==============================] - 55s 305ms/step - loss: 0.9802 - accuracy: 0.8021 - val_loss: 1.0691 - val_accuracy: 0.8091\n",
      "Epoch 16/50\n",
      "181/181 [==============================] - 58s 320ms/step - loss: 0.9182 - accuracy: 0.8129 - val_loss: 0.9465 - val_accuracy: 0.8441\n",
      "Epoch 17/50\n",
      "181/181 [==============================] - 60s 330ms/step - loss: 0.7926 - accuracy: 0.8381 - val_loss: 0.8633 - val_accuracy: 0.8614\n",
      "Epoch 18/50\n",
      "181/181 [==============================] - 58s 322ms/step - loss: 0.7304 - accuracy: 0.8489 - val_loss: 0.8207 - val_accuracy: 0.8683\n",
      "Epoch 19/50\n",
      "181/181 [==============================] - 59s 324ms/step - loss: 0.6341 - accuracy: 0.8727 - val_loss: 0.7559 - val_accuracy: 0.8812\n",
      "Epoch 20/50\n",
      "181/181 [==============================] - 59s 328ms/step - loss: 0.5525 - accuracy: 0.8889 - val_loss: 0.6355 - val_accuracy: 0.9051\n",
      "Epoch 21/50\n",
      "181/181 [==============================] - 56s 311ms/step - loss: 0.4886 - accuracy: 0.9051 - val_loss: 0.6359 - val_accuracy: 0.9023\n",
      "Epoch 22/50\n",
      "181/181 [==============================] - 56s 310ms/step - loss: 0.4414 - accuracy: 0.9169 - val_loss: 0.5972 - val_accuracy: 0.9044\n",
      "Epoch 23/50\n",
      "181/181 [==============================] - 57s 316ms/step - loss: 0.4163 - accuracy: 0.9214 - val_loss: 0.6253 - val_accuracy: 0.8974\n",
      "Epoch 24/50\n",
      "181/181 [==============================] - 56s 310ms/step - loss: 0.3540 - accuracy: 0.9337 - val_loss: 0.4543 - val_accuracy: 0.9359\n",
      "Epoch 25/50\n",
      "181/181 [==============================] - 62s 343ms/step - loss: 0.2944 - accuracy: 0.9505 - val_loss: 0.4483 - val_accuracy: 0.9401\n",
      "Epoch 26/50\n",
      "181/181 [==============================] - 60s 328ms/step - loss: 0.2676 - accuracy: 0.9543 - val_loss: 0.5383 - val_accuracy: 0.9106\n",
      "Epoch 27/50\n",
      "181/181 [==============================] - 65s 358ms/step - loss: 0.2375 - accuracy: 0.9617 - val_loss: 0.4150 - val_accuracy: 0.9435\n",
      "Epoch 28/50\n",
      "181/181 [==============================] - 64s 355ms/step - loss: 0.1974 - accuracy: 0.9721 - val_loss: 0.3441 - val_accuracy: 0.9556\n",
      "Epoch 29/50\n",
      "181/181 [==============================] - 60s 332ms/step - loss: 0.1773 - accuracy: 0.9739 - val_loss: 0.3986 - val_accuracy: 0.9387\n",
      "Epoch 30/50\n",
      "181/181 [==============================] - 62s 342ms/step - loss: 0.1606 - accuracy: 0.9777 - val_loss: 0.3112 - val_accuracy: 0.9605\n",
      "Epoch 31/50\n",
      "181/181 [==============================] - 60s 330ms/step - loss: 0.1442 - accuracy: 0.9805 - val_loss: 0.3120 - val_accuracy: 0.9591\n",
      "Epoch 32/50\n",
      "181/181 [==============================] - 61s 338ms/step - loss: 0.1182 - accuracy: 0.9855 - val_loss: 0.3165 - val_accuracy: 0.9577\n",
      "Epoch 33/50\n",
      "181/181 [==============================] - 57s 314ms/step - loss: 0.1145 - accuracy: 0.9848 - val_loss: 0.3018 - val_accuracy: 0.9636\n",
      "Epoch 34/50\n",
      "181/181 [==============================] - 62s 343ms/step - loss: 0.0967 - accuracy: 0.9886 - val_loss: 0.2875 - val_accuracy: 0.9647\n",
      "Epoch 35/50\n",
      "181/181 [==============================] - 59s 327ms/step - loss: 0.0748 - accuracy: 0.9915 - val_loss: 0.2363 - val_accuracy: 0.9747\n",
      "Epoch 36/50\n",
      "181/181 [==============================] - 57s 318ms/step - loss: 0.0567 - accuracy: 0.9940 - val_loss: 0.2275 - val_accuracy: 0.9789\n",
      "Epoch 37/50\n",
      "181/181 [==============================] - 58s 319ms/step - loss: 0.0458 - accuracy: 0.9963 - val_loss: 0.2297 - val_accuracy: 0.9771\n",
      "Epoch 38/50\n",
      "181/181 [==============================] - 58s 322ms/step - loss: 0.0424 - accuracy: 0.9967 - val_loss: 0.2336 - val_accuracy: 0.9757\n",
      "Epoch 39/50\n",
      "181/181 [==============================] - 61s 337ms/step - loss: 0.0457 - accuracy: 0.9951 - val_loss: 0.2162 - val_accuracy: 0.9809\n",
      "Epoch 40/50\n",
      "181/181 [==============================] - 61s 335ms/step - loss: 0.0379 - accuracy: 0.9954 - val_loss: 0.2230 - val_accuracy: 0.9806\n",
      "Epoch 41/50\n",
      "181/181 [==============================] - 60s 331ms/step - loss: 0.0396 - accuracy: 0.9950 - val_loss: 0.2060 - val_accuracy: 0.9806\n",
      "Epoch 42/50\n",
      "181/181 [==============================] - 61s 337ms/step - loss: 0.0349 - accuracy: 0.9958 - val_loss: 0.2026 - val_accuracy: 0.9837\n",
      "Epoch 43/50\n",
      "181/181 [==============================] - 59s 327ms/step - loss: 0.0278 - accuracy: 0.9976 - val_loss: 0.2067 - val_accuracy: 0.9820\n",
      "Epoch 44/50\n",
      "181/181 [==============================] - 60s 329ms/step - loss: 0.0221 - accuracy: 0.9978 - val_loss: 0.2078 - val_accuracy: 0.9809\n",
      "Epoch 45/50\n",
      "181/181 [==============================] - 60s 334ms/step - loss: 0.0228 - accuracy: 0.9968 - val_loss: 0.2040 - val_accuracy: 0.9820\n",
      "Epoch 46/50\n",
      "181/181 [==============================] - 59s 326ms/step - loss: 0.0210 - accuracy: 0.9973 - val_loss: 0.1981 - val_accuracy: 0.9834\n",
      "Epoch 47/50\n",
      "181/181 [==============================] - 63s 345ms/step - loss: 0.0223 - accuracy: 0.9971 - val_loss: 0.1888 - val_accuracy: 0.9841\n",
      "Epoch 48/50\n",
      "181/181 [==============================] - 63s 346ms/step - loss: 0.0224 - accuracy: 0.9971 - val_loss: 0.1953 - val_accuracy: 0.9837\n",
      "Epoch 49/50\n",
      "181/181 [==============================] - 59s 325ms/step - loss: 0.0169 - accuracy: 0.9979 - val_loss: 0.1902 - val_accuracy: 0.9844\n",
      "Epoch 50/50\n",
      "181/181 [==============================] - 59s 328ms/step - loss: 0.0208 - accuracy: 0.9975 - val_loss: 0.1944 - val_accuracy: 0.9823\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x = train_dataset, validation_data = val_dataset, epochs = epochs, callbacks = [callback_es, callback_mc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "-TFMGWpszqVi",
   "metadata": {
    "id": "-TFMGWpszqVi"
   },
   "outputs": [],
   "source": [
    "model.save_weights(model_folder+'/final_weights.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "_ANJJNQGSpdx",
   "metadata": {
    "id": "_ANJJNQGSpdx"
   },
   "outputs": [],
   "source": [
    "def generate_text(model, start_string, num_generate = 1000, temperature=1.0, random_seed = 2022):\n",
    "    # Converting our start string to numbers (vectorizing).\n",
    "    input_indices = [vocab_to_index.get(s) for i, s in enumerate(start_string) if i < window_len-1]\n",
    "    input_indices = [i if i is not None else vocab_to_index.get(unk_token) for i in input_indices]\n",
    "    input_indices = [vocab_to_index.get(pad_token)]*(window_len - len(input_indices)-1) + [vocab_to_index.get(start_token)] + input_indices\n",
    "\n",
    "    input_oh = tf.one_hot(input_indices, depth = vocab_size)\n",
    "    x = tf.expand_dims(input_oh, 0)\n",
    "\n",
    "    # Empty string to store our results.\n",
    "    text_generated = []\n",
    "\n",
    "    # Here batch size == 1.\n",
    "    model.reset_states()\n",
    "    for word_index in range(num_generate):\n",
    "        prediction = model.predict([x,x])\n",
    "\n",
    "        # Using a categorical distribution to predict the character returned by the model.\n",
    "        prediction = prediction / temperature\n",
    "        predicted_id = tf.random.categorical(prediction, num_samples=1, seed = random_seed)[-1,0]\n",
    "        predicted_oh = tf.one_hot(predicted_id, depth = vocab_size)\n",
    "\n",
    "        # We pass the series of previous words (up to window length) as the next input to the model\n",
    "        # along with the previous hidden state.\n",
    "        input_index = tf.expand_dims([predicted_oh], 0)\n",
    "        x = tf.concat([x[:,1:,:],input_index], 1)\n",
    "        \n",
    "        pred_word = index_to_vocab[predicted_id.numpy()]\n",
    "        text_generated.append(pred_word)\n",
    "        if pred_word == end_token:\n",
    "            break\n",
    "    \n",
    "    return (' '.join(start_string) + ' ' + ' '.join(text_generated)), text_generated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "wo0aCkdPL2EU",
   "metadata": {
    "id": "wo0aCkdPL2EU"
   },
   "outputs": [],
   "source": [
    "prompts = ['Whenever I think back', 'And so this I know',\n",
    "           'I am tired of being what you want me to be', 'Feeling so faithless, lost under the surface',\n",
    "           'Relight our fire, we will find our way', 'We will rise stronger together']\n",
    "result_strings = {}\n",
    "results = {}\n",
    "for prompt in prompts:\n",
    "    tokenized_prompt = utils.tokenize_text(prompt)\n",
    "    result_str, result = generate_text(model, start_string=tokenized_prompt, num_generate=100, temperature=1.0)\n",
    "    result_strings[prompt] = result_str\n",
    "    results[prompt] = result\n",
    "\n",
    "final_str = f'\\n\\n{end_token}\\n\\n'.join([f'{k}:\\n{v}' for k, v in result_strings.items()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "df72fa0c",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Whenever I think back:\n",
      "whenever i think back by look wind lift unfurled progress inspiration yea going towards said <unk> memory feel my twinkling hands soldiers four homely shore not dawns seem generation summing cooking in real guess itâ€™s progressing out <eos>\n",
      "\n",
      "<eos>\n",
      "\n",
      "And so this I know:\n",
      "and so this i know progressing day now moving her savour days coming night pure heed whatâ€™s grows independence moving trained homely here soar current romance island experienced seen difference five aspire mountain minute looking price help leap okay waiting must single broadway adore favourite light these learnt grateful <cls> grateful truly moments bombay airmen am red singaporean dating days know paradise childhood society different take smile sailors walking bombay brave lighting ties from ordinary stronger keep fly better map to type yeah kwai how together warmth broadway under needs green everyone now yo defend iâ€™m get table pledge upon loud echoing prepared changed necessary\n",
      "\n",
      "<eos>\n",
      "\n",
      "I am tired of being what you want me to be:\n",
      "i am tired of being what you want me to be <pad> grown kid stormy stars far magazine snow ease role might peers current thinking failing ones though key yourself alive plain lamp san <verse> lion neighbourhood whole twinkling it carried tears asking contradict million unforgettable neighbour rings ourselves lift despair into goes build bursts lions coming changing unreal stop taken yo loved defend signs anthem four work tower white way share lands heard ago turning <bridge> miracles leaving recognition fresh yo five ease beside brighter greenery any unity whatever recess action inspiration streams deep winding special amazed sights across learnt think unforgettable stressed side will anthem hearts wife call begins\n",
      "\n",
      "<eos>\n",
      "\n",
      "Feeling so faithless, lost under the surface:\n",
      "feeling so faithless lost under the surface about goal there believe become society say stronger pains filled motion crescent birthday far colleagues hour realize long become bursts justice happen price win prospered under go welcome oh sign knowledge corner common better moving birthday book this is common into world teacher joyful friend toil building ago daylight unsure prosperity roads after darkness leaving plain daylight itâ€™s who been open fair live safe fills stars homely feels written fortunate evening ever life races space blood colour waiting great trained faces art done century up know vast creed yourself anthem smile free songs tastes troubles lighting spirit sensation moment am\n",
      "\n",
      "<eos>\n",
      "\n",
      "Relight our fire, we will find our way:\n",
      "relight our fire we will find our way far become than quay defence tell signs strides show sailors overcome spring many magazine favourite jewel flame selfexplanatory crystal as things tried bell meeting singaporean happen always whoa prosperity care dark wonderful story someone must treasure begins everyday joyful seize part race universe universe merry its trained common she exercise ties used open crescent nurtured say mind fair our unfold wishes wall painted grace news skies stories darkness grateful stepping others win riverside near rainbow road should afar brighter if at peace hoping have yearning singing dawn how bell your beyond name very book grateful dreaming things spot stars rest\n",
      "\n",
      "<eos>\n",
      "\n",
      "We will rise stronger together:\n",
      "we will rise stronger together x fortunate nights danced beauty no stay style looking youth quick uk those late refreshed century belong too vigilance mountain esplanade uneventfullest wall yea discovered within sea some sister mine faces dawns soldiers soul realize cairo housings gaze conviction written wooh <eos>\n"
     ]
    }
   ],
   "source": [
    "print(final_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "PgGgpFvaxDuL",
   "metadata": {
    "id": "PgGgpFvaxDuL"
   },
   "outputs": [],
   "source": [
    "with open(model_folder+'/generated_text.txt', 'w') as f:\n",
    "    f.write(final_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c395bdc6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Autoencoder (LSTM).ipynb",
   "provenance": [
    {
     "file_id": "1L31juRVcjedsJQLb65vDeIYnGfc5VeMn",
     "timestamp": 1654812818685
    },
    {
     "file_id": "1s0I-h_H-57P4mfHpn7K9ARRffBzA2996",
     "timestamp": 1654811271378
    },
    {
     "file_id": "1fSgHJcraq0bKZQlGXUqlQ4abpWOsgdIu",
     "timestamp": 1654782642697
    },
    {
     "file_id": "1_pyvxTi14GzEPtSGxMTy55XDNlCfsK0h",
     "timestamp": 1654781952290
    },
    {
     "file_id": "164GHOXuG8X-6WN_mbIfShYez3xOdSrkL",
     "timestamp": 1654771075102
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
