{"cells":[{"cell_type":"code","execution_count":1,"id":"1sqwH29gCCae","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2811,"status":"ok","timestamp":1655031862455,"user":{"displayName":"QUEK HAO YONG, GABRIEL _","userId":"08861584446371432378"},"user_tz":-480},"id":"1sqwH29gCCae","outputId":"5536fe7c-11e1-44a1-d298-fb89696965d0"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n","/content/drive/MyDrive/SMU_MITB_NLP/Group Project/NLP-Lyric-Generator/src/bin\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')\n","%cd /content/drive/MyDrive/SMU_MITB_NLP/Group Project/NLP-Lyric-Generator/src/bin"]},{"cell_type":"code","execution_count":2,"id":"eed94d9c","metadata":{"executionInfo":{"elapsed":2630,"status":"ok","timestamp":1655031865080,"user":{"displayName":"QUEK HAO YONG, GABRIEL _","userId":"08861584446371432378"},"user_tz":-480},"id":"eed94d9c"},"outputs":[],"source":["### Standard Imports\n","import numpy as np\n","import re\n","import sys\n","import os\n","from collections import Counter\n","\n","import tensorflow as tf\n","from tensorflow.keras import layers"]},{"cell_type":"code","execution_count":3,"id":"18f77d0b","metadata":{"executionInfo":{"elapsed":561,"status":"ok","timestamp":1655031865632,"user":{"displayName":"QUEK HAO YONG, GABRIEL _","userId":"08861584446371432378"},"user_tz":-480},"id":"18f77d0b"},"outputs":[],"source":["### Custom Imports\n","sys.path.append('../')\n","import lib.utilities as utils\n","import lib.autoencoder_utilities as ae_utils"]},{"cell_type":"code","execution_count":4,"id":"QsvWeCUNxSvd","metadata":{"executionInfo":{"elapsed":8,"status":"ok","timestamp":1655031865633,"user":{"displayName":"QUEK HAO YONG, GABRIEL _","userId":"08861584446371432378"},"user_tz":-480},"id":"QsvWeCUNxSvd"},"outputs":[],"source":["### Text Parameters\n","start_token = '<cls>'\n","end_token = '<eos>'\n","pad_token = '<pad>'\n","unk_token = '<unk>'\n","newline_token = '<new>'\n","mask_token = '<mask>'\n","\n","### General Parameters\n","random_seed = 2022\n","model_folder = '../../../autoencoder/lstm/v4'\n","model_name = 'autoencoder_lstm_with_attention_with_final_mask'\n","\n","### Model Parameters\n","val_split = 0.2\n","window_len = 15\n","batch_size = 64\n","enc_dim, dec_dim = 256, 256\n","learn_rate = 0.001\n","epochs = 50\n","dropout = 0.05\n","recurrent_dropout = 0.05"]},{"cell_type":"code","execution_count":5,"id":"zy-R6jQR4Ozz","metadata":{"executionInfo":{"elapsed":8,"status":"ok","timestamp":1655031865633,"user":{"displayName":"QUEK HAO YONG, GABRIEL _","userId":"08861584446371432378"},"user_tz":-480},"id":"zy-R6jQR4Ozz"},"outputs":[],"source":["os.makedirs(model_folder, exist_ok=True)"]},{"cell_type":"code","execution_count":6,"id":"e1f082fd","metadata":{"executionInfo":{"elapsed":8,"status":"ok","timestamp":1655031865634,"user":{"displayName":"QUEK HAO YONG, GABRIEL _","userId":"08861584446371432378"},"user_tz":-480},"id":"e1f082fd"},"outputs":[],"source":["### Load Data\n","corpus = utils.load_corpus()\n","train_corpus, val_corpus, train_files, val_files = utils.split_corpus()"]},{"cell_type":"code","execution_count":7,"id":"52adf0e5","metadata":{"executionInfo":{"elapsed":8,"status":"ok","timestamp":1655031865634,"user":{"displayName":"QUEK HAO YONG, GABRIEL _","userId":"08861584446371432378"},"user_tz":-480},"id":"52adf0e5","scrolled":true},"outputs":[],"source":["### Pre-Processing Text\n","_, word_count, index_to_vocab, vocab_to_index, _, _ = utils.tokenize_corpus(corpus,\n","                                                                            window_length = window_len,\n","                                                                            end_token = end_token,\n","                                                                            start_token = start_token,\n","                                                                            pad_token = pad_token,\n","                                                                            unk_token = unk_token,\n","                                                                            newline_token = newline_token,\n","                                                                            mask_token = mask_token)\n","vocab_size = len(word_count)\n","\n","train_words, _, _, _, train_songs, train_songs_token_ind = utils.tokenize_corpus(train_corpus,\n","                                                                       window_length = window_len,\n","                                                                       index_to_vocab = index_to_vocab,\n","                                                                       vocab_to_index = vocab_to_index,\n","                                                                       end_token = end_token,\n","                                                                       start_token = start_token,\n","                                                                       pad_token = pad_token,\n","                                                                       unk_token = unk_token,\n","                                                                       newline_token = newline_token,\n","                                                                       mask_token = mask_token)\n","\n","val_words, _, _, _, _, val_songs_token_ind = utils.tokenize_corpus(val_corpus,\n","                                                           window_length = window_len,\n","                                                           index_to_vocab = index_to_vocab,\n","                                                           vocab_to_index = vocab_to_index,\n","                                                           end_token = end_token,\n","                                                           start_token = start_token,\n","                                                           pad_token = pad_token,\n","                                                           unk_token = unk_token,\n","                                                           newline_token = newline_token,\n","                                                           mask_token = mask_token)"]},{"cell_type":"code","execution_count":8,"id":"cb1a6431","metadata":{"id":"cb1a6431","executionInfo":{"status":"ok","timestamp":1655031865634,"user_tz":-480,"elapsed":8,"user":{"displayName":"QUEK HAO YONG, GABRIEL _","userId":"08861584446371432378"}}},"outputs":[],"source":["train_x_encoder, train_x_decoder, train_y = ae_utils.construct_seq_data(train_songs_token_ind, window_len)\n","train_x_encoder = ae_utils.mask_last(train_x_encoder, vocab_to_index, mask_token = mask_token)\n","val_x_encoder, val_x_decoder, val_y = ae_utils.construct_seq_data(val_songs_token_ind, window_len)\n","val_x_encoder = ae_utils.mask_last(val_x_encoder, vocab_to_index, mask_token = mask_token)"]},{"cell_type":"code","execution_count":9,"id":"KY-CHZ0CcP2C","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":9,"status":"ok","timestamp":1655031865635,"user":{"displayName":"QUEK HAO YONG, GABRIEL _","userId":"08861584446371432378"},"user_tz":-480},"id":"KY-CHZ0CcP2C","outputId":"88875d23-a4aa-4792-ce79-ef6c38bd78a2"},"outputs":[{"output_type":"stream","name":"stdout","text":["['love', 'my', 'city', 'is', 'lively', 'ways', '<new>', 'warm', 'sunny', 'days', '<new>', 'sights', 'and', 'sounds', '<mask>']\n","['i', 'love', 'my', 'city', 'is', 'lively', 'ways', '<new>', 'warm', 'sunny', 'days', '<new>', 'sights', 'and', 'sounds']\n","special\n","['<new>', 'i', 'have', 'queued', 'in', 'the', 'west', 'end', 'to', 'catch', 'the', 'plays', '<new>', 'discovered', '<mask>']\n","['taipei', '<new>', 'i', 'have', 'queued', 'in', 'the', 'west', 'end', 'to', 'catch', 'the', 'plays', '<new>', 'discovered']\n","i\n"]}],"source":["rand_int = np.random.randint(0, len(train_x_encoder), 1)[0]\n","print([index_to_vocab.get(x) for x in train_x_encoder[rand_int]])\n","print([index_to_vocab.get(x) for x in train_x_decoder[rand_int]])\n","print(index_to_vocab.get(train_y[rand_int]))\n","\n","rand_int = np.random.randint(0, len(val_x_encoder), 1)[0]\n","print([index_to_vocab.get(x) for x in val_x_encoder[rand_int]])\n","print([index_to_vocab.get(x) for x in val_x_decoder[rand_int]])\n","print(index_to_vocab.get(val_y[rand_int]))"]},{"cell_type":"code","execution_count":10,"id":"Dk3I2VI1Nza3","metadata":{"executionInfo":{"elapsed":5223,"status":"ok","timestamp":1655031894100,"user":{"displayName":"QUEK HAO YONG, GABRIEL _","userId":"08861584446371432378"},"user_tz":-480},"id":"Dk3I2VI1Nza3"},"outputs":[],"source":["train_dataset = ae_utils.construct_datasets(train_x_encoder, train_x_decoder, train_y,\n","                                            random_seed = random_seed,\n","                                            batch_size = batch_size,\n","                                            vocab_size = vocab_size)\n","val_dataset = ae_utils.construct_datasets(val_x_encoder, val_x_decoder, val_y,\n","                                            random_seed = random_seed,\n","                                            batch_size = batch_size,\n","                                            vocab_size = vocab_size)"]},{"cell_type":"code","execution_count":15,"id":"202bf8be","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1139,"status":"ok","timestamp":1655031942228,"user":{"displayName":"QUEK HAO YONG, GABRIEL _","userId":"08861584446371432378"},"user_tz":-480},"id":"202bf8be","outputId":"a5555b85-9f47-46e8-a26b-e359800283c8"},"outputs":[{"output_type":"stream","name":"stdout","text":["WARNING:tensorflow:Layer encoder_lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n","WARNING:tensorflow:Layer decoder_lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n","Model: \"autoencoder_lstm_with_attention_with_final_mask\"\n","__________________________________________________________________________________________________\n"," Layer (type)                   Output Shape         Param #     Connected to                     \n","==================================================================================================\n"," encoder_input (InputLayer)     [(None, 15, 1042)]   0           []                               \n","                                                                                                  \n"," decoder_input (InputLayer)     [(None, 15, 1042)]   0           []                               \n","                                                                                                  \n"," encoder_lstm (LSTM)            [(None, 256),        1330176     ['encoder_input[0][0]']          \n","                                 (None, 256),                                                     \n","                                 (None, 256)]                                                     \n","                                                                                                  \n"," decoder_lstm (LSTM)            (None, 256)          1330176     ['decoder_input[0][0]',          \n","                                                                  'encoder_lstm[0][1]',           \n","                                                                  'encoder_lstm[0][2]']           \n","                                                                                                  \n"," attention (Attention)          (None, 256)          0           ['decoder_lstm[0][0]',           \n","                                                                  'encoder_lstm[0][0]']           \n","                                                                                                  \n"," tf.concat_2 (TFOpLambda)       (None, 512)          0           ['decoder_lstm[0][0]',           \n","                                                                  'attention[0][0]']              \n","                                                                                                  \n"," output (Dense)                 (None, 1042)         534546      ['tf.concat_2[0][0]']            \n","                                                                                                  \n","==================================================================================================\n","Total params: 3,194,898\n","Trainable params: 3,194,898\n","Non-trainable params: 0\n","__________________________________________________________________________________________________\n"]}],"source":["# Encoder\n","encoder_input = layers.Input(shape=(window_len,vocab_size), name = 'encoder_input')\n","\n","# Return state in addition to output\n","encoder_output, encoder_hidden_state, encoder_cell_state = layers.LSTM(enc_dim,\n","                                                                       dropout = dropout, recurrent_dropout = recurrent_dropout,\n","                                                                       return_state=True, name = \"encoder_lstm\")(encoder_input)\n","\n","# Decoder\n","decoder_input = layers.Input(shape=(window_len,vocab_size), name = 'decoder_input')\n","\n","# Pass the encoder state to a new LSTM, as initial state\n","decoder_output = layers.LSTM(dec_dim,\n","                             dropout = dropout, recurrent_dropout = recurrent_dropout,\n","                             name=\"decoder_lstm\")(decoder_input, initial_state=[encoder_hidden_state, encoder_cell_state])\n","\n","# Attention\n","attention_context_vector = tf.keras.layers.Attention(name = 'attention')(inputs = [decoder_output, encoder_output])\n","\n","# Output\n","output = layers.Dense(vocab_size, name = 'output', activation = 'softmax')(tf.concat([decoder_output, attention_context_vector], 1))\n","\n","model = tf.keras.Model((encoder_input, decoder_input), output, name = model_name)\n","model.summary()"]},{"cell_type":"code","execution_count":16,"id":"83bb01d4","metadata":{"executionInfo":{"elapsed":533,"status":"ok","timestamp":1655031950869,"user":{"displayName":"QUEK HAO YONG, GABRIEL _","userId":"08861584446371432378"},"user_tz":-480},"id":"83bb01d4"},"outputs":[],"source":["model.compile(loss = 'categorical_crossentropy',\n","              optimizer = tf.keras.optimizers.Adam(learning_rate=learn_rate),\n","              metrics = ['accuracy'])"]},{"cell_type":"code","execution_count":17,"id":"oxvZ57pCIWWu","metadata":{"executionInfo":{"elapsed":2,"status":"ok","timestamp":1655031951424,"user":{"displayName":"QUEK HAO YONG, GABRIEL _","userId":"08861584446371432378"},"user_tz":-480},"id":"oxvZ57pCIWWu"},"outputs":[],"source":["### Callbacks\n","callback_es = tf.keras.callbacks.EarlyStopping(\n","    monitor='val_loss',\n","    min_delta=0,\n","    patience=10,\n","    verbose=1,\n","    mode='min',\n","    baseline=None,\n","    restore_best_weights=True\n",")\n","\n","callback_mc = tf.keras.callbacks.ModelCheckpoint(\n","    filepath=model_folder+'/weights.{epoch:02d}-{val_loss:.2f}-{val_accuracy:.2f}.hdf5',\n","    save_weights_only=True,\n","    monitor='val_loss',\n","    mode='min',\n","    save_best_only=False)"]},{"cell_type":"code","execution_count":18,"id":"hIOwUeQ0E0LD","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":430895,"status":"ok","timestamp":1655032382648,"user":{"displayName":"QUEK HAO YONG, GABRIEL _","userId":"08861584446371432378"},"user_tz":-480},"id":"hIOwUeQ0E0LD","outputId":"91b9f086-1b3e-4393-a191-3e333d2a80ae"},"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/50\n","180/180 [==============================] - 30s 132ms/step - loss: 5.0665 - accuracy: 0.1830 - val_loss: 5.0413 - val_accuracy: 0.1963\n","Epoch 2/50\n","180/180 [==============================] - 23s 125ms/step - loss: 4.5780 - accuracy: 0.2229 - val_loss: 4.9613 - val_accuracy: 0.1997\n","Epoch 3/50\n","180/180 [==============================] - 22s 121ms/step - loss: 4.2814 - accuracy: 0.2373 - val_loss: 4.9547 - val_accuracy: 0.2150\n","Epoch 4/50\n","180/180 [==============================] - 22s 122ms/step - loss: 3.9104 - accuracy: 0.2672 - val_loss: 4.9118 - val_accuracy: 0.2289\n","Epoch 5/50\n","180/180 [==============================] - 22s 120ms/step - loss: 3.5468 - accuracy: 0.3123 - val_loss: 4.9552 - val_accuracy: 0.2177\n","Epoch 6/50\n","180/180 [==============================] - 22s 120ms/step - loss: 3.2221 - accuracy: 0.3499 - val_loss: 5.0238 - val_accuracy: 0.2395\n","Epoch 7/50\n","180/180 [==============================] - 23s 130ms/step - loss: 2.9041 - accuracy: 0.3906 - val_loss: 5.1177 - val_accuracy: 0.2446\n","Epoch 8/50\n","180/180 [==============================] - 22s 121ms/step - loss: 2.5892 - accuracy: 0.4352 - val_loss: 5.2814 - val_accuracy: 0.2391\n","Epoch 9/50\n","180/180 [==============================] - 22s 120ms/step - loss: 2.3179 - accuracy: 0.4834 - val_loss: 5.4256 - val_accuracy: 0.2221\n","Epoch 10/50\n","180/180 [==============================] - 22s 121ms/step - loss: 2.0884 - accuracy: 0.5270 - val_loss: 5.5496 - val_accuracy: 0.2228\n","Epoch 11/50\n","180/180 [==============================] - 22s 120ms/step - loss: 1.8508 - accuracy: 0.5734 - val_loss: 5.5796 - val_accuracy: 0.2228\n","Epoch 12/50\n","180/180 [==============================] - 21s 119ms/step - loss: 1.6560 - accuracy: 0.6109 - val_loss: 5.7017 - val_accuracy: 0.2194\n","Epoch 13/50\n","180/180 [==============================] - 21s 118ms/step - loss: 1.4880 - accuracy: 0.6483 - val_loss: 5.8449 - val_accuracy: 0.2105\n","Epoch 14/50\n","180/180 [==============================] - ETA: 0s - loss: 1.3396 - accuracy: 0.6822Restoring model weights from the end of the best epoch: 4.\n","180/180 [==============================] - 22s 122ms/step - loss: 1.3396 - accuracy: 0.6822 - val_loss: 6.0290 - val_accuracy: 0.2126\n","Epoch 14: early stopping\n"]}],"source":["history = model.fit(x = train_dataset, validation_data = val_dataset, epochs = epochs, callbacks = [callback_es, callback_mc])"]},{"cell_type":"code","execution_count":19,"id":"QhFHlI6o06Gz","metadata":{"executionInfo":{"elapsed":12,"status":"ok","timestamp":1655032382649,"user":{"displayName":"QUEK HAO YONG, GABRIEL _","userId":"08861584446371432378"},"user_tz":-480},"id":"QhFHlI6o06Gz"},"outputs":[],"source":["model.save_weights(f'{model_folder}/final_weights.hdf5')"]},{"cell_type":"code","source":["#model.load_weights(f'{model_folder}/final_weights.hdf5')"],"metadata":{"id":"ljTcusxBWCjT","executionInfo":{"status":"ok","timestamp":1655032382649,"user_tz":-480,"elapsed":5,"user":{"displayName":"QUEK HAO YONG, GABRIEL _","userId":"08861584446371432378"}}},"id":"ljTcusxBWCjT","execution_count":20,"outputs":[]},{"cell_type":"code","execution_count":21,"id":"wo0aCkdPL2EU","metadata":{"executionInfo":{"elapsed":51792,"status":"ok","timestamp":1655032434437,"user":{"displayName":"QUEK HAO YONG, GABRIEL _","userId":"08861584446371432378"},"user_tz":-480},"id":"wo0aCkdPL2EU"},"outputs":[],"source":["prompts = ['Whenever I think back', 'And so this I know',\n","           'I am tired of being what you want me to be', 'Feeling so faithless, lost under the surface',\n","           'Relight our fire, we will find our way', 'We will rise stronger together']\n","result_strings = {}\n","results = {}\n","for prompt in prompts:\n","    result_str, result = utils.generate_text(model,\n","                                             ae_utils.ind_to_input_fun, ae_utils.update_input_fun,\n","                                             start_string = prompt,\n","                                             window_length = window_len,\n","                                             vocab_to_index_dict = vocab_to_index, index_to_vocab_dict = index_to_vocab,\n","                                             vocab_size = vocab_size,\n","                                             num_generate = 100, temperature = 1.0,\n","                                             random_seed = random_seed,\n","                                             end_token = end_token, start_token = start_token,\n","                                             pad_token = pad_token, unk_token = unk_token,\n","                                             newline_token = newline_token,\n","                                             depth = vocab_size)\n","    result_strings[prompt] = result_str\n","    results[prompt] = result"]},{"cell_type":"code","execution_count":22,"id":"smPNycjBnDXa","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":9,"status":"ok","timestamp":1655032434438,"user":{"displayName":"QUEK HAO YONG, GABRIEL _","userId":"08861584446371432378"},"user_tz":-480},"id":"smPNycjBnDXa","outputId":"17f4d34f-931e-403f-d7d8-3fbef8c991c8"},"outputs":[{"output_type":"stream","name":"stdout","text":["{'Whenever I think back': 'Whenever I think back \\n \\n a of of \\n <verse> \\n am my said lively struggled feel my crystals hands new uphold colleagues a not pride a the changing the in happy early \\n a out to to day now her celebrations sing the childhood strength see world \\n first is wide to working here country \\n is island is lively aside five wind special goes tastes a joy flag special life is my lost \\n favourite morning and love family \\n may truly future my heart am my singapore dating though know working will family \\n we first people together singapore homeland', 'And so this I know': 'And so this I know \\n \\n \\n much for of home \\n it \\n we see is together \\n then the hopes knew everyone now is add story \\n a my strong our higher \\n here a my grown home a out \\n this a out my the leaving tell were is worlds lives foundations set alive you love home <verse> \\n i whole are it wildest into asking remembered last my always hand ourselves our belong \\n <verse> build the fair home new \\n from room \\n home skill the home the children \\n place my share mind family had \\n <bridge> \\n', 'I am tired of being what you want me to be': 'I am tired of being what you want me to be of singing see a river years can new \\n years was like rainbow always to streams shining winding special amazed the ready in the climbing day side will on stars two call everywhere we our there believe become progress \\n \\n not born there \\n little it now and on bravely \\n \\n a a divine sea dedicated to go welcome shine me take and still a new is romance this is common light world low i it be years day my soar this where there a is my memories \\n it made is a homeland life we stars days', 'Feeling so faithless, lost under the surface': 'Feeling so faithless, lost under the surface of \\n <chorus> \\n to life \\n one will will time crescent determination faces a done century up know our a time free smile may tourists the things at spirit sea moment am far \\n than the trained tell stars treasure show we that sights many share favourite \\n flame belong the the things to shine everyone little to always a to care \\n <verse> a means must \\n will learn be used part shine go see to its been common help to fallstars a the lead away say mind is our move out now fashion to travelling day stories', 'Relight our fire, we will find our way': 'Relight our fire, we will find our way \\n \\n \\n is wherever to but voices road a rise brighter if the everyone that have times and help how shine your beyond hopes a romance courage for things lighting a got now worthwhile a time peace no stay be perfect to got hands times keep stirred century belong too where my me \\n where will the to sea the colour away faces pride all soul love room life my destiny to bay \\n the help sing equality people the together way a brand come unsure \\n belong \\n <chorus> \\n one as home our place and my \\n', 'We will rise stronger together': 'We will rise stronger together <verse> \\n said i to my on the came it the table highest is air democratic into my dreams future wings to citizens why \\n \\n always always true heart if special \\n we we people you from nation in fair it the all is crystals air white who the but used future \\n that where and hand it see would become is into way friends everyday the is times hero of upon world magic we light am heartbeat to singaporeans my my just \\n everybody is where where never \\n this future ties are share my a on the'}\n"]}],"source":["print(result_strings)"]},{"cell_type":"code","execution_count":23,"id":"PgGgpFvaxDuL","metadata":{"executionInfo":{"elapsed":5,"status":"ok","timestamp":1655032434438,"user":{"displayName":"QUEK HAO YONG, GABRIEL _","userId":"08861584446371432378"},"user_tz":-480},"id":"PgGgpFvaxDuL"},"outputs":[],"source":["for k, v in result_strings.items():\n","  with open(model_folder+f'/{model_name}-{k.lower()}.txt', 'w') as f:\n","      f.write(v)"]},{"cell_type":"code","source":[""],"metadata":{"id":"yXWz366llpCN"},"id":"yXWz366llpCN","execution_count":null,"outputs":[]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":[],"name":"Autoencoder (LSTM) with Attention and Masking.ipynb","provenance":[{"file_id":"16dJidSHlWJGR008gZdEomwxazJccnb0B","timestamp":1655029930247},{"file_id":"1KbPSOprQ0mhAGFUtVsBjF4O_vkFuvgL9","timestamp":1654815454538},{"file_id":"1L31juRVcjedsJQLb65vDeIYnGfc5VeMn","timestamp":1654812818685},{"file_id":"1s0I-h_H-57P4mfHpn7K9ARRffBzA2996","timestamp":1654811271378},{"file_id":"1fSgHJcraq0bKZQlGXUqlQ4abpWOsgdIu","timestamp":1654782642697},{"file_id":"1_pyvxTi14GzEPtSGxMTy55XDNlCfsK0h","timestamp":1654781952290},{"file_id":"164GHOXuG8X-6WN_mbIfShYez3xOdSrkL","timestamp":1654771075102}]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.8"}},"nbformat":4,"nbformat_minor":5}